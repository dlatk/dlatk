Search.setIndex({"alltitles": {"--AUC": [[9, null]], "--IDP": [[10, null]], "--add_corp_lex_table": [[12, null]], "--add_lda_messages": [[14, null]], "--add_lex_table": [[15, null]], "--add_ngrams": [[16, null]], "--add_ngrams_from_tokenized": [[17, null]], "--add_parses": [[18, null]], "--add_pos_ngram_table": [[19, null]], "--add_pos_table": [[20, null]], "--add_segmented": [[21, null]], "--add_sent_per_row": [[22, null]], "--add_sent_tokenized": [[23, null]], "--add_tokenized": [[24, null]], "--add_tweetpos": [[25, null]], "--add_tweettok": [[26, null]], "--aggregate_feats_by_new_group": [[27, null]], "--all_controls_only": [[28, null]], "--anscombe": [[29, null]], "--barplot": [[30, null]], "--bert_layer_aggregation": [[31, null]], "--bert_layers": [[32, null], [213, "bert-layers"]], "--bert_model": [[11, null], [33, null], [213, "bert-model"]], "--bert_msg_aggregation": [[34, null]], "--blacklist": [[35, null]], "--boolean": [[36, null]], "--bootstrapp": [[37, null]], "--categorical": [[39, null]], "--cca": [[40, null]], "--cca_outcomes_vs_controls": [[41, null]], "--cca_penalty_feats": [[42, null]], "--cca_penalty_outcomes": [[43, null]], "--cca_permute": [[44, null]], "--cca_predict_components": [[45, null]], "--classification_to_lexicon": [[46, null]], "--clean_messages": [[47, null]], "--cohens_d": [[48, null]], "--colabify": [[49, null]], "--colloc_table": [[50, null]], "--combine_feat_tables": [[51, null]], "--control_adjust_outcomes_regression": [[54, null]], "--control_combo_sizes": [[55, null]], "--corp_topic_tagcloud": [[56, null]], "--correlate": [[57, null]], "--create_random_sample": [[58, null], [59, null]], "--csv": [[60, null]], "--date_field": [[62, null]], "--db_engine": [[63, null]], "--deduplicate": [[64, null]], "--descplot": [[66, null]], "--describe_tables": [[65, null]], "--emb_layer_aggregation": [[67, null]], "--emb_layers": [[68, null], [239, "emb-layers"]], "--emb_model": [[13, null], [69, null], [239, "emb-model"]], "--emb_msg_aggregation": [[70, null]], "--encoding": [[71, null]], "--estimate_lda_topics": [[72, null]], "--extension": [[73, null]], "--feat_as_control": [[76, null]], "--feat_as_outcome": [[77, null]], "--feat_as_path_start": [[78, null]], "--feat_blacklist": [[79, null]], "--feat_colloc_filter": [[80, null]], "--feat_correl_filter": [[81, null]], "--feat_flexibin": [[82, null]], "--feat_names": [[83, null]], "--feat_occ_filter": [[84, null]], "--feat_whitelist": [[85, null]], "--feature_selection": [[86, null]], "--feature_selection_string": [[87, null]], "--feature_type_name": [[88, null]], "--fit_reducer": [[89, null]], "--flexiplot_file": [[90, null]], "--folds": [[91, null]], "--freq": [[92, null]], "--from_file": [[93, null]], "--group_freq_thresh": [[94, null]], "--include_sub_collocs": [[95, null]], "--interaction_ddla": [[96, null]], "--interaction_ddla_pvalue": [[97, null]], "--interactions": [[98, null]], "--keep_low_variance_outcomes": [[99, null]], "--language_filter": [[101, null]], "--lda_alpha": [[102, null]], "--lda_beta": [[103, null]], "--lda_iterations": [[104, null]], "--lda_lexicon_name": [[105, null]], "--lex_anscombe": [[106, null]], "--lex_interface": [[107, null]], "--lexicondb": [[108, null]], "--load_model": [[109, null]], "--loessplot": [[110, null]], "--log": [[111, null]], "--logistic_reg": [[112, null]], "--make_topic_wordclouds": [[114, null]], "--make_wordclouds": [[115, null]], "--mallet_path": [[116, null]], "--max_tagcloud_words": [[117, null]], "--mediation": [[118, null]], "--mediation_boot": [[119, null]], "--mediation_boot_num": [[120, null]], "--mediation_csv": [[121, null]], "--mediation_method": [[122, null]], "--mediation_no_summary": [[123, null]], "--mediators": [[124, null]], "--message_field": [[125, null]], "--messageid_field": [[126, null]], "--model": [[127, null]], "--multiclass": [[128, null]], "--mysql_config_file": [[129, null]], "--n_components": [[130, null]], "--nfold_test_classifiers": [[52, null]], "--nfold_test_regression": [[53, null]], "--no_correction": [[131, null]], "--no_features": [[132, null]], "--no_lang": [[133, null]], "--no_lda_lexicon": [[134, null]], "--no_lda_stopping": [[135, null]], "--no_metafeats": [[136, null]], "--no_standardize": [[137, null]], "--no_tagcloud_filter": [[138, null]], "--no_unicode": [[139, null]], "--num_stopwords": [[140, null]], "--num_topics": [[141, null]], "--nvalue": [[142, null]], "--outcome_controls": [[143, null]], "--outcome_fields": [[144, null]], "--outcome_interaction": [[145, null]], "--outcome_table": [[146, null]], "--outcome_with_outcome": [[147, null]], "--outcome_with_outcome_only": [[148, null]], "--outcomes": [[149, null]], "--outliers_to_mean": [[150, null]], "--output_name": [[151, null]], "--p_correction": [[152, null]], "--p_value": [[153, null]], "--path_starts": [[154, null]], "--picklefile": [[155, null]], "--predict_classification_to_outcome_table": [[156, null]], "--predict_classifiers": [[157, null]], "--predict_classifiers_to_feats": [[158, null], [159, null]], "--predict_regression": [[160, null]], "--predict_regression_to_feats": [[161, null]], "--predict_regression_to_outcome_table": [[162, null]], "--prediction_csv": [[163, null]], "--print_joined_feature_lines": [[164, null]], "--print_tokenized_lines": [[165, null]], "--reduced_lexicon": [[166, null]], "--reducer_to_lexicon": [[167, null]], "--regression_to_lexicon": [[168, null]], "--rmatrix": [[169, null]], "--roc": [[170, null]], "--save_lda_files": [[171, null]], "--save_model": [[172, null]], "--scatterplot": [[173, null]], "--segmentation_model": [[174, null]], "--set_p_occ": [[175, null]], "--set_pmi_threshold": [[176, null]], "--show_feature_tables": [[113, null]], "--show_tables": [[177, null]], "--sort": [[178, null]], "--spam_filter": [[179, null]], "--sparse": [[180, null]], "--spearman": [[181, null]], "--sqrt": [[182, null]], "--stratify_folds": [[183, null]], "--super_topics": [[184, null]], "--tagcloud": [[186, null]], "--tagcloud_colorscheme": [[187, null]], "--tagcloud_filter": [[188, null]], "--test_classifiers": [[189, null]], "--test_regression": [[190, null]], "--tf_idf": [[191, null]], "--to_file": [[192, null]], "--topic_lexicon": [[193, null]], "--topic_tagcloud": [[194, null]], "--train_classifiers": [[195, null]], "--train_regression": [[196, null]], "--ttest_feat_tables": [[197, null]], "--use_collocs": [[198, null]], "--view_tables": [[199, null]], "--weighted_lexicon": [[200, null]], "--where": [[201, null]], "--whitelist": [[202, null]], "--word_table": [[203, null]], "--zScoreGroup": [[204, null]], "-d": [[61, null]], "-f": [[74, null]], "-f.": [[75, null]], "-g": [[38, null]], "-l": [[100, null]], "-t": [[185, null]], "0.4.0 (2015-08-17)": [[0, "id15"]], "0.5.0 (2016-04-01)": [[0, "id14"]], "0.6.0 (2016-06-15)": [[0, "id13"]], "0.6.1 (2016-07-05)": [[0, "id12"]], "1 to 3 Gram Clouds": [[231, "to-3-gram-clouds"]], "1. Adding Transformers features": [[239, "adding-transformers-features"]], "1. Preparing messages": [[213, "preparing-messages"]], "1.0.0 (2016-10-21)": [[0, "id11"]], "1.0.1 (2016-11-21)": [[0, "id10"]], "1.1.0 (2017-06-29)": [[0, "id9"]], "1.1.1 (2017-11-30)": [[0, "id8"]], "1.1.2 (2018-01-09)": [[0, "id7"]], "1.1.3 (2018-01-09)": [[0, "id6"]], "1.1.4 (2018-01-11)": [[0, "id5"]], "1.1.5 (2018-03-02)": [[0, "id4"]], "1.1.6 (2019-07-31)": [[0, "id3"]], "1.2.0 (2021-03-11)": [[0, "id2"]], "2. Adding BERT features": [[213, "adding-bert-features"]], "2000 Facebook Topics": [[1, "facebook-topics"]], "2013": [[209, "id32"]], "2014": [[209, "id26"]], "2015": [[209, "id21"]], "2016": [[209, "id11"]], "2017": [[209, "id4"]], "2018": [[209, "id3"]], "2019": [[209, "id2"]], "2020": [[209, "id1"]], "3. Understanding BERT Feature Table Names": [[213, "understanding-bert-feature-table-names"]], "3. Understanding Transformers Feature Table Names": [[239, "understanding-transformers-feature-table-names"]], "4. Using BERT features": [[213, "using-bert-features"]], "4. Using Transformers features": [[239, "using-transformers-features"]], "Acknowledgment": [[223, "acknowledgment"]], "Advanced Feature Extraction": [[212, null]], "Age and Gender Lexica": [[1, "age-and-gender-lexica"]], "Aggregation": [[213, "aggregation"], [239, "aggregation"]], "Alphabetical list of dlatkInterface Flags": [[8, null]], "Applying A Pickle Model": [[234, null]], "Argument and Default Value": [[9, "argument-and-default-value"], [10, "argument-and-default-value"], [11, "argument-and-default-value"], [12, "argument-and-default-value"], [13, "argument-and-default-value"], [14, "argument-and-default-value"], [15, "argument-and-default-value"], [16, "argument-and-default-value"], [17, "argument-and-default-value"], [18, "argument-and-default-value"], [19, "argument-and-default-value"], [20, "argument-and-default-value"], [21, "argument-and-default-value"], [22, "argument-and-default-value"], [23, "argument-and-default-value"], [24, "argument-and-default-value"], [25, "argument-and-default-value"], [26, "argument-and-default-value"], [27, "argument-and-default-value"], [28, "argument-and-default-value"], [29, "argument-and-default-value"], [30, "argument-and-default-value"], [31, "argument-and-default-value"], [32, "argument-and-default-value"], [33, "argument-and-default-value"], [34, "argument-and-default-value"], [35, "argument-and-default-value"], [36, "argument-and-default-value"], [37, "argument-and-default-value"], [38, "argument-and-default-value"], [39, "argument-and-default-value"], [40, "argument-and-default-value"], [41, "argument-and-default-value"], [42, "argument-and-default-value"], [43, "argument-and-default-value"], [44, "argument-and-default-value"], [45, "argument-and-default-value"], [46, "argument-and-default-value"], [47, "argument-and-default-value"], [48, "argument-and-default-value"], [49, "argument-and-default-value"], [50, "argument-and-default-value"], [51, "argument-and-default-value"], [52, "argument-and-default-value"], [53, "argument-and-default-value"], [54, "argument-and-default-value"], [55, "argument-and-default-value"], [57, "argument-and-default-value"], [61, "argument-and-default-value"], [62, "argument-and-default-value"], [63, "argument-and-default-value"], [64, "argument-and-default-value"], [66, "argument-and-default-value"], [67, "argument-and-default-value"], [68, "argument-and-default-value"], [69, "argument-and-default-value"], [70, "argument-and-default-value"], [71, "argument-and-default-value"], [72, "argument-and-default-value"], [74, "argument-and-default-value"], [75, "argument-and-default-value"], [79, "argument-and-default-value"], [80, "argument-and-default-value"], [81, "argument-and-default-value"], [82, "argument-and-default-value"], [83, "argument-and-default-value"], [84, "argument-and-default-value"], [85, "argument-and-default-value"], [86, "argument-and-default-value"], [87, "argument-and-default-value"], [89, "argument-and-default-value"], [90, "argument-and-default-value"], [91, "argument-and-default-value"], [92, "argument-and-default-value"], [93, "argument-and-default-value"], [94, "argument-and-default-value"], [95, "argument-and-default-value"], [96, "argument-and-default-value"], [97, "argument-and-default-value"], [98, "argument-and-default-value"], [99, "argument-and-default-value"], [100, "argument-and-default-value"], [101, "argument-and-default-value"], [102, "argument-and-default-value"], [103, "argument-and-default-value"], [104, "argument-and-default-value"], [105, "argument-and-default-value"], [106, "argument-and-default-value"], [108, "argument-and-default-value"], [109, "argument-and-default-value"], [110, "argument-and-default-value"], [112, "argument-and-default-value"], [114, "argument-and-default-value"], [115, "argument-and-default-value"], [116, "argument-and-default-value"], [117, "argument-and-default-value"], [118, "argument-and-default-value"], [119, "argument-and-default-value"], [120, "argument-and-default-value"], [121, "argument-and-default-value"], [122, "argument-and-default-value"], [123, "argument-and-default-value"], [124, "argument-and-default-value"], [125, "argument-and-default-value"], [126, "argument-and-default-value"], [127, "argument-and-default-value"], [128, "argument-and-default-value"], [129, "argument-and-default-value"], [130, "argument-and-default-value"], [131, "argument-and-default-value"], [132, "argument-and-default-value"], [133, "argument-and-default-value"], [134, "argument-and-default-value"], [135, "argument-and-default-value"], [136, "argument-and-default-value"], [137, "argument-and-default-value"], [138, "argument-and-default-value"], [139, "argument-and-default-value"], [140, "argument-and-default-value"], [141, "argument-and-default-value"], [142, "argument-and-default-value"], [143, "argument-and-default-value"], [144, "argument-and-default-value"], [145, "argument-and-default-value"], [146, "argument-and-default-value"], [147, "argument-and-default-value"], [148, "argument-and-default-value"], [149, "argument-and-default-value"], [150, "argument-and-default-value"], [151, "argument-and-default-value"], [152, "argument-and-default-value"], [153, "argument-and-default-value"], [154, "argument-and-default-value"], [155, "argument-and-default-value"], [156, "argument-and-default-value"], [157, "argument-and-default-value"], [158, "argument-and-default-value"], [159, "argument-and-default-value"], [160, "argument-and-default-value"], [161, "argument-and-default-value"], [162, "argument-and-default-value"], [163, "argument-and-default-value"], [164, "argument-and-default-value"], [165, "argument-and-default-value"], [166, "argument-and-default-value"], [167, "argument-and-default-value"], [168, "argument-and-default-value"], [169, "argument-and-default-value"], [170, "argument-and-default-value"], [171, "argument-and-default-value"], [172, "argument-and-default-value"], [173, "argument-and-default-value"], [174, "argument-and-default-value"], [175, "argument-and-default-value"], [176, "argument-and-default-value"], [178, "argument-and-default-value"], [179, "argument-and-default-value"], [180, "argument-and-default-value"], [181, "argument-and-default-value"], [182, "argument-and-default-value"], [183, "argument-and-default-value"], [184, "argument-and-default-value"], [185, "argument-and-default-value"], [186, "argument-and-default-value"], [187, "argument-and-default-value"], [188, "argument-and-default-value"], [189, "argument-and-default-value"], [190, "argument-and-default-value"], [191, "argument-and-default-value"], [192, "argument-and-default-value"], [193, "argument-and-default-value"], [194, "argument-and-default-value"], [195, "argument-and-default-value"], [196, "argument-and-default-value"], [197, "argument-and-default-value"], [198, "argument-and-default-value"], [200, "argument-and-default-value"], [201, "argument-and-default-value"], [202, "argument-and-default-value"], [203, "argument-and-default-value"], [204, "argument-and-default-value"]], "BERT in DLATK": [[213, null]], "Blog Authorship Corpus": [[1, "blog-authorship-corpus"]], "Build Image from DockerFile": [[223, "build-image-from-dockerfile"]], "Building A Pickle Model": [[235, null]], "Building The Final Model": [[235, "building-the-final-model"]], "CSV": [[231, "csv"]], "CSV to MySQL": [[225, "csv-to-mysql"], [225, "id1"]], "Changelog": [[0, null]], "Character n-grams": [[212, "character-n-grams"]], "Citations": [[205, "citations"]], "Classification": [[7, "classification"], [236, "classification"]], "Clustering": [[7, "clustering"], [211, "clustering"]], "Clustering and Super Topics": [[215, null]], "Colloc_filter": [[222, "colloc-filter"]], "Collocations and Pointwise Mutual Information": [[212, "collocations-and-pointwise-mutual-information"]], "Combining Feature Tables": [[212, "combining-feature-tables"]], "Command Line Interface": [[206, "command-line-interface"]], "Commands": [[234, "commands"], [235, "commands"]], "Continuing on...": [[221, "continuing-on"]], "Correlation Matrix": [[231, "correlation-matrix"]], "Correlations": [[231, "correlations"]], "Creating an init file from the command line": [[226, "creating-an-init-file-from-the-command-line"]], "Creating tables": [[237, "creating-tables"]], "DDLA with an interactions": [[227, "ddla-with-an-interactions"]], "DLA": [[222, "dla"]], "DLA Rules of Thumb": [[222, null]], "DLA with Interactions": [[227, null]], "DLATK LDA Interface": [[228, null]], "DLATK Paper": [[209, "dlatk-paper"]], "DLATK with ConvoKit": [[218, null]], "DLATK's Pandas Interface": [[232, null]], "Data Cleaning": [[219, null]], "Data Engines": [[211, "data-engines"], [220, null]], "Deduplicating": [[219, "deduplicating"]], "Describe Tables": [[237, "describe-tables"]], "Description": [[9, "description"], [10, "description"], [11, "description"], [12, "description"], [13, "description"], [14, "description"], [15, "description"], [16, "description"], [17, "description"], [18, "description"], [19, "description"], [20, "description"], [21, "description"], [22, "description"], [23, "description"], [24, "description"], [25, "description"], [26, "description"], [27, "description"], [28, "description"], [29, "description"], [30, "description"], [31, "description"], [32, "description"], [33, "description"], [34, "description"], [35, "description"], [36, "description"], [37, "description"], [38, "description"], [39, "description"], [40, "description"], [41, "description"], [42, "description"], [43, "description"], [44, "description"], [45, "description"], [46, "description"], [47, "description"], [48, "description"], [49, "description"], [50, "description"], [51, "description"], [52, "description"], [53, "description"], [54, "description"], [55, "description"], [56, "description"], [57, "description"], [58, "description"], [59, "description"], [60, "description"], [61, "description"], [62, "description"], [63, "description"], [64, "description"], [65, "description"], [66, "description"], [67, "description"], [68, "description"], [69, "description"], [70, "description"], [71, "description"], [72, "description"], [73, "description"], [74, "description"], [75, "description"], [76, "description"], [77, "description"], [78, "description"], [79, "description"], [80, "description"], [81, "description"], [82, "description"], [83, "description"], [84, "description"], [85, "description"], [86, "description"], [87, "description"], [89, "description"], [90, "description"], [91, "description"], [92, "description"], [93, "description"], [94, "description"], [95, "description"], [96, "description"], [97, "description"], [98, "description"], [99, "description"], [100, "description"], [101, "description"], [102, "description"], [103, "description"], [104, "description"], [105, "description"], [106, "description"], [107, "description"], [108, "description"], [109, "description"], [110, "description"], [111, "description"], [112, "description"], [113, "description"], [114, "description"], [115, "description"], [116, "description"], [117, "description"], [118, "description"], [119, "description"], [120, "description"], [121, "description"], [122, "description"], [123, "description"], [124, "description"], [125, "description"], [126, "description"], [127, "description"], [128, "description"], [129, "description"], [130, "description"], [131, "description"], [132, "description"], [133, "description"], [134, "description"], [135, "description"], [136, "description"], [137, "description"], [138, "description"], [139, "description"], [140, "description"], [141, "description"], [142, "description"], [143, "description"], [144, "description"], [145, "description"], [146, "description"], [147, "description"], [148, "description"], [149, "description"], [150, "description"], [151, "description"], [152, "description"], [153, "description"], [154, "description"], [155, "description"], [156, "description"], [157, "description"], [158, "description"], [159, "description"], [160, "description"], [161, "description"], [162, "description"], [163, "description"], [164, "description"], [165, "description"], [166, "description"], [167, "description"], [168, "description"], [169, "description"], [170, "description"], [171, "description"], [172, "description"], [173, "description"], [174, "description"], [175, "description"], [176, "description"], [177, "description"], [178, "description"], [179, "description"], [180, "description"], [181, "description"], [182, "description"], [183, "description"], [184, "description"], [185, "description"], [186, "description"], [187, "description"], [188, "description"], [189, "description"], [190, "description"], [191, "description"], [192, "description"], [193, "description"], [194, "description"], [195, "description"], [196, "description"], [197, "description"], [198, "description"], [199, "description"], [200, "description"], [201, "description"], [202, "description"], [203, "description"], [204, "description"]], "Details": [[9, "details"], [10, "details"], [11, "details"], [12, "details"], [13, "details"], [14, "details"], [15, "details"], [16, "details"], [17, "details"], [18, "details"], [19, "details"], [20, "details"], [21, "details"], [22, "details"], [23, "details"], [24, "details"], [25, "details"], [26, "details"], [27, "details"], [28, "details"], [29, "details"], [30, "details"], [31, "details"], [32, "details"], [33, "details"], [34, "details"], [35, "details"], [36, "details"], [37, "details"], [38, "details"], [39, "details"], [40, "details"], [41, "details"], [42, "details"], [43, "details"], [44, "details"], [45, "details"], [46, "details"], [47, "details"], [48, "details"], [49, "details"], [50, "details"], [51, "details"], [52, "details"], [53, "details"], [54, "details"], [55, "details"], [57, "details"], [61, "details"], [62, "details"], [63, "details"], [64, "details"], [66, "details"], [67, "details"], [68, "details"], [69, "details"], [70, "details"], [71, "details"], [72, "details"], [74, "details"], [75, "details"], [79, "details"], [80, "details"], [81, "details"], [82, "details"], [83, "details"], [84, "details"], [85, "details"], [86, "details"], [87, "details"], [88, "details"], [89, "details"], [90, "details"], [91, "details"], [92, "details"], [93, "details"], [94, "details"], [95, "details"], [96, "details"], [97, "details"], [98, "details"], [100, "details"], [101, "details"], [102, "details"], [103, "details"], [104, "details"], [105, "details"], [106, "details"], [107, "details"], [108, "details"], [109, "details"], [110, "details"], [111, "details"], [112, "details"], [116, "details"], [118, "details"], [119, "details"], [120, "details"], [122, "details"], [123, "details"], [125, "details"], [126, "details"], [127, "details"], [128, "details"], [129, "details"], [130, "details"], [131, "details"], [132, "details"], [133, "details"], [134, "details"], [135, "details"], [136, "details"], [137, "details"], [138, "details"], [140, "details"], [141, "details"], [142, "details"], [143, "details"], [144, "details"], [145, "details"], [146, "details"], [147, "details"], [148, "details"], [149, "details"], [151, "details"], [152, "details"], [153, "details"], [155, "details"], [156, "details"], [157, "details"], [158, "details"], [159, "details"], [160, "details"], [161, "details"], [162, "details"], [163, "details"], [164, "details"], [165, "details"], [166, "details"], [167, "details"], [168, "details"], [170, "details"], [171, "details"], [172, "details"], [173, "details"], [174, "details"], [179, "details"], [180, "details"], [181, "details"], [182, "details"], [183, "details"], [184, "details"], [185, "details"], [188, "details"], [189, "details"], [190, "details"], [191, "details"], [192, "details"], [193, "details"], [195, "details"], [196, "details"], [197, "details"], [198, "details"], [200, "details"], [202, "details"], [203, "details"], [204, "details"]], "Differential Language Analysis (DLA) Tutorial": [[221, null]], "Differential Language Analysis ToolKit": [[205, null]], "Example 1: unigram, bigram, etc features": [[224, "example-1-unigram-bigram-etc-features"]], "Example 2: extracted lexicon/topic features": [[224, "example-2-extracted-lexicon-topic-features"]], "Example Commands": [[9, "example-commands"], [10, "example-commands"], [11, "example-commands"], [12, "example-commands"], [13, "example-commands"], [14, "example-commands"], [15, "example-commands"], [16, "example-commands"], [17, "example-commands"], [18, "example-commands"], [19, "example-commands"], [20, "example-commands"], [21, "example-commands"], [22, "example-commands"], [23, "example-commands"], [24, "example-commands"], [25, "example-commands"], [26, "example-commands"], [27, "example-commands"], [28, "example-commands"], [29, "example-commands"], [30, "example-commands"], [31, "example-commands"], [32, "example-commands"], [33, "example-commands"], [34, "example-commands"], [35, "example-commands"], [36, "example-commands"], [37, "example-commands"], [39, "example-commands"], [40, "example-commands"], [41, "example-commands"], [42, "example-commands"], [43, "example-commands"], [44, "example-commands"], [45, "example-commands"], [46, "example-commands"], [47, "example-commands"], [48, "example-commands"], [49, "example-commands"], [51, "example-commands"], [52, "example-commands"], [53, "example-commands"], [54, "example-commands"], [56, "example-commands"], [57, "example-commands"], [58, "example-commands"], [59, "example-commands"], [60, "example-commands"], [62, "example-commands"], [63, "example-commands"], [64, "example-commands"], [65, "example-commands"], [66, "example-commands"], [67, "example-commands"], [68, "example-commands"], [69, "example-commands"], [70, "example-commands"], [71, "example-commands"], [72, "example-commands"], [73, "example-commands"], [79, "example-commands"], [80, "example-commands"], [81, "example-commands"], [82, "example-commands"], [83, "example-commands"], [84, "example-commands"], [85, "example-commands"], [86, "example-commands"], [87, "example-commands"], [89, "example-commands"], [90, "example-commands"], [91, "example-commands"], [92, "example-commands"], [93, "example-commands"], [94, "example-commands"], [96, "example-commands"], [97, "example-commands"], [98, "example-commands"], [99, "example-commands"], [101, "example-commands"], [102, "example-commands"], [103, "example-commands"], [104, "example-commands"], [105, "example-commands"], [106, "example-commands"], [107, "example-commands"], [109, "example-commands"], [110, "example-commands"], [111, "example-commands"], [112, "example-commands"], [113, "example-commands"], [114, "example-commands"], [115, "example-commands"], [116, "example-commands"], [117, "example-commands"], [118, "example-commands"], [119, "example-commands"], [120, "example-commands"], [122, "example-commands"], [123, "example-commands"], [125, "example-commands"], [126, "example-commands"], [128, "example-commands"], [129, "example-commands"], [130, "example-commands"], [132, "example-commands"], [133, "example-commands"], [134, "example-commands"], [135, "example-commands"], [136, "example-commands"], [138, "example-commands"], [139, "example-commands"], [139, "id1"], [140, "example-commands"], [141, "example-commands"], [147, "example-commands"], [148, "example-commands"], [149, "example-commands"], [150, "example-commands"], [151, "example-commands"], [152, "example-commands"], [158, "example-commands"], [159, "example-commands"], [163, "example-commands"], [164, "example-commands"], [166, "example-commands"], [167, "example-commands"], [168, "example-commands"], [169, "example-commands"], [171, "example-commands"], [172, "example-commands"], [174, "example-commands"], [175, "example-commands"], [176, "example-commands"], [177, "example-commands"], [178, "example-commands"], [178, "id1"], [179, "example-commands"], [181, "example-commands"], [182, "example-commands"], [183, "example-commands"], [184, "example-commands"], [186, "example-commands"], [187, "example-commands"], [188, "example-commands"], [189, "example-commands"], [190, "example-commands"], [191, "example-commands"], [192, "example-commands"], [193, "example-commands"], [194, "example-commands"], [195, "example-commands"], [196, "example-commands"], [197, "example-commands"], [198, "example-commands"], [199, "example-commands"], [200, "example-commands"], [201, "example-commands"], [202, "example-commands"], [203, "example-commands"], [204, "example-commands"]], "Examples": [[232, "examples"]], "Feature Extraction": [[7, "feature-extraction"], [211, "feature-extraction"]], "Feature Occurrence Filter": [[212, "feature-occurrence-filter"]], "Feature Refinement": [[7, "feature-refinement"]], "Feature Table": [[234, "feature-table"]], "Feature Tables": [[234, "feature-tables"]], "Features": [[232, "features"]], "Features and Outcomes in one dataframe": [[232, "features-and-outcomes-in-one-dataframe"]], "First Pass": [[235, "first-pass"]], "Flags": [[8, "flags"]], "Full Install": [[206, "full-install"]], "Full List of Dependencies": [[206, "full-list-of-dependencies"]], "Generate 1 to 3-gram Features": [[221, "generate-1-to-3-gram-features"]], "Generate 1to3-gram Features": [[221, "generate-1to3-gram-features"]], "Generate Lexicon (topic) Features": [[221, "generate-lexicon-topic-features"]], "Getting Started": [[205, "getting-started"], [206, "getting-started"]], "Getting feature tables as dataframes": [[232, "getting-feature-tables-as-dataframes"]], "Getting outcome tables as dataframes": [[232, "getting-outcome-tables-as-dataframes"]], "Getting started": [[211, "getting-started"]], "HTML": [[231, "html"]], "Happier Fun Tokenizer": [[238, "happier-fun-tokenizer"]], "Importing a FeatureGetter or OutcomeGetter": [[232, "importing-a-featuregetter-or-outcomegetter"]], "Importing and Exporting Data": [[225, null]], "Ini files": [[231, "ini-files"]], "Install (Anaconda)": [[206, "install-anaconda"]], "Install (GitHub)": [[206, "install-github"]], "Install (pip)": [[206, "install-pip"]], "Install FAQs": [[207, null]], "Install Issues": [[206, "install-issues"]], "Install Other Dependencies": [[206, "install-other-dependencies"]], "Install Stanford Parser": [[206, "install-stanford-parser"]], "Install Tweet NLP v0.3 (ark-tweet-nlp-0.3)": [[206, "install-tweet-nlp-v0-3-ark-tweet-nlp-0-3"]], "Install the IBM Wordcloud jar file (optional)": [[206, "install-the-ibm-wordcloud-jar-file-optional"]], "Installation": [[206, null]], "Installing DLATK with Docker": [[223, null]], "Intro Prediction / Classification / Predictive Lexica": [[236, null]], "LDA Topics": [[1, "lda-topics"]], "LDA with Mallet": [[211, "lda-with-mallet"]], "Language Data": [[1, "language-data"]], "Language Filtering": [[219, "language-filtering"]], "Language Insights": [[7, "language-insights"]], "Levels of analysis and group frequency threshold": [[222, "levels-of-analysis-and-group-frequency-threshold"]], "Lexica": [[1, "lexica"], [212, "lexica"]], "Linux": [[206, "linux"]], "Load NLTK corpus": [[206, "load-nltk-corpus"]], "Mallet (optional)": [[206, "mallet-optional"]], "Mallet LDA Interface": [[229, null]], "Module contents": [[2, "module-dlatk"], [3, "module-contents"], [4, "module-contents"], [5, "module-contents"]], "More Information": [[205, "more-information"]], "MySQL": [[220, "mysql"]], "MySQL Configuration": [[206, "mysql-configuration"]], "MySQL to CSV": [[225, "mysql-to-csv"], [225, "id2"]], "N-grams": [[212, "n-grams"]], "N-grams From Other Tokenizers": [[212, "n-grams-from-other-tokenizers"]], "N-grams, Collocations, Tf-idf and more": [[212, "n-grams-collocations-tf-idf-and-more"]], "Next Steps": [[206, "next-steps"]], "OSX (with brew)": [[206, "osx-with-brew"]], "Other": [[206, "other"]], "Other (optional)": [[206, "other-optional"]], "Other Lexica": [[1, "other-lexica"]], "Other Switches": [[9, "other-switches"], [10, "other-switches"], [11, "other-switches"], [12, "other-switches"], [13, "other-switches"], [14, "other-switches"], [15, "other-switches"], [16, "other-switches"], [17, "other-switches"], [18, "other-switches"], [19, "other-switches"], [20, "other-switches"], [21, "other-switches"], [22, "other-switches"], [23, "other-switches"], [24, "other-switches"], [25, "other-switches"], [26, "other-switches"], [27, "other-switches"], [28, "other-switches"], [29, "other-switches"], [30, "other-switches"], [31, "other-switches"], [32, "other-switches"], [33, "other-switches"], [34, "other-switches"], [35, "other-switches"], [36, "other-switches"], [37, "other-switches"], [39, "other-switches"], [40, "other-switches"], [41, "other-switches"], [42, "other-switches"], [43, "other-switches"], [44, "other-switches"], [45, "other-switches"], [46, "other-switches"], [47, "other-switches"], [48, "other-switches"], [49, "other-switches"], [51, "other-switches"], [52, "other-switches"], [53, "other-switches"], [54, "other-switches"], [56, "other-switches"], [57, "other-switches"], [58, "other-switches"], [59, "other-switches"], [60, "other-switches"], [62, "other-switches"], [64, "other-switches"], [65, "other-switches"], [66, "other-switches"], [67, "other-switches"], [68, "other-switches"], [69, "other-switches"], [70, "other-switches"], [72, "other-switches"], [73, "other-switches"], [76, "other-switches"], [77, "other-switches"], [78, "other-switches"], [79, "other-switches"], [80, "other-switches"], [81, "other-switches"], [82, "other-switches"], [83, "other-switches"], [84, "other-switches"], [85, "other-switches"], [86, "other-switches"], [87, "other-switches"], [89, "other-switches"], [90, "other-switches"], [91, "other-switches"], [92, "other-switches"], [94, "other-switches"], [98, "other-switches"], [99, "other-switches"], [101, "other-switches"], [102, "other-switches"], [103, "other-switches"], [104, "other-switches"], [105, "other-switches"], [106, "other-switches"], [109, "other-switches"], [110, "other-switches"], [111, "other-switches"], [112, "other-switches"], [113, "other-switches"], [114, "other-switches"], [115, "other-switches"], [116, "other-switches"], [117, "other-switches"], [118, "other-switches"], [119, "other-switches"], [120, "other-switches"], [121, "other-switches"], [122, "other-switches"], [123, "other-switches"], [124, "other-switches"], [125, "other-switches"], [126, "other-switches"], [127, "other-switches"], [128, "other-switches"], [130, "other-switches"], [132, "other-switches"], [133, "other-switches"], [134, "other-switches"], [135, "other-switches"], [136, "other-switches"], [137, "other-switches"], [138, "other-switches"], [140, "other-switches"], [141, "other-switches"], [142, "other-switches"], [143, "other-switches"], [145, "other-switches"], [147, "other-switches"], [148, "other-switches"], [150, "other-switches"], [151, "other-switches"], [152, "other-switches"], [153, "other-switches"], [154, "other-switches"], [155, "other-switches"], [156, "other-switches"], [157, "other-switches"], [158, "other-switches"], [159, "other-switches"], [160, "other-switches"], [161, "other-switches"], [162, "other-switches"], [164, "other-switches"], [165, "other-switches"], [166, "other-switches"], [167, "other-switches"], [168, "other-switches"], [169, "other-switches"], [169, "id1"], [170, "other-switches"], [171, "other-switches"], [172, "other-switches"], [173, "other-switches"], [174, "other-switches"], [177, "other-switches"], [179, "other-switches"], [180, "other-switches"], [181, "other-switches"], [182, "other-switches"], [183, "other-switches"], [184, "other-switches"], [186, "other-switches"], [186, "id1"], [187, "other-switches"], [188, "other-switches"], [189, "other-switches"], [190, "other-switches"], [191, "other-switches"], [193, "other-switches"], [194, "other-switches"], [194, "id1"], [195, "other-switches"], [196, "other-switches"], [197, "other-switches"], [198, "other-switches"], [199, "other-switches"], [200, "other-switches"], [201, "other-switches"], [202, "other-switches"], [204, "other-switches"]], "Other Topics": [[211, "other-topics"]], "Other switches": [[96, "other-switches"], [97, "other-switches"], [100, "other-switches"]], "Outcome Table": [[234, "outcome-table"]], "Outcomes": [[232, "outcomes"]], "Output": [[53, "output"]], "Output Feature table": [[234, "output-feature-table"]], "Output Formats": [[231, null]], "Output table": [[234, "output-table"]], "PERMA Lexicon": [[1, "perma-lexicon"]], "Packaged Datasets": [[1, null]], "Papers Utilizing DLATK": [[209, null]], "Part of Speech": [[212, "part-of-speech"]], "Part of Speech N-grams": [[212, "part-of-speech-n-grams"]], "Part of Speech Tagging": [[238, "part-of-speech-tagging"]], "Part of Speech Usage": [[212, "part-of-speech-usage"]], "Peer Reviewed Publications": [[209, "peer-reviewed-publications"]], "Pickles": [[231, "pickles"]], "Predict Regression To Feature Table": [[234, "predict-regression-to-feature-table"]], "Predict Regression To Output Table": [[234, "predict-regression-to-output-table"]], "Prediction": [[7, "prediction"], [211, "prediction"], [222, "prediction"], [236, "prediction"]], "Prediction / Classification Metrics": [[231, "prediction-classification-metrics"]], "Predictions": [[231, "predictions"]], "Predictive Lexica": [[236, "predictive-lexica"]], "Preprocessing": [[7, "preprocessing"]], "Prerequisites": [[213, "prerequisites"], [239, "prerequisites"]], "Print Word Clouds For A Topic Lexicon": [[231, "print-word-clouds-for-a-topic-lexicon"]], "Probabilities": [[231, "probabilities"]], "Python": [[206, "python"]], "Python (optional)": [[206, "python-optional"]], "Python Modules (optional)": [[206, "python-modules-optional"]], "Python version support": [[206, "python-version-support"]], "Random Sample": [[237, "random-sample"]], "Real World Example": [[219, "real-world-example"]], "Recommended Install": [[206, "recommended-install"]], "References": [[46, "references"], [168, "references"]], "Regression": [[7, "regression"]], "Removing URLs and @-mentions": [[219, "removing-urls-and-mentions"]], "Required Switches": [[234, "required-switches"], [234, "id2"]], "Run from Docker Hub": [[223, "run-from-docker-hub"]], "Running DLA with an interaction term": [[227, "running-dla-with-an-interaction-term"]], "SQLite": [[220, "sqlite"]], "STEP 0 - Prepare": [[221, "step-0-prepare"]], "STEP 1 - Feature Extraction": [[221, "step-1-feature-extraction"]], "STEP 2 - Insights (DLA): Correlate features with outcomes": [[221, "step-2-insights-dla-correlate-features-with-outcomes"]], "STEP 3 - Prediction, Classification and Predictive Lexica": [[236, "step-3-prediction-classification-and-predictive-lexica"]], "Sample Command": [[234, "sample-command"], [234, "id1"]], "Sample Datasets": [[206, "sample-datasets"]], "Second Pass": [[235, "second-pass"]], "Segmentation with the Stanford Segmenter": [[238, "segmentation-with-the-stanford-segmenter"]], "Sentence Tokenization": [[238, "sentence-tokenization"]], "Setup": [[7, "setup"], [206, "setup"]], "Show Feature Tables": [[237, "show-feature-tables"]], "Show Tables": [[237, "show-tables"]], "Spam Filtering": [[219, "spam-filtering"]], "Spanish PERMA Lexicon": [[1, "spanish-perma-lexicon"]], "Standalone Script": [[225, "standalone-script"]], "Stanford Parser": [[238, "stanford-parser"]], "Step 0: Get Access To Mallet": [[229, "step-0-get-access-to-mallet"]], "Step 0: Setup": [[228, "step-0-setup"]], "Step 1 - Clustering": [[215, "step-1-clustering"]], "Step 1 - Import Data": [[218, "step-1-import-data"]], "Step 1: (If necessary) Create sample tweet table": [[228, "step-1-if-necessary-create-sample-tweet-table"], [229, "step-1-if-necessary-create-sample-tweet-table"]], "Step 1: Install Docker": [[223, "step-1-install-docker"]], "Step 1a: Fit Reducer": [[215, "step-1a-fit-reducer"]], "Step 1b: Reducer to lexicon": [[215, "step-1b-reducer-to-lexicon"]], "Step 2 - Correlate Features with Outcomes": [[218, "step-2-correlate-features-with-outcomes"]], "Step 2 - Extract Features with DLATK": [[218, "step-2-extract-features-with-dlatk"]], "Step 2, option A: Create tokenized table in mySQL and Export it": [[229, "step-2-option-a-create-tokenized-table-in-mysql-and-export-it"]], "Step 2, option B: Generate a feature table and convert it to a mallet-appropriate formatted text file": [[229, "step-2-option-b-generate-a-feature-table-and-convert-it-to-a-mallet-appropriate-formatted-text-file"]], "Step 2: Generate a feature table": [[228, "step-2-generate-a-feature-table"]], "Step 2: Install MySQL": [[223, "step-2-install-mysql"]], "Step 2: Super Topics": [[215, "step-2-super-topics"]], "Step 3: Estimate LDA topics": [[228, "step-3-estimate-lda-topics"]], "Step 3: Format for Mallet": [[229, "step-3-format-for-mallet"]], "Step 3: Link MySQL and DLATK": [[223, "step-3-link-mysql-and-dlatk"]], "Step 3: Using your super topics": [[215, "step-3-using-your-super-topics"]], "Step 4: Extract features from lexicon": [[228, "step-4-extract-features-from-lexicon"]], "Step 4: Run LDA with Mallet": [[229, "step-4-run-lda-with-mallet"]], "Step 5: Add message ID\u2019s to state file": [[229, "step-5-add-message-ids-to-state-file"]], "Step 6: Import state file into database": [[229, "step-6-import-state-file-into-database"]], "Step 7: Create topic-word distributions": [[229, "step-7-create-topic-word-distributions"]], "Step 8: Add topic-lexicon to lexicon database": [[229, "step-8-add-topic-lexicon-to-lexicon-database"]], "Step 9: Extract features from lexicon": [[229, "step-9-extract-features-from-lexicon"]], "Structure": [[224, "structure"]], "Submodules": [[2, "submodules"], [3, "submodules"], [4, "submodules"], [5, "submodules"]], "Subpackages": [[2, "subpackages"]], "Switch": [[9, "switch"], [10, "switch"], [11, "switch"], [12, "switch"], [13, "switch"], [14, "switch"], [15, "switch"], [16, "switch"], [17, "switch"], [18, "switch"], [19, "switch"], [20, "switch"], [21, "switch"], [22, "switch"], [23, "switch"], [24, "switch"], [25, "switch"], [26, "switch"], [27, "switch"], [28, "switch"], [29, "switch"], [30, "switch"], [31, "switch"], [32, "switch"], [33, "switch"], [34, "switch"], [35, "switch"], [36, "switch"], [37, "switch"], [38, "switch"], [39, "switch"], [40, "switch"], [41, "switch"], [42, "switch"], [43, "switch"], [44, "switch"], [45, "switch"], [46, "switch"], [47, "switch"], [48, "switch"], [49, "switch"], [50, "switch"], [51, "switch"], [52, "switch"], [53, "switch"], [54, "switch"], [55, "switch"], [56, "switch"], [57, "switch"], [58, "switch"], [59, "switch"], [60, "switch"], [61, "switch"], [62, "switch"], [63, "switch"], [64, "switch"], [65, "switch"], [66, "switch"], [67, "switch"], [68, "switch"], [69, "switch"], [70, "switch"], [71, "switch"], [72, "switch"], [73, "switch"], [74, "switch"], [75, "switch"], [76, "switch"], [77, "switch"], [78, "switch"], [79, "switch"], [80, "switch"], [81, "switch"], [82, "switch"], [83, "switch"], [84, "switch"], [85, "switch"], [86, "switch"], [87, "switch"], [88, "switch"], [89, "switch"], [90, "switch"], [91, "switch"], [92, "switch"], [93, "switch"], [94, "switch"], [95, "switch"], [96, "switch"], [97, "switch"], [98, "switch"], [99, "switch"], [100, "switch"], [101, "switch"], [102, "switch"], [103, "switch"], [104, "switch"], [105, "switch"], [106, "switch"], [107, "switch"], [108, "switch"], [109, "switch"], [110, "switch"], [111, "switch"], [112, "switch"], [113, "switch"], [114, "switch"], [115, "switch"], [116, "switch"], [117, "switch"], [118, "switch"], [119, "switch"], [120, "switch"], [121, "switch"], [122, "switch"], [123, "switch"], [124, "switch"], [125, "switch"], [126, "switch"], [127, "switch"], [128, "switch"], [129, "switch"], [130, "switch"], [131, "switch"], [132, "switch"], [133, "switch"], [134, "switch"], [135, "switch"], [136, "switch"], [137, "switch"], [138, "switch"], [139, "switch"], [140, "switch"], [141, "switch"], [142, "switch"], [143, "switch"], [144, "switch"], [145, "switch"], [146, "switch"], [147, "switch"], [148, "switch"], [149, "switch"], [150, "switch"], [151, "switch"], [152, "switch"], [153, "switch"], [154, "switch"], [155, "switch"], [156, "switch"], [157, "switch"], [158, "switch"], [159, "switch"], [160, "switch"], [161, "switch"], [162, "switch"], [163, "switch"], [164, "switch"], [165, "switch"], [166, "switch"], [167, "switch"], [168, "switch"], [169, "switch"], [170, "switch"], [171, "switch"], [172, "switch"], [173, "switch"], [174, "switch"], [175, "switch"], [176, "switch"], [177, "switch"], [178, "switch"], [179, "switch"], [180, "switch"], [181, "switch"], [182, "switch"], [183, "switch"], [184, "switch"], [185, "switch"], [186, "switch"], [187, "switch"], [188, "switch"], [189, "switch"], [190, "switch"], [191, "switch"], [192, "switch"], [193, "switch"], [194, "switch"], [195, "switch"], [196, "switch"], [197, "switch"], [198, "switch"], [199, "switch"], [200, "switch"], [201, "switch"], [202, "switch"], [203, "switch"], [204, "switch"]], "TF-IDF Tables": [[212, "tf-idf-tables"]], "Text Cleaning and Transformations": [[211, "text-cleaning-and-transformations"]], "Third Pass": [[235, "third-pass"]], "Tokenization": [[238, "tokenization"]], "Tokenization, Part of Speech Tagging and Segmentation": [[238, null]], "Topic Clouds": [[231, "topic-clouds"]], "Training A Model": [[235, "training-a-model"]], "Transformed Tables": [[212, "transformed-tables"]], "Transformers in DLATK (Huggingface Interface)": [[239, null]], "Tutorials": [[211, null]], "TweetNLP Part of Speech Tags": [[238, "tweetnlp-part-of-speech-tags"]], "TweetNLP Tokenizer": [[238, "tweetnlp-tokenizer"]], "Under the hood": [[215, "under-the-hood"]], "Understanding Feature Table Names": [[224, null]], "Unigrams": [[212, "unigrams"]], "Using DLATK to view your SQL data": [[237, null]], "Using FeatureStar": [[214, "using-featurestar"]], "Using INI Files": [[226, null]], "Using Python": [[225, "using-python"]], "Using an init file via the command line": [[226, "using-an-init-file-via-the-command-line"]], "Using an init file with classes": [[226, "using-an-init-file-with-classes"]], "Using two continuous variables": [[227, "using-two-continuous-variables"]], "Video Tutorials": [[211, "video-tutorials"]], "View Table Data": [[237, "view-table-data"]], "Viewing and Describing Tables": [[237, "viewing-and-describing-tables"]], "Viewing your data and output": [[211, "viewing-your-data-and-output"]], "Visualization": [[7, "visualization"]], "Word Clouds": [[231, "word-clouds"]], "Word Tables": [[212, "word-tables"]], "Working with DLATK's Classes": [[214, null]], "Working with classes": [[214, "working-with-classes"]], "dlatk": [[208, null]], "dlatk package": [[2, null]], "dlatk.DDLA module": [[2, "dlatk-ddla-module"]], "dlatk.LexicaInterface package": [[3, null]], "dlatk.LexicaInterface.addMessageID module": [[3, "dlatk-lexicainterface-addmessageid-module"]], "dlatk.LexicaInterface.ldaExtractor module": [[3, "dlatk-lexicainterface-ldaextractor-module"]], "dlatk.LexicaInterface.lexInterface module": [[3, "dlatk-lexicainterface-lexinterface-module"]], "dlatk.classifyPredictor module": [[2, "dlatk-classifypredictor-module"]], "dlatk.clustering module": [[2, "dlatk-clustering-module"]], "dlatk.featureExtractor module": [[2, "dlatk-featureextractor-module"]], "dlatk.featureGetter module": [[2, "dlatk-featuregetter-module"]], "dlatk.featureRefiner module": [[2, "dlatk-featurerefiner-module"]], "dlatk.featureStar module": [[2, "dlatk-featurestar-module"]], "dlatk.featureWorker module": [[2, "dlatk-featureworker-module"]], "dlatk.fwConstants module": [[2, "dlatk-fwconstants-module"]], "dlatk.lib package": [[4, null]], "dlatk.lib.StanfordParser module": [[4, "dlatk-lib-stanfordparser-module"]], "dlatk.lib.TweetNLP module": [[4, "dlatk-lib-tweetnlp-module"]], "dlatk.lib.descStats module": [[4, "dlatk-lib-descstats-module"]], "dlatk.lib.happierfuntokenizing module": [[4, "dlatk-lib-happierfuntokenizing-module"]], "dlatk.lib.notify module": [[4, "dlatk-lib-notify-module"]], "dlatk.lib.wordcloud module": [[4, "dlatk-lib-wordcloud-module"]], "dlatk.mediation module": [[2, "dlatk-mediation-module"]], "dlatk.mysqlMethods package": [[5, null]], "dlatk.mysqlMethods.mysqlMethods module": [[5, "dlatk-mysqlmethods-mysqlmethods-module"]], "dlatk.mysqlMethods.mysql_iter_funcs module": [[5, "dlatk-mysqlmethods-mysql-iter-funcs-module"]], "dlatk.occurrenceSelection module": [[2, "dlatk-occurrenceselection-module"]], "dlatk.outcomeAnalyzer module": [[2, "dlatk-outcomeanalyzer-module"]], "dlatk.outcomeGetter module": [[2, "dlatk-outcomegetter-module"]], "dlatk.pca_mod module": [[2, "dlatk-pca-mod-module"]], "dlatk.regressionPredictor module": [[2, "dlatk-regressionpredictor-module"]], "dlatk.semanticsExtractor module": [[2, "dlatk-semanticsextractor-module"]], "dlatkInterface Flags by type": [[7, null]], "dlatkInterface module": [[6, null]], "setup module": [[210, null]]}, "docnames": ["changelog", "datasets", "dlatk", "dlatk.LexicaInterface", "dlatk.lib", "dlatk.mysqlMethods", "dlatkInterface", "dlatkinterface_ordered", "fwinterface", "fwinterface/fwflag_AUC", "fwinterface/fwflag_IDP", "fwinterface/fwflag_add_bert", "fwinterface/fwflag_add_corp_lex_table", "fwinterface/fwflag_add_emb", "fwinterface/fwflag_add_lda_messages", "fwinterface/fwflag_add_lex_table", "fwinterface/fwflag_add_ngrams", "fwinterface/fwflag_add_ngrams_from_tokenized", "fwinterface/fwflag_add_parses", "fwinterface/fwflag_add_pos_ngram_table", "fwinterface/fwflag_add_pos_table", "fwinterface/fwflag_add_segmented", "fwinterface/fwflag_add_sent_per_row", "fwinterface/fwflag_add_sent_tokenized", "fwinterface/fwflag_add_tokenized", "fwinterface/fwflag_add_tweetpos", "fwinterface/fwflag_add_tweettok", "fwinterface/fwflag_aggregate_feats_by_new_group", "fwinterface/fwflag_all_controls_only", "fwinterface/fwflag_anscombe", "fwinterface/fwflag_barplot", "fwinterface/fwflag_bert_layer_aggregation", "fwinterface/fwflag_bert_layers", "fwinterface/fwflag_bert_model", "fwinterface/fwflag_bert_msg_aggregation", "fwinterface/fwflag_blacklist", "fwinterface/fwflag_boolean", "fwinterface/fwflag_bootstrapp", "fwinterface/fwflag_c", "fwinterface/fwflag_categorical", "fwinterface/fwflag_cca", "fwinterface/fwflag_cca_outcomes_vs_controls", "fwinterface/fwflag_cca_penalty_feats", "fwinterface/fwflag_cca_penalty_outcomes", "fwinterface/fwflag_cca_permute", "fwinterface/fwflag_cca_predict_components", "fwinterface/fwflag_classification_to_lexicon", "fwinterface/fwflag_clean_messages", "fwinterface/fwflag_cohens_d", "fwinterface/fwflag_colabify", "fwinterface/fwflag_colloc_table", "fwinterface/fwflag_combine_feat_tables", "fwinterface/fwflag_combo_test_classifiers", "fwinterface/fwflag_combo_test_regression", "fwinterface/fwflag_control_adjust_outcomes_regression", "fwinterface/fwflag_control_combo_sizes", "fwinterface/fwflag_corp_topic_tagcloud", "fwinterface/fwflag_correlate", "fwinterface/fwflag_create_rand_group_sample", "fwinterface/fwflag_create_rand_sample", "fwinterface/fwflag_csv", "fwinterface/fwflag_d", "fwinterface/fwflag_date_field", "fwinterface/fwflag_db_engine", "fwinterface/fwflag_deduplicate", "fwinterface/fwflag_desc_tables", "fwinterface/fwflag_descplot", "fwinterface/fwflag_emb_layer_aggregation.rst", "fwinterface/fwflag_emb_layers", "fwinterface/fwflag_emb_model", "fwinterface/fwflag_emb_msg_aggregation", "fwinterface/fwflag_encoding", "fwinterface/fwflag_estimate_lda_topics", "fwinterface/fwflag_extension", "fwinterface/fwflag_f", "fwinterface/fwflag_f.", "fwinterface/fwflag_feat_as_control", "fwinterface/fwflag_feat_as_outcome", "fwinterface/fwflag_feat_as_path_start", "fwinterface/fwflag_feat_blacklist", "fwinterface/fwflag_feat_colloc_filter", "fwinterface/fwflag_feat_correl_filter", "fwinterface/fwflag_feat_flexibin", "fwinterface/fwflag_feat_names", "fwinterface/fwflag_feat_occ_filter", "fwinterface/fwflag_feat_whitelist", "fwinterface/fwflag_feature_selection", "fwinterface/fwflag_feature_selection_string", "fwinterface/fwflag_feature_type_name", "fwinterface/fwflag_fit_reducer", "fwinterface/fwflag_flexiplot_file", "fwinterface/fwflag_folds", "fwinterface/fwflag_freq", "fwinterface/fwflag_from_file", "fwinterface/fwflag_group_freq_thresh", "fwinterface/fwflag_include_sub_collocs", "fwinterface/fwflag_interaction_ddla", "fwinterface/fwflag_interaction_ddla_pvalue", "fwinterface/fwflag_interactions", "fwinterface/fwflag_keep_low_variance_outcomes", "fwinterface/fwflag_l", "fwinterface/fwflag_language_filter", "fwinterface/fwflag_lda_alpha", "fwinterface/fwflag_lda_beta", "fwinterface/fwflag_lda_iterations", "fwinterface/fwflag_lda_lexicon_name", "fwinterface/fwflag_lex_anscombe", "fwinterface/fwflag_lex_interface", "fwinterface/fwflag_lexicondb", "fwinterface/fwflag_load_model", "fwinterface/fwflag_loessplot", "fwinterface/fwflag_log", "fwinterface/fwflag_logistic_reg", "fwinterface/fwflag_ls", "fwinterface/fwflag_make_topic_wordclouds", "fwinterface/fwflag_make_wordclouds", "fwinterface/fwflag_mallet_path", "fwinterface/fwflag_max_tagcloud_words", "fwinterface/fwflag_mediation", "fwinterface/fwflag_mediation_boot", "fwinterface/fwflag_mediation_boot_num", "fwinterface/fwflag_mediation_csv", "fwinterface/fwflag_mediation_method", "fwinterface/fwflag_mediation_no_summary", "fwinterface/fwflag_mediators", "fwinterface/fwflag_message_field", "fwinterface/fwflag_messageid_field", "fwinterface/fwflag_model", "fwinterface/fwflag_multiclass", "fwinterface/fwflag_mysql_config_file", "fwinterface/fwflag_n_components", "fwinterface/fwflag_no_correction", "fwinterface/fwflag_no_features", "fwinterface/fwflag_no_lang", "fwinterface/fwflag_no_lda_lexicon", "fwinterface/fwflag_no_lda_stopping", "fwinterface/fwflag_no_metafeats", "fwinterface/fwflag_no_standardize", "fwinterface/fwflag_no_tagcloud_filter", "fwinterface/fwflag_no_unicode", "fwinterface/fwflag_num_stopwords", "fwinterface/fwflag_num_topics", "fwinterface/fwflag_nvalue", "fwinterface/fwflag_outcome_controls", "fwinterface/fwflag_outcome_fields", "fwinterface/fwflag_outcome_interaction", "fwinterface/fwflag_outcome_table", "fwinterface/fwflag_outcome_with_outcome", "fwinterface/fwflag_outcome_with_outcome_only", "fwinterface/fwflag_outcomes", "fwinterface/fwflag_outliers_to_mean", "fwinterface/fwflag_output_name", "fwinterface/fwflag_p_correction", "fwinterface/fwflag_p_value", "fwinterface/fwflag_path_starts", "fwinterface/fwflag_picklefile", "fwinterface/fwflag_predict_classification_to_outcome_table", "fwinterface/fwflag_predict_classifiers", "fwinterface/fwflag_predict_classifiers_to_feats", "fwinterface/fwflag_predict_probabilities_to_feats", "fwinterface/fwflag_predict_regression", "fwinterface/fwflag_predict_regression_to_feats", "fwinterface/fwflag_predict_regression_to_outcome_table", "fwinterface/fwflag_prediction_csv", "fwinterface/fwflag_print_joined_feature_lines", "fwinterface/fwflag_print_tokenized_lines", "fwinterface/fwflag_reduced_lexicon", "fwinterface/fwflag_reducer_to_lexicon", "fwinterface/fwflag_regression_to_lexicon", "fwinterface/fwflag_rmatrix", "fwinterface/fwflag_roc", "fwinterface/fwflag_save_lda_files", "fwinterface/fwflag_save_model", "fwinterface/fwflag_scatterplot", "fwinterface/fwflag_segmentation_model", "fwinterface/fwflag_set_p_occ", "fwinterface/fwflag_set_pmi_threshold", "fwinterface/fwflag_show_tables", "fwinterface/fwflag_sort", "fwinterface/fwflag_spam_filter", "fwinterface/fwflag_sparse", "fwinterface/fwflag_spearman", "fwinterface/fwflag_sqrt", "fwinterface/fwflag_stratify_folds", "fwinterface/fwflag_super_topics", "fwinterface/fwflag_t", "fwinterface/fwflag_tagcloud", "fwinterface/fwflag_tagcloud_colorscheme", "fwinterface/fwflag_tagcloud_filter", "fwinterface/fwflag_test_classifiers", "fwinterface/fwflag_test_regression", "fwinterface/fwflag_tf_idf", "fwinterface/fwflag_to_file", "fwinterface/fwflag_topic_lexicon", "fwinterface/fwflag_topic_tagcloud", "fwinterface/fwflag_train_classifiers", "fwinterface/fwflag_train_regression", "fwinterface/fwflag_ttest_feat_tables", "fwinterface/fwflag_use_collocs", "fwinterface/fwflag_view_tables", "fwinterface/fwflag_weighted_lexicon", "fwinterface/fwflag_where", "fwinterface/fwflag_whitelist", "fwinterface/fwflag_word_table", "fwinterface/fwflag_zScoreGroup", "index", "install", "install_faq", "modules", "papers", "setup", "tutorials", "tutorials/tut_adv_fe", "tutorials/tut_bert", "tutorials/tut_classes", "tutorials/tut_clustering", "tutorials/tut_colloc", "tutorials/tut_conda", "tutorials/tut_convokit", "tutorials/tut_data_cleaning", "tutorials/tut_dataengine", "tutorials/tut_dla", "tutorials/tut_dla_rot", "tutorials/tut_docker", "tutorials/tut_feat_tables", "tutorials/tut_import_methods", "tutorials/tut_ini_files", "tutorials/tut_interactions", "tutorials/tut_lda", "tutorials/tut_lda_full", "tutorials/tut_mediation", "tutorials/tut_output", "tutorials/tut_pandas", "tutorials/tut_pickle", "tutorials/tut_pickle_apply", "tutorials/tut_pickle_build", "tutorials/tut_pred", "tutorials/tut_sql_commands", "tutorials/tut_text_transformations", "tutorials/tut_trns"], "envversion": {"sphinx": 64, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.viewcode": 1}, "filenames": ["changelog.rst", "datasets.rst", "dlatk.rst", "dlatk.LexicaInterface.rst", "dlatk.lib.rst", "dlatk.mysqlMethods.rst", "dlatkInterface.rst", "dlatkinterface_ordered.rst", "fwinterface.rst", "fwinterface/fwflag_AUC.rst", "fwinterface/fwflag_IDP.rst", "fwinterface/fwflag_add_bert.rst", "fwinterface/fwflag_add_corp_lex_table.rst", "fwinterface/fwflag_add_emb.rst", "fwinterface/fwflag_add_lda_messages.rst", "fwinterface/fwflag_add_lex_table.rst", "fwinterface/fwflag_add_ngrams.rst", "fwinterface/fwflag_add_ngrams_from_tokenized.rst", "fwinterface/fwflag_add_parses.rst", "fwinterface/fwflag_add_pos_ngram_table.rst", "fwinterface/fwflag_add_pos_table.rst", "fwinterface/fwflag_add_segmented.rst", "fwinterface/fwflag_add_sent_per_row.rst", "fwinterface/fwflag_add_sent_tokenized.rst", "fwinterface/fwflag_add_tokenized.rst", "fwinterface/fwflag_add_tweetpos.rst", "fwinterface/fwflag_add_tweettok.rst", "fwinterface/fwflag_aggregate_feats_by_new_group.rst", "fwinterface/fwflag_all_controls_only.rst", "fwinterface/fwflag_anscombe.rst", "fwinterface/fwflag_barplot.rst", "fwinterface/fwflag_bert_layer_aggregation.rst", "fwinterface/fwflag_bert_layers.rst", "fwinterface/fwflag_bert_model.rst", "fwinterface/fwflag_bert_msg_aggregation.rst", "fwinterface/fwflag_blacklist.rst", "fwinterface/fwflag_boolean.rst", "fwinterface/fwflag_bootstrapp.rst", "fwinterface/fwflag_c.rst", "fwinterface/fwflag_categorical.rst", "fwinterface/fwflag_cca.rst", "fwinterface/fwflag_cca_outcomes_vs_controls.rst", "fwinterface/fwflag_cca_penalty_feats.rst", "fwinterface/fwflag_cca_penalty_outcomes.rst", "fwinterface/fwflag_cca_permute.rst", "fwinterface/fwflag_cca_predict_components.rst", "fwinterface/fwflag_classification_to_lexicon.rst", "fwinterface/fwflag_clean_messages.rst", "fwinterface/fwflag_cohens_d.rst", "fwinterface/fwflag_colabify.rst", "fwinterface/fwflag_colloc_table.rst", "fwinterface/fwflag_combine_feat_tables.rst", "fwinterface/fwflag_combo_test_classifiers.rst", "fwinterface/fwflag_combo_test_regression.rst", "fwinterface/fwflag_control_adjust_outcomes_regression.rst", "fwinterface/fwflag_control_combo_sizes.rst", "fwinterface/fwflag_corp_topic_tagcloud.rst", "fwinterface/fwflag_correlate.rst", "fwinterface/fwflag_create_rand_group_sample.rst", "fwinterface/fwflag_create_rand_sample.rst", "fwinterface/fwflag_csv.rst", "fwinterface/fwflag_d.rst", "fwinterface/fwflag_date_field.rst", "fwinterface/fwflag_db_engine.rst", "fwinterface/fwflag_deduplicate.rst", "fwinterface/fwflag_desc_tables.rst", "fwinterface/fwflag_descplot.rst", "fwinterface/fwflag_emb_layer_aggregation.rst.rst", "fwinterface/fwflag_emb_layers.rst", "fwinterface/fwflag_emb_model.rst", "fwinterface/fwflag_emb_msg_aggregation.rst", "fwinterface/fwflag_encoding.rst", "fwinterface/fwflag_estimate_lda_topics.rst", "fwinterface/fwflag_extension.rst", "fwinterface/fwflag_f.rst", "fwinterface/fwflag_f..rst", "fwinterface/fwflag_feat_as_control.rst", "fwinterface/fwflag_feat_as_outcome.rst", "fwinterface/fwflag_feat_as_path_start.rst", "fwinterface/fwflag_feat_blacklist.rst", "fwinterface/fwflag_feat_colloc_filter.rst", "fwinterface/fwflag_feat_correl_filter.rst", "fwinterface/fwflag_feat_flexibin.rst", "fwinterface/fwflag_feat_names.rst", "fwinterface/fwflag_feat_occ_filter.rst", "fwinterface/fwflag_feat_whitelist.rst", "fwinterface/fwflag_feature_selection.rst", "fwinterface/fwflag_feature_selection_string.rst", "fwinterface/fwflag_feature_type_name.rst", "fwinterface/fwflag_fit_reducer.rst", "fwinterface/fwflag_flexiplot_file.rst", "fwinterface/fwflag_folds.rst", "fwinterface/fwflag_freq.rst", "fwinterface/fwflag_from_file.rst", "fwinterface/fwflag_group_freq_thresh.rst", "fwinterface/fwflag_include_sub_collocs.rst", "fwinterface/fwflag_interaction_ddla.rst", "fwinterface/fwflag_interaction_ddla_pvalue.rst", "fwinterface/fwflag_interactions.rst", "fwinterface/fwflag_keep_low_variance_outcomes.rst", "fwinterface/fwflag_l.rst", "fwinterface/fwflag_language_filter.rst", "fwinterface/fwflag_lda_alpha.rst", "fwinterface/fwflag_lda_beta.rst", "fwinterface/fwflag_lda_iterations.rst", "fwinterface/fwflag_lda_lexicon_name.rst", "fwinterface/fwflag_lex_anscombe.rst", "fwinterface/fwflag_lex_interface.rst", "fwinterface/fwflag_lexicondb.rst", "fwinterface/fwflag_load_model.rst", "fwinterface/fwflag_loessplot.rst", "fwinterface/fwflag_log.rst", "fwinterface/fwflag_logistic_reg.rst", "fwinterface/fwflag_ls.rst", "fwinterface/fwflag_make_topic_wordclouds.rst", "fwinterface/fwflag_make_wordclouds.rst", "fwinterface/fwflag_mallet_path.rst", "fwinterface/fwflag_max_tagcloud_words.rst", "fwinterface/fwflag_mediation.rst", "fwinterface/fwflag_mediation_boot.rst", "fwinterface/fwflag_mediation_boot_num.rst", "fwinterface/fwflag_mediation_csv.rst", "fwinterface/fwflag_mediation_method.rst", "fwinterface/fwflag_mediation_no_summary.rst", "fwinterface/fwflag_mediators.rst", "fwinterface/fwflag_message_field.rst", "fwinterface/fwflag_messageid_field.rst", "fwinterface/fwflag_model.rst", "fwinterface/fwflag_multiclass.rst", "fwinterface/fwflag_mysql_config_file.rst", "fwinterface/fwflag_n_components.rst", "fwinterface/fwflag_no_correction.rst", "fwinterface/fwflag_no_features.rst", "fwinterface/fwflag_no_lang.rst", "fwinterface/fwflag_no_lda_lexicon.rst", "fwinterface/fwflag_no_lda_stopping.rst", "fwinterface/fwflag_no_metafeats.rst", "fwinterface/fwflag_no_standardize.rst", "fwinterface/fwflag_no_tagcloud_filter.rst", "fwinterface/fwflag_no_unicode.rst", "fwinterface/fwflag_num_stopwords.rst", "fwinterface/fwflag_num_topics.rst", "fwinterface/fwflag_nvalue.rst", "fwinterface/fwflag_outcome_controls.rst", "fwinterface/fwflag_outcome_fields.rst", "fwinterface/fwflag_outcome_interaction.rst", "fwinterface/fwflag_outcome_table.rst", "fwinterface/fwflag_outcome_with_outcome.rst", "fwinterface/fwflag_outcome_with_outcome_only.rst", "fwinterface/fwflag_outcomes.rst", "fwinterface/fwflag_outliers_to_mean.rst", "fwinterface/fwflag_output_name.rst", "fwinterface/fwflag_p_correction.rst", "fwinterface/fwflag_p_value.rst", "fwinterface/fwflag_path_starts.rst", "fwinterface/fwflag_picklefile.rst", "fwinterface/fwflag_predict_classification_to_outcome_table.rst", "fwinterface/fwflag_predict_classifiers.rst", "fwinterface/fwflag_predict_classifiers_to_feats.rst", "fwinterface/fwflag_predict_probabilities_to_feats.rst", "fwinterface/fwflag_predict_regression.rst", "fwinterface/fwflag_predict_regression_to_feats.rst", "fwinterface/fwflag_predict_regression_to_outcome_table.rst", "fwinterface/fwflag_prediction_csv.rst", "fwinterface/fwflag_print_joined_feature_lines.rst", "fwinterface/fwflag_print_tokenized_lines.rst", "fwinterface/fwflag_reduced_lexicon.rst", "fwinterface/fwflag_reducer_to_lexicon.rst", "fwinterface/fwflag_regression_to_lexicon.rst", "fwinterface/fwflag_rmatrix.rst", "fwinterface/fwflag_roc.rst", "fwinterface/fwflag_save_lda_files.rst", "fwinterface/fwflag_save_model.rst", "fwinterface/fwflag_scatterplot.rst", "fwinterface/fwflag_segmentation_model.rst", "fwinterface/fwflag_set_p_occ.rst", "fwinterface/fwflag_set_pmi_threshold.rst", "fwinterface/fwflag_show_tables.rst", "fwinterface/fwflag_sort.rst", "fwinterface/fwflag_spam_filter.rst", "fwinterface/fwflag_sparse.rst", "fwinterface/fwflag_spearman.rst", "fwinterface/fwflag_sqrt.rst", "fwinterface/fwflag_stratify_folds.rst", "fwinterface/fwflag_super_topics.rst", "fwinterface/fwflag_t.rst", "fwinterface/fwflag_tagcloud.rst", "fwinterface/fwflag_tagcloud_colorscheme.rst", "fwinterface/fwflag_tagcloud_filter.rst", "fwinterface/fwflag_test_classifiers.rst", "fwinterface/fwflag_test_regression.rst", "fwinterface/fwflag_tf_idf.rst", "fwinterface/fwflag_to_file.rst", "fwinterface/fwflag_topic_lexicon.rst", "fwinterface/fwflag_topic_tagcloud.rst", "fwinterface/fwflag_train_classifiers.rst", "fwinterface/fwflag_train_regression.rst", "fwinterface/fwflag_ttest_feat_tables.rst", "fwinterface/fwflag_use_collocs.rst", "fwinterface/fwflag_view_tables.rst", "fwinterface/fwflag_weighted_lexicon.rst", "fwinterface/fwflag_where.rst", "fwinterface/fwflag_whitelist.rst", "fwinterface/fwflag_word_table.rst", "fwinterface/fwflag_zScoreGroup.rst", "index.rst", "install.rst", "install_faq.rst", "modules.rst", "papers.rst", "setup.rst", "tutorials.rst", "tutorials/tut_adv_fe.rst", "tutorials/tut_bert.rst", "tutorials/tut_classes.rst", "tutorials/tut_clustering.rst", "tutorials/tut_colloc.rst", "tutorials/tut_conda.rst", "tutorials/tut_convokit.rst", "tutorials/tut_data_cleaning.rst", "tutorials/tut_dataengine.rst", "tutorials/tut_dla.rst", "tutorials/tut_dla_rot.rst", "tutorials/tut_docker.rst", "tutorials/tut_feat_tables.rst", "tutorials/tut_import_methods.rst", "tutorials/tut_ini_files.rst", "tutorials/tut_interactions.rst", "tutorials/tut_lda.rst", "tutorials/tut_lda_full.rst", "tutorials/tut_mediation.rst", "tutorials/tut_output.rst", "tutorials/tut_pandas.rst", "tutorials/tut_pickle.rst", "tutorials/tut_pickle_apply.rst", "tutorials/tut_pickle_build.rst", "tutorials/tut_pred.rst", "tutorials/tut_sql_commands.rst", "tutorials/tut_text_transformations.rst", "tutorials/tut_trns.rst"], "indexentries": {"dlatk": [[2, "module-dlatk", false]], "module": [[2, "module-dlatk", false]]}, "objects": {"": [[2, 0, 0, "-", "dlatk"]]}, "objnames": {"0": ["py", "module", "Python module"]}, "objtypes": {"0": "py:module"}, "terms": {"": [1, 15, 16, 18, 21, 24, 25, 26, 38, 41, 48, 49, 57, 61, 74, 80, 96, 106, 107, 108, 128, 137, 152, 164, 189, 190, 192, 195, 196, 203, 204, 205, 209, 211, 212, 213, 218, 221, 223, 224, 226, 235, 236, 238, 239], "0": [9, 14, 18, 25, 27, 34, 35, 40, 41, 42, 43, 45, 52, 53, 70, 79, 80, 84, 85, 87, 93, 94, 96, 97, 99, 102, 103, 128, 135, 138, 153, 157, 164, 179, 188, 191, 192, 195, 196, 198, 199, 201, 202, 212, 213, 215, 218, 219, 220, 223, 224, 225, 226, 227, 231, 232, 234, 235, 236, 237, 238, 239], "00": [53, 199, 209, 213, 223, 231, 235, 237, 239], "000": [1, 212], "00000": 236, "000000": [232, 235, 236], "0000000217525421774642": 212, "0000007502882982786135": 27, "000000921854579604825": 215, "0000011117948649530572": 27, "0000012686121256484195": 27, "0000016047294586605644": 27, "00000232305243540397": 215, "0000026320123388738445": 27, "000005261560964829973": 27, "000006096408605690388": 27, "00000e": [53, 231, 235], "00001": 236, "000013396794444795903": 27, "00001484692817056151": 27, "0000182426537148019": 27, "000019275622120703946": 27, "000019890601690701143": 27, "000019987607683236393": 27, "00002283123484160593": 27, "00003332777870354941": 27, "000036302911493501776": 27, "0000368626647544864": 215, "000037435667062561665": 27, "000040645449741901396": 27, "00006541063856000905": 215, "0000711541198235": [212, 221], "0000762679547477": 221, "0000878334772103": [191, 212], "0001": [215, 235, 236], "000112631240734": 227, "000141436336165": [191, 212], "000150407662892745": 212, "000161019216334877": 215, "000162284972412": [212, 221], "000218674830527": 221, "000253421187886": [221, 231], "00026": 232, "000260010400416017": 221, "000283381640611496": 215, "000299298548129527": 212, "000334689956064": [191, 212], "000337894917181": [221, 231], "0003415147203434118": 215, "00040225261464199515": 27, "000479616306954436": 212, "000518033494791095": 215, "000520020800832": [212, 221], "000545379245206831": 212, "000556947925369": [212, 221], "000677": 232, "000780": 232, "00078003120124805": 221, "000827587016091": [191, 212], "000859845227858985": 218, "00086305723986972909": 235, "000872790748418": 221, "000952834755272": 212, "000953288846520496": 212, "000965250965250965": 212, "000977517106549365": 212, "000998442620366": [191, 212], "001": [97, 153], "0010413347897739": 212, "00112652429225695": 215, "0012968155250152563": 235, "00130": 232, "00130005200208008": 221, "001647": 232, "00185070943861814": 212, "00190476248065": 212, "00193050193050193": 212, "0024991387176062363": 236, "0025": 229, "00257953568357696": 218, "0026496137794309827": 215, "00287769784172662": 212, "00317432871342": [221, 231], "00380590373768": 212, "00381315538608198": 212, "00390": 232, "00390015600624025": 221, "003ae43fae340174a67ffbcf19da1549": [221, 232, 236], "00467374305816601": 215, "00532112905379904": 215, "0054909123600744899": 53, "00570741964554": [212, 221], "00575539568345324": 212, "0059028924590036405": 236, "00719424460431655": 212, "00734567214878": 236, "00759737747394": 212, "00773860705073087": 218, "00829021870801": [221, 231], "0083296286255124322": 53, "00839234198794": 221, "00925354719309068": 212, "00945829750644884": 218, "009535178394562414": 215, "01": [53, 103, 199, 213, 221, 229, 235, 236, 237, 239], "010472837603757787": 215, "0104861773117255": 212, "0109437945432": 227, "0120238095238": 221, "01292986": 209, "013089769277": [221, 231], "014106368216269394": 235, "0146000411268764": 212, "01581679229802067": [213, 239], "015851020617975636": 236, "0165877776996": 231, "016872174598": 227, "017539415798": 227, "017977732950626615": 236, "018905676945535039": 235, "0190901461024": 227, "0193195458569": 227, "019350854084730935": 235, "019365962321772998": 235, "0193760958564": 231, "0194290": 209, "019926181063055992": [213, 239], "01997606345512792": 236, "01f6c25f87600f619e05767bf8942a5f": [232, 236], "01hea_aar": [40, 41, 44, 45, 54], "02": [53, 213, 231, 235, 239], "020210781774380928": 215, "0204222202935": 227, "020823064135712589": 236, "020842882578666778": 235, "02199555614": 231, "02206729102836306": [213, 239], "0221719208099": [221, 231], "022243809343": 227, "0224": 236, "022425595182743487": 236, "023172378772080934": 236, "024241974166569567": 236, "0257042977585852": 212, "026510802106572903": 235, "0282628861297": 227, "028505009510342232": 235, "0287859326858": 227, "028974068999092516": 53, "0292565947242206": 212, "0296604288467": 227, "02be98c1005c0e7605385fbc5009de61": [232, 236], "02mal_aar": [40, 41, 44, 45, 54], "03": [53, 213, 218, 229, 239], "03019054224": 231, "0308753760547": 212, "0310773305901": 227, "031671145902": 227, "0318cc38971845f7470f34704de7339d": [232, 236], "0330878687188": 227, "0333333333333333": 164, "0339621286241": 227, "034045921063826e": 236, "03408812109811863": 236, "0344849879812": 227, "0352946253": 231, "0366415948096726": 215, "0378331900257954": 218, "03944440616": 231, "0398759714239": [221, 231], "03chr_aar": [40, 41, 44, 45], "03res_aar": 54, "04": [53, 206, 213, 229, 231, 235, 239], "04002299128": 231, "0404994395195": 227, "040b2b154e4074a72d8a7b9697ec76d2": [232, 236], "041178583963528741": 236, "041434284485758692": 53, "0416764169778933e": [213, 239], "0423187330217": 227, "0434198157553": 227, "0436488652219": 227, "04366437556": 212, "0451970546256": 227, "0458631098209": 227, "04686722815": 231, "048943029258": [221, 231], "0492504223304": [221, 231], "0492893813166": 212, "04acc_aar": 54, "04cer_aar": [40, 41, 44, 45], "05": [53, 84, 93, 94, 96, 192, 198, 212, 213, 218, 221, 226, 231, 236, 239], "0513189448441247": 212, "0517785038655": 227, "0537304778134": [221, 231], "0556496028558": [221, 231], "05acc_aar": [40, 41, 44, 45], "05cer_aar": 54, "06": [215, 221, 231, 235], "0617507521094": 212, "0625": 229, "0625745873057": 227, "065154589658": [221, 231], "0656672297739": [221, 231], "0666666666666667": 164, "06alz_aar": [40, 41, 44, 45, 54], "06mb": 223, "07": [37, 57, 199, 221, 231, 237], "0714285714285714": 164, "0735800930425": 227, "07432567922874671": 232, "0750219732934": [221, 231], "07764014307349": 236, "0794748937429": 227, "07dia_aar": [40, 41, 44, 45, 54], "08": [199, 221, 231, 237], "0800006243256": [221, 231], "0801380815627": 227, "0816791773924": 227, "0819071265087": 227, "0829920718038": [221, 231], "0830027366666": 227, "0840494768068": [221, 231], "0848123243954": 227, "0851259142747209e": 235, "0873287511199": 212, "0894683992084": [221, 231], "08flu_aar": 54, "08mb": 223, "08nep_aar": [40, 41, 44, 45], "0909090909090909": 229, "0910": [41, 54], "0910_ageadj": 118, "0921758215433": 227, "0941709591925": 227, "0964435792616": 227, "096464": 232, "0969621565127": 227, "09flu_aar": [40, 41, 44, 45], "09nep_aar": 54, "0_0001": [89, 127], "0_005": [85, 229, 234], "0_01": [27, 46, 52, 73, 91, 113, 137, 155, 156, 157, 160, 161, 162, 168, 172, 193, 200, 203, 212, 214, 224, 232], "0_02": 80, "0_05": [94, 113, 181, 198, 218, 221], "0_1": [10, 46, 153, 168, 235], "0_5": 218, "0f8f18074713": 223, "0me": [213, 239], "0th": [31, 32, 67, 68, 213, 239], "0x7f0f75de38c8": 235, "0x7f87e75e1390": 214, "0x7f87e75e13d0": 214, "0x7fa9b599e8c8": 235, "0x7fb5691946e0": 53, "0x7fd8667328c8": 235, "0x7ff58b5bfcf8": 236, "1": [9, 14, 15, 16, 17, 18, 19, 20, 23, 24, 25, 26, 27, 42, 43, 51, 52, 53, 54, 58, 59, 65, 71, 80, 84, 85, 91, 94, 95, 96, 111, 128, 136, 143, 145, 157, 164, 179, 189, 190, 191, 195, 196, 199, 201, 203, 206, 209, 212, 219, 220, 222, 227, 232, 234, 235, 236, 237, 238], "10": [28, 31, 32, 41, 52, 53, 54, 58, 59, 65, 91, 99, 118, 144, 149, 150, 164, 166, 167, 183, 206, 209, 212, 213, 215, 218, 219, 221, 222, 227, 229, 235, 236, 237, 238, 239], "100": [89, 107, 117, 127, 141, 143, 195, 196, 197, 201, 227, 235, 236], "1000": [1, 104, 107, 119, 120, 139, 193, 221, 231, 235, 236], "10000": [37, 218, 235, 236], "100000": [235, 236], "1000000": [235, 236], "100215331046": [221, 231], "1007": 53, "100k": 222, "101": 215, "1023": 145, "1043863": [191, 212], "1049": 212, "105": [212, 213, 235, 239], "1051": [144, 149], "106": 235, "107": [212, 215], "1073": 218, "10797": 53, "1080": 209, "1087": 145, "1087054717738083": 209, "109": 209, "10eea3e0202a": 223, "10k": [218, 222], "10sel_aar": [40, 41, 44, 45], "10sui_aar": 54, "10th": 209, "10to16": 27, "11": [31, 32, 65, 67, 68, 164, 206, 209, 212, 213, 218, 219, 221, 223, 224, 235, 237, 238, 239], "110": [231, 235], "11000000000000001": 237, "1111": 209, "111962191762": [221, 231], "11203": 209, "11208": 209, "1125": 209, "1125738610915348e": 235, "114": 235, "11400408216e": [221, 231], "1145": 145, "1146": [46, 168, 209], "1149": 145, "115": 209, "1150911": [191, 212], "1151": [46, 168, 209], "115339374305": [221, 231], "11535169076175808": [213, 239], "117238226305": [221, 231], "1177": 209, "118": 209, "11834531391511936": 235, "11sep_aar": [40, 41, 44, 45, 54], "11th": 213, "12": [67, 68, 164, 212, 213, 215, 232, 235, 236, 239], "120": 235, "1200": 118, "1224": 236, "123031255372": 231, "124": [213, 239], "124771933759": 227, "12491": 209, "125": [209, 212, 221, 229], "12508f45aa9c98ae6e6816b030b6b581": 236, "1259": 153, "126636171693": [221, 231], "127": 0, "128": 235, "1283": 145, "128514": 25, "128675651556356096": 165, "128679866827677696": 14, "12liv_aar": [40, 41, 44, 45, 54], "12th": [32, 68, 239], "13": [113, 164, 209, 223, 236], "130": 235, "1309": 145, "1319": 229, "133333333333333": 164, "1338": 236, "134": 231, "1356583": 218, "136": 235, "1371": 209, "1375": 212, "1390": 218, "13hyp_aar": [40, 41, 44, 45, 54], "14": [164, 199, 206, 232, 237], "14099512415343221": 235, "141292966419": [221, 231], "141548621844": 215, "142": 235, "142857142857143": 164, "14424303335": [221, 231], "14425018597": 215, "1447": 145, "1453849": 209, "148": 212, "14par_aar": [40, 41, 44, 45, 54], "15": [40, 41, 44, 164, 209, 212, 215, 221, 223, 232], "151": [213, 239], "1529": 145, "1537464257": 231, "15381597749128": 236, "1539536735386": 236, "1540": 229, "1543": 145, "156478519231599": 235, "158": 209, "15837": 237, "159": 209, "159080830815": 215, "15951572834767661": 235, "15k": 218, "15m": [228, 229], "15pne_aar": [40, 41, 44, 45, 54], "16": [15, 65, 164, 199, 221, 224, 232, 237], "1608": 229, "161206890368": [221, 231], "164": 218, "1650058031082153": [213, 239], "1655": 53, "16581363417963907": 235, "167": 218, "169": 209, "16and1": 234, "16mb": 223, "16to": 15, "16to1": [36, 89, 113, 127, 212, 224, 234, 235, 237], "16to16": [0, 9, 10, 12, 15, 16, 17, 19, 20, 27, 28, 37, 40, 41, 44, 45, 46, 51, 52, 53, 57, 60, 73, 80, 84, 85, 86, 87, 91, 93, 94, 96, 99, 100, 113, 114, 118, 136, 137, 139, 143, 144, 145, 147, 149, 150, 151, 153, 155, 156, 157, 160, 161, 162, 164, 166, 167, 168, 169, 172, 181, 183, 186, 187, 191, 192, 193, 194, 197, 198, 200, 201, 203, 213, 214, 215, 226, 227, 228, 229, 231, 232, 234, 235, 236, 237, 239], "16to3": [111, 212, 224], "16to4": [182, 212, 224], "16to8": [29, 212, 224], "17": [164, 199, 206, 209, 212, 215, 223, 232, 236, 237], "171": 212, "172": 223, "172756193994": [221, 231], "174": 209, "174357": [212, 232, 234], "175281125172": 231, "177938062241": [221, 231], "178": 209, "1781": 215, "18": [27, 145, 164, 209, 215, 218, 229, 231, 236], "1804": 229, "181": 209, "1826": 145, "18394": 235, "1840": 229, "1843": 145, "184425": 227, "184659675097676": 212, "1872": 221, "188": [209, 212], "19": [164, 218, 236], "191": 229, "1915221687336874e": 236, "1948550617711228": 209, "194981277707842e": 235, "198": 231, "1_01": [22, 238], "1_02": [22, 238], "1_03": [22, 238], "1_04": [22, 238], "1_05": [22, 238], "1_mean_value_filt": [53, 195, 196, 235], "1_univariate_select": 236, "1a": 221, "1e": 153, "1g": 229, "1gra": [46, 48, 111, 112, 158, 159, 168, 212, 221, 224, 236], "1gram": [12, 15, 16, 17, 19, 46, 51, 52, 53, 73, 85, 86, 87, 91, 94, 99, 100, 111, 113, 136, 137, 143, 145, 147, 150, 153, 155, 156, 157, 160, 161, 162, 168, 172, 183, 186, 187, 191, 193, 198, 200, 203, 212, 214, 218, 221, 224, 228, 229, 231, 232, 236, 237], "1gram_po": [19, 212], "1grams16to16": 172, "1k": 222, "1m": 218, "1me": [213, 239], "1st": [68, 239], "1to2cgram": 212, "1to2gram": [16, 17, 51], "1to3gram": [10, 27, 60, 84, 89, 94, 113, 127, 169, 203, 212, 215, 221, 222, 224, 231, 234, 235], "1to3grams_tagcloud_wordcloud": 231, "2": [15, 16, 17, 18, 27, 40, 46, 51, 53, 58, 59, 65, 71, 84, 128, 150, 160, 164, 177, 191, 199, 206, 209, 212, 220, 222, 227, 231, 234, 235, 236, 237, 238, 239], "20": [1, 164, 179, 209, 220, 222, 229, 231, 236], "200": [215, 218, 236], "2000": [215, 221, 223, 229, 231, 234, 235], "20000": [96, 145, 218], "2000fbtopic": [158, 159, 234, 235], "2004": [199, 237], "2004blog": [17, 51, 136], "2006": 27, "20067386714575627": [213, 235, 239], "2010": [205, 209], "2014": [21, 46, 168, 236, 238], "2015": [37, 57, 198], "20152088984": [221, 231], "2017": [205, 223], "2018": 223, "2024": 218, "203": 215, "2033616": [191, 212], "204": 212, "204408282607": [221, 231], "20481809973716736": [213, 239], "21": [164, 209, 218, 236], "213": 223, "216": 212, "216833": 232, "22": [164, 231, 236], "220991447954": [221, 231], "223": 212, "224776130551": 212, "22630059748": 212, "22785435243": 212, "23": [164, 232, 234, 236], "230": 145, "2300555": 212, "23095597872": 212, "231cb0e216d3": 223, "23204271891755": 236, "232261824573": [221, 231], "232561097638729e": 235, "2327": 236, "2338": 209, "234459": 221, "2347": 209, "23713590324": 212, "239": 212, "24": [37, 57, 89, 130, 164, 199, 231, 232, 237], "2418219903436825": 53, "244": 212, "245": 212, "249": 229, "25": [44, 138, 164, 188, 199, 231, 232, 236, 237], "250": 229, "255": 218, "2567": 236, "2585161030292511": [213, 239], "25th": 209, "26": [53, 164, 209, 218, 232, 236], "265": 212, "2664993405342102": [213, 239], "26721023671": 215, "2689576980217385": 236, "26935520215": 231, "27": [164, 209, 231, 232, 236], "272": 215, "274": 229, "275": 212, "27544591260491": 236, "276": [212, 215], "277": [145, 212], "2779": 236, "278": [212, 215], "278647": [191, 212], "2790368274979054": 235, "28": [164, 221], "281": 235, "28171112431": 215, "283": 212, "283547": [191, 212], "28451": [212, 215, 232, 234], "285": 145, "285k": 218, "2863105": 231, "2876677": [191, 212], "288374195668318e": 235, "2885389879": 234, "29": [27, 53, 164], "290": 215, "2901904881000519": [213, 239], "290k": 218, "2945": 236, "295": 212, "2954": 235, "295k": 218, "296": [209, 212, 229], "29672280401": 215, "2968": 235, "298": 212, "2_rpca": 236, "2_univariate_select": [53, 195, 196, 235], "2a4ea8a5ac157246feedfcf72edad5ff": 236, "2d": [89, 127, 215], "2g": 229, "2gram": [16, 17, 51, 80, 113, 212, 221, 222], "2k": 222, "2mb": 223, "2me": [213, 239], "2n": [52, 53], "2to3gram": 80, "3": [18, 27, 49, 53, 65, 71, 80, 84, 128, 145, 150, 164, 195, 196, 199, 205, 209, 212, 218, 220, 222, 224, 227, 234, 235, 237, 238], "30": [164, 201, 215, 221, 236], "300000": 218, "30072681531286": 235, "3010": 236, "3010202588882005": 236, "304": 212, "30464448623": 212, "305": 209, "307349": [191, 212], "30786952879339": 236, "31": [164, 199, 223, 236, 237], "31201123597329": 236, "31234": 209, "3132484926424": 236, "3136": 236, "3136392251334551": 236, "31528063131662087": 236, "3155970": 231, "3167": 237, "317581": 232, "319316495428431": 235, "32": [65, 164, 218, 237], "32342564224e": 231, "32mb": 223, "33": 164, "3306": 223, "3321866": 231, "33229129841": 231, "333333333333": 212, "333333333333333": 229, "334117399851": 231, "33522bc535275457a87e20b3d0be71f2": 236, "335374453708489": [213, 239], "3361075": [199, 232, 237], "34": 164, "3414": 236, "3417138": [199, 232, 237], "344": [212, 215, 221], "346": 215, "346333662611386": 235, "3482840": [191, 212], "3485704": 231, "349": 215, "35": [164, 223], "3572426774038191e": 235, "35815398645287": 236, "359848659": 231, "36": [164, 215, 218, 224, 234], "36172845861240155": 235, "364230235902": 231, "3673414": [199, 232, 237], "3708": 236, "3711805": [191, 212], "37306214998000053": 235, "3734409296293868": 235, "375110412634": 227, "3757": 25, "37710881124945012": 235, "38": [212, 213, 239], "380720301847": 231, "382388363028": 231, "39": 235, "39436851707394593": 235, "39617060533142334": 236, "3991108": [199, 232, 237], "399554821560564": 236, "3_rpca": [53, 195, 196, 235], "3d2aa70286b8": 223, "3gram": [80, 113, 212, 221], "3me": [213, 239], "4": [15, 18, 40, 41, 44, 45, 118, 128, 158, 159, 164, 189, 190, 195, 196, 199, 206, 209, 212, 215, 218, 221, 223, 224, 231, 235, 236, 237, 238], "40": [212, 223, 229, 236], "400": 218, "40000": [12, 15, 29, 36, 94, 114, 153, 182, 194], "401": 218, "4016135": 231, "40167196195e": 231, "402": 235, "40222682541212029": 235, "40305582938481005": 235, "4034265034747871e": 235, "403504235": 231, "404": 145, "40456074476242065": [213, 239], "4065": 236, "408754348795": [221, 231], "41": [235, 236], "41097464037854003": 235, "4115327": [199, 232, 237], "414": 212, "4144593": [191, 212], "41721742624e": [221, 231], "418": 145, "4184069": 231, "42": [53, 58, 59, 195, 196, 215, 231, 235, 236, 237], "42001": 27, "42001_2012_01": 27, "42001_2012_02": 27, "42001_2012_03": 27, "42001_2012_04": 27, "42001_2012_05": 27, "42003": 27, "42003_2012_06": 27, "42003_2012_08": 27, "42007": 27, "42007_2012_01": 27, "42017": 27, "42025": 27, "42049": 27, "420633811537": 227, "42071_2012_02": 27, "42071_2012_11": 27, "42077": 27, "42091_2012_11": 27, "42101": 27, "42101_2012_02": 27, "42101_2012_04": 27, "42101_2012_05": 27, "42101_2012_07": 27, "42125_2012_03": 27, "4233643081827411": [213, 239], "42678743626421878": 235, "4276": 53, "42848778125374": 236, "43": 235, "4329061542488414e": 236, "43404698847": 231, "43803046030458836": [213, 239], "43888092428e": [221, 231], "44": [209, 218], "441": 236, "444": 218, "445": [145, 218], "445mb": 223, "446275": 232, "45": [212, 221, 223], "450": 236, "45284615270670103": 235, "45703007082": 231, "45911352125": [221, 231], "464315148935017": [213, 239], "4643151489350172": 235, "466": 229, "47": 212, "470_wc": 218, "47423319603178121": 236, "48": [27, 215], "4810": 25, "483710711985": [221, 231], "48483654856681824": [213, 239], "484973024855944e": [213, 239], "48kb": 223, "4962114905936383": 236, "4971926509824059e": 235, "499": 236, "49964": 227, "4g": 229, "4gram": 222, "4me": [213, 239], "5": [9, 14, 18, 22, 40, 49, 52, 53, 85, 91, 94, 102, 128, 150, 164, 177, 189, 190, 191, 195, 196, 199, 206, 209, 212, 213, 215, 218, 221, 223, 224, 231, 232, 234, 235, 236, 237, 238, 239], "50": [58, 59, 84, 140, 193, 209, 222, 223, 228, 229, 235, 236, 237], "500": [9, 10, 28, 37, 48, 86, 87, 93, 94, 112, 151, 181, 192, 212, 213, 215, 221, 222, 226, 227, 234, 235, 236, 239], "5000": 221, "50000": [40, 44, 54], "50668539378": [221, 231], "5067491373744111": 53, "507": 218, "5072966814041138": [213, 239], "507_wc": 218, "50k": 222, "51": 212, "5102667175760027": 236, "5103": 236, "5155537183235": 236, "516": 209, "51687": 227, "5176954815233685": 53, "5218": 236, "527": 209, "5281778935127832": 235, "53": [212, 221, 231], "5336986508333688": 235, "5453007746": 234, "54865313166717689": 236, "5487": 236, "55": [205, 209, 237], "5527": [25, 238], "552954e73844": 223, "5559": 236, "556797752649086": 236, "55682728995491": 236, "55th": 209, "561": 218, "5645": [25, 238], "56542413757": 215, "567": [58, 59, 237], "56gb": 223, "56th": 209, "57": 235, "571561056997": 227, "576185788081": 227, "57657": 227, "58": 236, "5833280925503392": 215, "59": 236, "5994": 53, "5k": [218, 222], "5me": [213, 239], "6": [18, 49, 53, 64, 80, 128, 164, 191, 206, 209, 212, 213, 215, 218, 219, 221, 223, 224, 228, 231, 235, 236, 237, 238, 239], "60": [87, 205, 209, 223, 235], "602222": 236, "604638389981": [221, 231], "605114549867": 231, "606670069561": 231, "60813970285153": 236, "6084": [25, 238], "61": [212, 236], "61078813837532941": 235, "612360070325049e": 235, "6127094761": 231, "6128928956045994": 236, "6129": 236, "6141474094178232": 235, "614437770178403e": 235, "616220914873225": 236, "616423448270654": [213, 239], "617025365643": 231, "6186": 157, "619034298134363": [213, 239], "6200": 236, "6225268232718818": 235, "623": 229, "62368517193313822": 53, "62425777784888248": 53, "62582613937e": [221, 231], "626654933077618688": 234, "626654998773014528": 234, "626655093023211520": 234, "626655195976568832": 234, "626655248321482752": 234, "6279876727085858": 235, "62849684211444135": 235, "6293": 53, "63": [235, 236], "63000000000000012": 236, "631052186337": 231, "631679282044317": 235, "631780162099723": 235, "632378566764": 227, "63275749683012394": 235, "634404850072": 231, "63739741140546302": 235, "64": [65, 212, 215, 219, 237, 238], "6475": 53, "648": 145, "6496": [213, 236, 239], "64961384918228648": 236, "65": 235, "6505762607835": 236, "65093645124": 231, "6529378160101356": 235, "65328970316714685": 235, "65400913034708874": 235, "6544622564": 231, "65593": 221, "6585525274276733": [213, 239], "661": 229, "66135842980913795": 235, "6618386965904822": [213, 239], "6621": [213, 239], "6621098985283438": [213, 239], "6623785068464": 236, "666": [213, 239], "66881845157843556": 235, "66895432831001": 235, "6694097453791333": [213, 239], "671748": 231, "67282259377235909": 236, "673432284751": 231, "67558": 236, "67593": 236, "678967347": 231, "679288049345": [221, 231], "6814": 236, "68141019974698003": 236, "681655428515": 231, "683227405819": 227, "68505102312465327": 235, "6923076923077": 212, "69474789987194996": 235, "6a56f67c249e8e14403b3f40231cdde4": 236, "6me": [213, 239], "6mopostcount": 181, "7": [27, 49, 128, 164, 206, 213, 215, 221, 223, 231, 235, 236, 239], "70": [53, 195, 196], "70032e45f971": 223, "701": 14, "71": [212, 235, 236], "7107187086007063": [213, 239], "71484278807899": 236, "7181": 236, "718894793283": 227, "72": 236, "7200": 236, "7277": 236, "72770801319050482": 236, "7278": 236, "727807054395043": 236, "729": 234, "73": [27, 236], "731260898487": 215, "73150685503": 215, "73199999999999998": 236, "7325620923091893": 235, "732582650282395e": 235, "7327336968238978": 235, "73343605546995": 212, "7403932140338458": 235, "7488590924939": 236, "752": 145, "7572038557968686": 235, "7577487943864093": 236, "75985663082437271": 236, "76": 236, "7604": 236, "7619989539884977": 53, "762037681819328": 53, "7633413628e": [221, 231], "764": 209, "76549094375596": 212, "766": 229, "768": [213, 239], "77": 236, "77229872578756076": 53, "773": 209, "7795793244": 231, "78": 236, "780": 231, "78283": 218, "783371417616072e": [213, 239], "785": 145, "79009985308749586": 53, "7909194802451609": 53, "79109013487672142": 53, "7924": [25, 238], "793": [234, 235], "7941701177133611e": 236, "7992072704676758": 235, "7992666876157764": 215, "7me": [213, 239], "8": [15, 32, 164, 206, 209, 212, 213, 215, 220, 221, 223, 235, 236, 239], "80": [201, 212, 219], "800": [145, 235], "8017728082382849": 235, "8069174191858989e": 235, "808381l": 53, "81": 212, "81170807542": 215, "8168508661": 231, "820150245521624": [213, 239], "8225060221e": [221, 231], "82280081643e": [221, 231], "83": 236, "83089815326e": 231, "8336": 236, "83367105025": 231, "83561091756": 231, "84": 223, "84338861809425469": 236, "8446": 218, "84652080652080652": 236, "85393467507425691": 52, "854171578743": 227, "854440157161314": [213, 239], "8575587089762855": 215, "857939340623183": 235, "859884969097588": [213, 239], "8599": 236, "860030650986": 231, "86367966775116722": 52, "8649261269079": 236, "8679725446432318": 235, "8697": 53, "86mb": 223, "8702764242703": 236, "87199798082e": [221, 231], "87205025089102173": 236, "873": [213, 235, 239], "873216515253354": 235, "8749": 157, "881": 235, "8819": [25, 238], "8820983398248488": 215, "882525635420599": 235, "8839": 157, "884718059241858": 235, "8890": 218, "88992485335879401": 235, "89": 236, "89544586136045368": 53, "898": [52, 212], "898025697226569": 53, "8991": 53, "899256104306499": 53, "8ad4098a61dfc3e42916a35293802a59": 236, "8d": 215, "8m": 218, "8me": [213, 239], "9": [68, 91, 164, 206, 209, 212, 213, 215, 218, 221, 231, 235, 236, 239], "90": 236, "9002353374669132": 235, "904": 145, "91": 145, "912mb": 223, "916875173924": 227, "9268": [25, 238], "937405646479284": 236, "9407575669782": 236, "943": 145, "9448": 25, "945148184099": 231, "947": 229, "95": [215, 218], "9505": [25, 238], "951236181408891": 236, "9543434601896134e": [213, 239], "95579279429": 231, "957358049868": 231, "95925394952e": [221, 231], "96270830361273707": 235, "9695": [25, 238], "97": [1, 235], "972723923762": 231, "9735": [25, 238], "9776": [25, 238], "978": [213, 215, 227, 231, 235, 239], "9791": [25, 238], "98": 235, "9806": 25, "9813": [25, 238], "9815875967542": 236, "9853": [25, 238], "9890": [25, 238], "98930451373e": 231, "9898": 25, "9903": 25, "9904": [25, 238], "991911281360676e": 235, "992287422430842": 236, "9925": [25, 238], "9931": [25, 238], "9934": [25, 238], "995385541164": 231, "9955": 25, "9957": [25, 238], "9958": [25, 238], "9959": 25, "9962": [25, 238], "9963": [25, 238], "9964": [25, 238], "9967": 25, "9973": [25, 238], "9981": [25, 238], "9984": [25, 238], "9985": [25, 238], "9986": [25, 238], "9990": [25, 238], "9991": [25, 238], "9992": 25, "9993": [25, 238], "9994": [25, 238], "9996": [25, 238], "9997": [25, 238], "9997143428258404e": 235, "9998": 53, "9999": [25, 238], "9me": [213, 239], "9th": 209, "A": [1, 14, 16, 17, 25, 26, 29, 36, 42, 43, 46, 89, 96, 97, 102, 111, 119, 127, 144, 149, 158, 159, 168, 182, 209, 211, 215, 218, 228, 238], "AS": [27, 215], "As": [44, 52, 53, 94, 213, 221, 235, 237, 239], "At": [27, 52, 53, 223, 236], "BY": [27, 152, 215], "Be": 228, "Being": [1, 205, 209, 211], "Beings": 205, "By": [16, 99, 101, 124, 154, 203, 213, 219, 220, 224, 235, 239], "FOR": 221, "For": [18, 39, 52, 53, 56, 62, 63, 64, 74, 80, 89, 94, 106, 114, 115, 118, 125, 126, 127, 128, 129, 130, 143, 145, 161, 172, 186, 194, 212, 213, 214, 215, 218, 219, 220, 226, 227, 228, 229, 232, 235, 236, 238, 239], "IF": [218, 237], "INTO": [27, 221, 237], "If": [24, 38, 39, 40, 44, 45, 52, 53, 57, 77, 78, 89, 94, 106, 109, 124, 136, 138, 139, 148, 155, 156, 158, 159, 161, 162, 164, 170, 172, 173, 179, 188, 189, 190, 192, 195, 196, 203, 205, 206, 213, 219, 221, 222, 223, 225, 234, 235, 239], "In": [14, 15, 46, 80, 89, 94, 100, 109, 118, 127, 168, 195, 196, 209, 212, 213, 215, 218, 220, 221, 223, 224, 226, 231, 232, 234, 235, 236, 238, 239], "It": [24, 40, 44, 54, 94, 96, 172, 189, 190, 195, 196, 205, 212, 213, 221, 228, 234, 235, 239], "NO": [65, 212, 219, 221, 224, 237, 238], "NOT": [93, 154, 201, 236], "No": [93, 129, 134, 135, 154, 207, 209, 220], "Not": 64, "ON": [27, 188, 236], "ONE": 209, "OR": [28, 79, 85, 107, 133, 138, 188, 207], "On": [37, 107, 209, 221], "One": [28, 32, 68, 212, 236], "Or": [143, 214, 238], "The": [14, 16, 17, 18, 21, 22, 24, 25, 26, 27, 29, 31, 33, 36, 39, 46, 51, 52, 53, 57, 64, 67, 69, 80, 84, 89, 91, 94, 96, 99, 104, 105, 107, 111, 118, 121, 124, 127, 128, 138, 140, 141, 143, 145, 154, 156, 157, 158, 159, 160, 161, 162, 167, 168, 182, 184, 188, 191, 192, 198, 201, 206, 209, 211, 212, 213, 215, 218, 220, 221, 223, 224, 226, 227, 228, 229, 231, 232, 234, 236, 238, 239], "Then": [84, 166], "There": [14, 40, 84, 86, 87, 96, 101, 116, 118, 127, 130, 144, 146, 149, 166, 167, 184, 201, 213, 225, 228, 239], "These": [99, 118, 143, 145, 212, 213, 221, 224, 226, 228, 237, 239], "To": [24, 40, 54, 76, 77, 78, 86, 101, 119, 120, 121, 132, 195, 196, 206, 207, 213, 214, 218, 219, 220, 221, 223, 228, 235, 236, 239], "Will": [21, 40, 65, 72, 105, 135, 137, 155, 172, 199, 221], "With": [85, 206, 214], "_": [215, 218, 229, 235], "_0": [96, 227], "_1": [96, 227], "__file__": [206, 207], "__init__": [0, 207], "__multiclass": 128, "_an": [47, 219], "_avg1gramlength": 212, "_avg1gramspermsg": 212, "_cp": [105, 224, 228, 229], "_dedup": [64, 219], "_en": 219, "_freq_t50ll": [105, 193, 228], "_fwflag_add_sent_per_row": 23, "_intercept": 0, "_multixpredict": 0, "_nospam": 219, "_rand": [58, 59], "_tok": 0, "_total1gram": 212, "_w": [200, 224], "a19_d6_s4": [114, 144, 149], "a30": 221, "a8a59477268d": 223, "aaaannnndd": 229, "aaai": 209, "ab": 223, "abdul": 209, "abeb": 209, "abera": 209, "abl": 106, "abort": 207, "about": [1, 24, 52, 53, 195, 196, 209, 213, 218, 221, 223, 239], "abov": [14, 15, 80, 166, 175, 179, 206, 213, 214, 215, 218, 221, 222, 226, 227, 228, 229, 231, 232, 235, 236, 239], "absolut": [53, 118, 150, 160, 222, 236], "abstract": [213, 239], "abus": 209, "ac": 209, "academi": 209, "acc": [52, 157, 236], "accept": [31, 67, 213, 239], "access": [0, 221, 223, 239], "accid": 215, "accident": 215, "accomplish": [164, 213, 239], "accord": [18, 218, 238], "account": 206, "accur": 222, "accuraci": [52, 53, 157, 189, 190], "acl": 209, "aclweb": [205, 209], "acm": [118, 209], "across": [113, 209, 212, 213, 218, 224, 239], "act": 164, "action": 90, "actual": [37, 74, 107, 157, 160, 201, 213, 229, 231, 239], "ad": [0, 22, 73, 118, 206, 215, 218, 219, 223], "adapt": [0, 209], "add": [0, 11, 12, 13, 14, 15, 21, 52, 53, 84, 107, 147, 198, 206, 213, 214, 219, 220, 235, 239], "add_bert": [11, 31, 32, 33, 34, 213], "add_char_ngram": [0, 212], "add_convokit": 218, "add_corp_lex_t": [0, 7, 8], "add_emb_feat": [13, 67, 68, 69, 70, 239], "add_embed": 0, "add_lda_messag": [7, 8, 229], "add_lex_t": [7, 8, 29, 36, 73, 100, 106, 111, 182, 200, 203, 212, 215, 221, 224, 228, 229, 236], "add_message_id": [0, 229], "add_ngram": [7, 8, 19, 29, 36, 51, 63, 71, 73, 84, 111, 129, 136, 182, 198, 212, 218, 221, 224, 228, 229], "add_ngrams_from_token": [7, 8, 21, 51, 212], "add_pars": [7, 8, 19, 20, 238], "add_pos_ngram_t": [7, 8, 20, 212], "add_pos_t": [7, 8, 212], "add_postimexdiff": [0, 62], "add_seg": [7, 8, 174, 238], "add_sent_per_row": [8, 238], "add_sent_token": [8, 213, 238], "add_term": 107, "add_timexdiff": 62, "add_token": [7, 8, 14, 212, 229, 238], "add_tweetpo": [7, 8, 19, 20, 238], "add_tweettok": [7, 8, 212, 238], "addit": [0, 40, 44, 180, 215, 220, 221, 227, 235], "addmessageid": [0, 2, 14, 208], "adhd": 209, "adjac": 17, "adjust": [54, 218, 228, 229], "adult": 209, "advanc": [46, 128, 168, 211, 223, 235], "advantag": 180, "advis": 229, "advmod": 18, "advp": 18, "aek": 209, "af": 101, "affect": [1, 103], "affili": [209, 223], "after": [21, 27, 39, 51, 52, 53, 54, 128, 150, 172, 197, 201, 223, 224, 228, 234, 235, 236], "ag": [28, 39, 46, 52, 53, 57, 60, 65, 86, 87, 93, 94, 128, 137, 143, 145, 147, 148, 150, 151, 155, 160, 161, 162, 168, 169, 172, 183, 192, 199, 201, 202, 209, 211, 213, 214, 215, 221, 224, 226, 227, 231, 232, 234, 235, 236, 237, 239], "again": [21, 178, 221, 229, 234, 235], "against": [213, 239], "age__withlanguag": [231, 236], "age_and_gender_cloud": 151, "age_neg": 231, "age_po": 231, "agedummi": 234, "agelex1gram": 168, "agelex1gramstop": [46, 168], "agetercile0": [9, 10, 28, 35, 37, 79, 85, 181], "agetercile1": [9, 10, 28, 35, 37, 79, 85, 181], "agetercile2": [9, 10, 28, 35, 37, 79, 85, 181], "agg_1to3gram": 27, "aggreg": [16, 17, 27, 31, 32, 34, 38, 67, 68, 70, 84, 209, 212, 218, 221], "aggregate_feats_by_new_group": [7, 8], "aggregation_method": [31, 34, 67, 70], "ago": 223, "agr": [35, 79, 85, 202, 234], "agraw": 209, "agress": 195, "ahm": 209, "aid": 229, "aka": [40, 189, 212, 219, 237, 238], "aku": 212, "al": [209, 236], "album": [27, 164], "alcohol": [209, 229], "algorithm": [46, 89, 127, 168, 215], "alia": [0, 55, 143, 223], "alias": [0, 39, 113, 128, 151], "align": 57, "all": [0, 1, 16, 17, 28, 51, 52, 53, 54, 64, 76, 77, 78, 79, 84, 93, 94, 96, 99, 107, 113, 118, 123, 132, 139, 143, 145, 148, 154, 177, 197, 198, 203, 204, 206, 212, 213, 214, 215, 218, 220, 221, 223, 224, 229, 232, 235, 236, 237, 238, 239], "all_control_combin": 0, "all_controls_onli": [8, 52, 53], "all_featur": 57, "all_met_a30_2000_tagcloud": 231, "allfw": 214, "alloc": 221, "allow": [0, 46, 61, 107, 108, 132, 168, 185, 214, 215, 218, 228, 231, 237], "almodaresi": 209, "alon": [47, 52, 53, 219, 227, 235], "alpha": [53, 87, 102, 195, 196, 213, 215, 221, 229, 231, 235, 236, 239], "alphabet": [7, 128], "alreadi": [17, 206, 225], "also": [16, 17, 33, 35, 39, 40, 41, 46, 47, 49, 54, 62, 63, 65, 93, 118, 124, 125, 126, 128, 129, 130, 153, 158, 159, 161, 168, 192, 199, 202, 206, 212, 213, 214, 215, 219, 221, 223, 225, 226, 227, 228, 232, 234, 235, 236, 238, 239], "alter": 237, "altern": [12, 15, 48, 189, 190, 212, 232], "although": [110, 229], "alwai": [0, 107, 222, 228, 229], "am": [22, 23, 24, 25, 26, 101, 164, 209, 221, 238], "american": [209, 229], "among": 221, "amount": [89, 127, 215], "amuel": 206, "an": [12, 14, 15, 16, 17, 24, 29, 40, 42, 43, 44, 51, 74, 93, 94, 101, 114, 115, 128, 145, 146, 150, 158, 159, 161, 165, 191, 192, 195, 196, 201, 205, 209, 212, 213, 214, 219, 220, 221, 223, 224, 228, 229, 234, 235, 236, 238, 239], "analys": [35, 57, 83, 202], "analysi": [38, 76, 77, 78, 89, 94, 118, 119, 120, 121, 123, 124, 127, 132, 144, 147, 149, 153, 154, 166, 195, 206, 209, 211, 215, 218, 226, 234, 235, 236], "analyz": [38, 209], "andrew": [205, 209], "ani": [0, 34, 46, 49, 52, 53, 64, 65, 70, 87, 93, 94, 99, 113, 137, 139, 153, 168, 179, 195, 196, 199, 206, 212, 213, 219, 221, 223, 228, 229, 237, 239], "annek": 209, "annot": [1, 18, 107], "annotate_sens": 107, "anonym": 0, "anoth": [219, 221], "anscomb": [7, 8, 15, 16, 17, 19, 20, 106, 212, 224], "answer": [213, 221, 239], "anthologi": [205, 209], "antijokeappl": 26, "anyon": 221, "anyth": [45, 109, 137, 152, 222], "anytim": 221, "apart": 18, "apc": 229, "appear": [16, 17, 80, 106, 117, 178, 213, 239], "append": [19, 39, 47, 58, 59, 64, 105, 128, 147, 200, 219, 221, 225, 231], "append_csv_to_mysql": 225, "appli": [31, 34, 47, 52, 53, 67, 70, 89, 106, 127, 148, 158, 159, 172, 197, 211, 213, 215, 219, 221, 222, 232, 235, 236, 239], "applic": [89, 127, 205, 209, 215], "approach": [118, 209, 221], "appropri": [193, 195, 196], "approxim": 29, "apt": [206, 207], "ar": [1, 12, 15, 16, 17, 27, 29, 31, 35, 36, 40, 41, 46, 52, 53, 57, 61, 65, 67, 68, 74, 76, 77, 78, 84, 89, 91, 94, 96, 99, 101, 108, 109, 110, 111, 118, 119, 120, 121, 122, 123, 124, 127, 128, 130, 132, 137, 140, 143, 145, 148, 154, 155, 156, 157, 158, 159, 160, 161, 162, 168, 172, 175, 180, 182, 193, 195, 196, 199, 202, 203, 206, 209, 211, 212, 213, 214, 215, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 231, 232, 235, 236, 237, 238, 239], "area": [9, 157], "aren": [195, 196, 198], "argamon": 1, "argpars": 107, "arguement": 14, "argument": [65, 107, 177, 199, 213, 221, 234, 239], "arithmet": 180, "around": 94, "arous": 209, "arrai": [53, 213, 231, 235, 236, 239], "articl": [80, 112, 209], "ascii": [71, 139], "ascii_general_ci": 71, "ashford": 209, "asian": 209, "ask": [107, 221], "aspect": [209, 221], "ass": 229, "assert": 209, "assess": 209, "assign": [40, 219, 223], "associ": [205, 209, 229], "assum": [198, 206, 207, 213, 224, 227, 234, 235], "assur": 212, "astrolog": 128, "atlanta": 209, "attach": 221, "attempt": 221, "attent": 209, "attribut": 214, "auc": [0, 8, 37, 52, 57, 157, 236], "august": [199, 237], "auth": 94, "author": [205, 209], "auto": 0, "auto_incr": [65, 212, 219, 221, 224, 237, 238], "autom": [72, 229], "automat": [48, 140, 207, 209, 212, 220], "aux": 18, "avail": [1, 107, 113, 177, 206, 212, 219, 231, 235, 237, 238, 239], "averag": [52, 53, 118, 212, 236], "avg": 236, "avoid": [189, 190, 195, 196], "awai": 94, "awesom": [179, 219], "axi": [31, 34, 67, 70, 213, 239], "ayer": [213, 239], "az": 101, "b": [22, 23, 24, 25, 26, 27, 80, 101, 209, 238], "b0": [143, 145], "b1": [143, 145], "b2": [143, 145], "b3": 145, "b4": 145, "b67875fbdbabb1187715721697517139": 236, "b_0": 218, "ba": [213, 239], "babi": 212, "bachdeghc03_vc94acs3yr": [41, 54], "back": [41, 164, 223, 235, 238], "backend": [0, 63], "background": 223, "bad": 26, "baker": 209, "band": 229, "bard": 239, "bare": 27, "baron": 118, "barplot": 8, "barron": [118, 122], "base": [0, 12, 13, 15, 33, 56, 67, 68, 69, 80, 84, 94, 107, 110, 143, 145, 178, 179, 186, 194, 201, 206, 209, 212, 213, 215, 223, 229, 234, 239], "baselin": [53, 157, 235], "bash": 223, "basi": 221, "basic": [220, 221, 236], "batch": 0, "bay": [89, 127, 215], "becaus": [46, 54, 80, 168, 213, 222, 239], "becker": 223, "becom": [118, 235], "bee": 26, "been": [27, 33, 46, 52, 53, 168, 206, 218, 239], "befor": [1, 47, 49, 101, 106, 134, 206, 207, 213, 218, 219, 221, 229, 235, 239], "before_aft": 197, "begin": [32, 177, 221, 224, 236], "beginn": 211, "behavior": [96, 209], "beij": [174, 238], "being": [1, 27, 64, 106, 206, 209], "bel": [199, 237], "belief": 209, "believ": [22, 23, 24, 25, 26, 238], "below": [107, 192, 195, 196, 206, 218, 228, 229, 238], "benefit": [209, 222], "berger": 209, "bert": [0, 11, 13, 31, 32, 33, 34, 67, 68, 69, 70, 209, 239], "bert_ba_un_mel10co": [213, 239], "bert_ba_un_mel10con": [213, 239], "bert_lay": [8, 11, 31, 33, 34], "bert_layer_aggreg": [8, 11, 32, 33, 34, 213], "bert_model": [8, 31, 32, 34], "bert_msg_aggreg": [8, 11, 31, 32, 33, 213], "bertmessagevector": [34, 70], "besid": [206, 235], "best": [44, 46, 48, 168, 222, 235], "beta": [0, 96, 103, 107, 215, 227, 229], "better": [27, 112, 189, 190], "between": [18, 42, 43, 57, 96, 143, 158, 159, 160, 161, 209, 221, 228, 238], "bewar": [46, 168, 221], "beyond": [209, 236], "bg": 101, "bh": 152, "bianca": 218, "big": [209, 223], "bigint": [221, 224], "bigram": 80, "bin": [82, 116, 206, 228, 229], "binari": [0, 9, 10, 46, 48, 96, 112, 168, 183, 209, 218, 222, 236], "biocomput": 209, "bioconda": 207, "bird": 80, "birthdai": [16, 17, 80, 95], "bishop": 209, "bit": [213, 229, 239], "blacklist": [7, 8, 57, 79, 110, 202], "blackpop255210d": [41, 54], "blanco": 209, "blank": 132, "bloat": 229, "blob": 206, "block": 239, "blog": [177, 221, 237], "blog_outcom": [1, 39, 46, 48, 52, 53, 58, 59, 65, 93, 94, 99, 112, 128, 147, 148, 150, 151, 158, 159, 168, 172, 177, 183, 192, 199, 201, 202, 213, 214, 215, 221, 226, 227, 231, 232, 235, 236, 237, 239], "blog_outcomes_rand": [58, 59, 177, 237], "blogger": 1, "blow": 221, "blue": [114, 144, 149, 181, 187, 194], "bluer": [48, 112, 151, 187, 215, 221, 227], "bmi_absslope_1q4q": 10, "bmi_absslope_2bin": 10, "bmi_avg_1q4q": 10, "bmi_avg_2bin": 10, "bmi_range_1q4q": 10, "bmi_range_2bin": 10, "bmi_slope_1q4q": 10, "bmi_slope_2bin": 10, "bmj": 209, "bn": 101, "bodi": 221, "boi": 229, "bonferroni": [57, 93, 152, 192, 226], "bonu": [179, 219], "book": [14, 229], "booktitl": [205, 209], "boolean": [7, 8, 15, 16, 17, 19, 20, 106, 204, 212, 224, 234, 235], "boost": [189, 190], "bootstrap": [119, 120], "bootstrapp": [8, 9, 57], "boston": 209, "both": [16, 17, 40, 45, 52, 53, 113, 122, 136, 139, 183, 197, 212, 214, 218, 219, 221, 223, 227, 232, 234, 235], "bottom": [221, 231], "bouma": 80, "boundari": [89, 127, 215, 222, 235], "boxplot": 66, "br": 101, "brawner": 209, "breadth": [213, 239], "break": 18, "brick": 229, "brief": [221, 236], "brigad": 229, "bring": [212, 221], "broken": [27, 221, 223], "brook": 205, "browser": 221, "bu": 229, "buechel": 209, "buffon": 209, "bug": 0, "build": [96, 106, 203, 211, 227, 234, 239], "built": [24, 152, 172, 223, 234, 235, 238], "bulk": 223, "bull": 221, "bump": 235, "bunch": [40, 52], "burn": 229, "busi": 229, "bye": 223, "c": [0, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 44, 45, 46, 47, 48, 51, 52, 53, 54, 57, 60, 63, 64, 67, 68, 69, 70, 71, 73, 79, 80, 84, 85, 86, 87, 89, 91, 93, 94, 99, 101, 107, 111, 112, 113, 114, 118, 128, 129, 143, 147, 148, 149, 150, 151, 158, 159, 166, 167, 168, 172, 174, 179, 183, 184, 191, 192, 195, 196, 198, 200, 201, 202, 203, 206, 207, 209, 213, 215, 219, 223, 225, 226, 227, 228, 229, 231, 234, 235, 236, 237, 238, 239], "c1": 145, "c2": 145, "c35536977baa796cdf671697400f16ac": 236, "c4776548e966": 223, "ca": 101, "calcul": [80, 99, 118, 191, 198, 221, 227], "california": 209, "call": [0, 21, 24, 25, 26, 34, 40, 46, 49, 70, 84, 107, 118, 137, 152, 155, 156, 161, 162, 168, 172, 180, 189, 190, 192, 201, 206, 212, 213, 218, 219, 221, 226, 227, 235, 236, 237, 238, 239], "cam": 229, "cameron": 218, "can": [12, 15, 19, 20, 22, 23, 24, 25, 26, 33, 34, 40, 41, 44, 46, 58, 59, 63, 70, 86, 89, 93, 94, 99, 112, 118, 127, 129, 130, 137, 139, 156, 161, 162, 166, 168, 172, 180, 183, 189, 190, 192, 195, 196, 199, 203, 205, 206, 207, 209, 212, 213, 214, 215, 218, 220, 221, 223, 225, 226, 227, 228, 229, 232, 234, 235, 236, 237, 238, 239], "cancer": 128, "cannot": [46, 48, 112, 124, 168, 186, 199, 237], "capricorn": [128, 199, 237], "captur": [213, 239], "carnegi": [25, 26, 238], "carpent": 209, "case": [27, 73, 80, 96, 118, 203, 212, 213, 223, 235, 239], "cat": 229, "cat_dd_emnlp14_agegender_w": 236, "cat_lex_t": [15, 29, 36], "cat_liwc2007": [57, 96, 139, 201], "cat_liwc2015": 212, "cat_met_a30_2000_cp_w": [12, 15, 29, 36, 40, 41, 44, 45, 46, 48, 73, 86, 87, 93, 111, 112, 113, 114, 118, 144, 145, 149, 151, 153, 158, 159, 166, 167, 168, 182, 192, 194, 200, 212, 215, 221, 224, 226, 227, 231, 234, 235, 236, 237], "cat_moralfound": 143, "cat_msgs_10nmf_fbcp_w": 215, "cat_msgspa_800_cp_w": 193, "cat_ser1_f2_200_cp_w": [9, 37], "cat_statuses_er1_cp_w": [28, 181, 197], "cat_to_bin": 39, "cat_to_int": 128, "catalog": 239, "catch": [0, 164], "categor": [0, 8, 218, 227], "categori": [0, 95, 96, 100, 107, 212, 215, 221, 229], "categories_to_binari": [0, 39], "categories_to_integ": 128, "caten": [213, 239], "caus": [41, 52, 53, 54, 94, 158, 159, 161, 195, 196, 221, 229, 232, 238], "causal": 118, "cbt": 174, "cc": 212, "cc1a78bfd46b": 223, "cca": [7, 8, 41, 42, 43, 44, 45, 109, 172], "cca_outcomes_vs_control": [8, 40, 44, 45], "cca_penalty_feat": [8, 40, 41], "cca_penalty_outcom": [8, 40, 41], "cca_penaltyx": [40, 41], "cca_penaltyz": [40, 41], "cca_penatlyx": [41, 42], "cca_penatlyz": 43, "cca_permut": [8, 40, 42, 43], "cca_predict_compon": [7, 8], "ccapermut": 44, "cd": [206, 215, 220, 223], "ce": [212, 221], "celebr": 229, "celica": 229, "censor": 229, "center": [89, 127, 215], "certain": [204, 212, 214, 215, 221], "chandra": 209, "chang": [0, 14, 16, 17, 27, 41, 45, 99, 103, 130, 161, 180, 206, 209, 218, 228, 229, 238], "changelog": 205, "chapter": 209, "char": 139, "charact": [209, 224, 229], "character": [46, 168, 209, 221], "character_nam": 218, "characterist": [9, 170, 209, 221], "charect": 212, "charli": 229, "charset": 0, "chastiti": 218, "chatgpt": 239, "check": [0, 49, 118, 134, 158, 159, 179, 213, 219, 239], "chhaya": 209, "chines": [0, 21, 174, 238], "choic": [213, 235, 239], "choos": [21, 44, 46, 168, 174, 195, 196, 209, 213, 222, 235, 239], "chose": 235, "chosen": [52, 53, 195, 196, 235], "chunk": [52, 53, 91, 236, 238], "ci_l": [221, 227, 231], "ci_u": [221, 227, 231], "cikm": 209, "circl": [89, 127, 215], "cite": 205, "citi": 164, "cl": 213, "class": [0, 46, 89, 93, 107, 127, 157, 158, 159, 180, 189, 192, 211, 215, 235], "class_weight": 236, "classif": [0, 28, 46, 52, 99, 101, 137, 150, 156, 157, 158, 159, 189, 195, 201, 205, 211, 213, 219, 221, 222, 234, 235, 239], "classifi": [89, 127, 157, 189, 215, 223], "classification_to_lexicon": [0, 7, 8, 127, 137, 157, 195], "classifypredictor": [0, 195, 208, 214], "clean": [0, 47, 64, 101, 218], "clean_cloud": 0, "clean_messag": [0, 8, 64, 101, 219], "cleanmessag": 0, "clear": 223, "clickthrough": 209, "client": [220, 223], "clifton": 209, "clinic": 209, "clone": [206, 220, 223], "close": 235, "cloud": [0, 56, 114, 115, 138, 151, 186, 187, 188, 194, 206, 211, 221], "clound": 231, "clpsych": 209, "cluser": 89, "cluster": [0, 40, 41, 89, 127, 130, 166, 167, 184, 195, 196, 205, 208], "cm_rate": [114, 144, 149, 186, 187, 194], "cmu": [205, 206], "cn": [21, 238], "cnf": [0, 129, 220], "cnty": [27, 40, 41, 44, 45, 54, 94, 114, 144, 149, 153, 186, 187, 193, 194], "cntyym": 27, "cntyym_to_cnti": 27, "co": [33, 64, 69, 239], "cobb": 209, "code": [0, 21, 41, 57, 64, 127, 137, 142, 143, 144, 145, 153, 155, 156, 157, 158, 159, 160, 161, 162, 165, 169, 170, 173, 180, 186, 194, 206, 221, 224], "coeffici": [46, 48, 53, 89, 112, 127, 143, 145, 160, 168, 215, 218], "cognit": 209, "cohen": 48, "cohens_d": [0, 8, 112], "colab": [49, 205, 211], "colabifi": [7, 8], "collaps": 27, "collat": 71, "collect": 1, "colleg": [39, 128], "colloc": [50, 80, 84, 95, 164, 198, 222], "colloc_t": [8, 198], "color": 187, "colorschem": 0, "column": [0, 14, 16, 17, 18, 21, 22, 24, 25, 26, 38, 39, 41, 51, 57, 62, 74, 94, 96, 125, 126, 128, 137, 144, 145, 146, 149, 156, 162, 179, 180, 183, 198, 199, 201, 206, 212, 213, 215, 218, 219, 221, 224, 225, 227, 231, 236, 237, 238, 239], "column_descript": 225, "column_nam": [199, 201, 237], "columndescript": 225, "com": [16, 17, 206, 220, 223], "comb_test_classifi": 52, "combin": [0, 17, 46, 51, 91, 110, 168, 213, 221, 236, 239], "combine_feat_t": [7, 8, 16, 17, 84, 212, 221, 224], "combinedf": 232, "combo_s": 54, "combo_test_classif": [28, 231], "combo_test_classifi": [0, 52, 91, 133], "combo_test_regress": [0, 53, 99, 133, 150, 183, 231, 235], "come": [206, 218, 221], "comfort": 212, "comma": [93, 214, 232], "command": [0, 38, 127, 137, 142, 143, 144, 145, 153, 155, 156, 157, 160, 161, 162, 165, 170, 173, 180, 212, 213, 214, 215, 218, 220, 221, 223, 227, 228, 231, 236, 237, 238, 239], "comment": [195, 196], "commit": 164, "common": [206, 228], "commondream": 229, "commonli": [80, 84], "commun": [199, 209, 212, 223, 224, 235, 237, 239], "compar": [48, 107, 112, 144, 149, 157, 160, 209, 213, 221, 222, 231, 236, 239], "comparison": [152, 158, 159, 161, 209], "complet": [9, 40, 44, 89, 127, 203, 213, 215, 221, 223, 234, 235, 239], "complic": 222, "compon": [40, 41, 44, 45, 89, 127, 215], "compos": 80, "compress": 180, "comput": [68, 170, 205, 206, 209, 213, 239], "con": [35, 79, 85, 202, 213, 234, 239], "concaten": [31, 41, 67], "concept": [211, 212, 221], "conceptu": [221, 228, 229], "concret": [213, 239], "conda": [206, 207, 220], "condit": [1, 89, 127, 215, 221, 224], "conf": 129, "confer": [46, 168, 205, 209], "confid": [0, 57, 219, 227], "config": [0, 129, 220], "configur": [0, 129, 220, 223], "confirm": 223, "confus": [157, 213, 221, 236, 239], "connect": [218, 223, 238], "consid": [64, 76, 77, 78, 94, 99, 118, 124, 132, 148, 198, 201, 212, 235, 238], "constant": [93, 192, 214, 226, 232], "constraint": 44, "construct": [138, 188], "consumpt": 209, "contain": [1, 16, 18, 27, 39, 58, 59, 62, 74, 80, 84, 89, 107, 125, 126, 127, 128, 146, 157, 158, 159, 160, 161, 165, 179, 192, 203, 205, 206, 212, 213, 214, 215, 218, 219, 221, 223, 229, 234, 236, 237, 239], "content": [18, 121, 124, 139, 154, 169, 175, 176, 178, 186, 194, 208, 209, 213, 223, 239], "context": [209, 223], "contextu": [68, 213], "contin": 227, "continu": [143, 183, 207, 213, 236, 239], "control": [0, 9, 28, 37, 40, 41, 43, 44, 45, 52, 53, 54, 57, 76, 89, 93, 96, 99, 114, 118, 127, 143, 144, 145, 149, 186, 187, 192, 194, 202, 209, 215, 226, 228, 232, 234], "control_1": [76, 118], "control_adjust_outcomes_regress": [8, 86, 87, 91, 180], "control_adjust_reg": [54, 87, 91], "control_combo_s": [8, 28, 52, 53], "control_l": [76, 118], "convent": [0, 213, 218, 224, 239], "convers": 218, "conversation_id": 218, "convert": [39, 128, 213, 218, 220], "convex": 215, "copenhagen": [205, 209], "copi": [53, 215, 221, 235, 236], "copyright": 223, "core": [89, 127, 215], "cornel": 218, "corp_topic_tagcloud": [8, 114], "corpdb": [7, 61, 93, 192, 214, 232], "corpor": 223, "corpora": 239, "corptabl": [7, 93, 185, 192, 214, 232], "corptable_dedup": 64, "corptable_nospam": 179, "corpu": [107, 108, 215, 218, 221, 229], "corpus_db": 107, "corpus_exampl": 107, "corpus_lexicon": 107, "corpus_message_field": 107, "corpus_messageid_field": 107, "corpus_sampl": 107, "corpus_t": 107, "corpus_term_field": 107, "correct": [0, 57, 131, 152, 226, 228, 235], "correctli": 157, "correl": [0, 7, 8, 9, 10, 30, 35, 37, 39, 46, 48, 60, 79, 81, 85, 93, 94, 99, 112, 113, 114, 128, 143, 144, 145, 147, 148, 149, 151, 152, 153, 156, 160, 162, 168, 169, 178, 181, 186, 187, 192, 193, 194, 201, 202, 205, 226, 227], "correl_field": [0, 7, 38, 93, 94, 192, 214, 226, 232], "correspond": [18, 22, 145, 227, 238, 239], "cough": [212, 221], "could": [27, 74, 235, 236, 238], "count": [16, 17, 57, 74, 94, 95, 198, 203, 209, 221], "counterfactu": 209, "counti": [45, 94, 114, 144, 149, 186, 187, 194, 209, 221, 222, 224], "countri": [209, 221, 229], "county_addict": 153, "county_dens": [41, 54], "county_diseas": [40, 41, 44, 45, 54], "countyvotingsm2": [96, 143], "coupl": [195, 196], "cover": 218, "cp": 214, "cpwb": 205, "crap": [191, 212], "creat": [0, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 31, 32, 33, 34, 36, 39, 40, 46, 47, 51, 58, 59, 64, 67, 68, 69, 70, 73, 74, 80, 94, 101, 105, 107, 128, 136, 137, 143, 145, 151, 153, 155, 156, 157, 158, 159, 160, 161, 162, 164, 166, 168, 172, 173, 179, 182, 189, 190, 191, 192, 193, 195, 196, 200, 205, 206, 212, 213, 214, 215, 218, 219, 221, 223, 224, 227, 231, 232, 234, 235, 236, 238, 239], "create_collocation_scor": 0, "create_dist": 229, "create_random_sampl": [0, 8, 237], "created_tim": [65, 199, 212, 219, 237, 238], "creation": [136, 215, 226], "credit_po": 218, "cross": [0, 52, 53, 91, 99, 150, 183, 191, 209, 212, 213, 235, 236, 239], "crutchlei": [205, 209], "csr": 180, "csr_matrix": 180, "csv": [0, 1, 7, 8, 9, 28, 37, 39, 40, 41, 45, 54, 57, 92, 107, 121, 128, 139, 142, 147, 148, 151, 153, 163, 169, 178, 197, 221, 227, 229, 236], "csv_file": 225, "csv_to_mysql": 225, "csvfile": 225, "csvtomysql": 225, "ctb": [174, 238], "cty": 94, "cty_id": [96, 118, 143, 144, 149, 224], "cultur": 209, "curli": 25, "current": [31, 37, 44, 49, 61, 62, 67, 83, 103, 107, 108, 129, 188, 213, 220, 223], "curti": 209, "curv": [9, 157, 170], "custom": [213, 239], "cute": 209, "cv": [52, 53, 213, 231, 235, 236, 239], "cvparam": [195, 196], "cy": 101, "d": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 53, 54, 57, 58, 59, 60, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 79, 80, 84, 85, 86, 87, 89, 91, 93, 94, 96, 97, 99, 100, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 116, 118, 127, 128, 129, 134, 135, 136, 137, 139, 140, 141, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 155, 156, 157, 158, 159, 160, 161, 162, 164, 165, 166, 167, 168, 169, 171, 172, 174, 177, 179, 181, 182, 183, 184, 185, 186, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 209, 212, 213, 215, 218, 219, 220, 221, 225, 226, 227, 228, 229, 231, 234, 235, 236, 237, 238, 239], "d0s0": 40, "d17": [205, 209], "d2c05365ee2a": 223, "d330010a503a": 223, "d388b5ca68ff9192bab2f6b53a6cab13": 236, "d6": [186, 187, 194], "d6ed6aa86c31": 223, "d6v4adj": 54, "da": 101, "daemon": 223, "dai": [22, 23, 24, 25, 26, 27, 215, 218, 223, 229, 235, 238], "daltkinterfac": 9, "daniel": 64, "dark": 209, "data": [46, 52, 53, 54, 56, 63, 84, 89, 91, 114, 127, 129, 143, 144, 145, 149, 168, 183, 186, 187, 189, 190, 194, 199, 206, 207, 209, 212, 215, 221, 222, 223, 229, 231, 232, 234, 235, 236, 238], "databas": [0, 21, 24, 25, 26, 61, 89, 107, 108, 113, 127, 146, 165, 167, 177, 184, 185, 206, 212, 213, 215, 218, 219, 220, 221, 223, 225, 226, 228, 237, 238, 239], "databs": [15, 29, 36, 182], "datafram": 205, "dataset": [205, 207, 221, 228, 229], "date": [62, 65, 199, 212, 219, 237, 238], "date_field": [7, 8, 93, 125, 126, 192], "datetim": [65, 212, 219, 237, 238], "dateutil": 206, "db": [100, 107, 218, 220], "db_engin": [8, 220], "dbscan": [89, 127, 130, 215], "dc2005cd24a6": 223, "dch": 229, "dd": [46, 168], "dd_agelex1gram": 168, "dd_agelex1gramstop": [46, 168], "dd_argument": [46, 168], "dd_emnlp14_agegend": [1, 236], "dd_genderlex1gram": 46, "dd_intaff": 1, "dd_paprefut": 1, "dd_permav3": 1, "dd_sperma_v2": 1, "ddla": 208, "de": 101, "deal": 229, "death": [41, 54], "decid": [228, 235], "decim": 224, "decis": [89, 127, 215], "decomposit": [89, 127, 215], "decreas": [218, 235], "dedupl": [0, 8, 47], "deep": [213, 239], "def": 45, "def_lexicon_db": 206, "def_low_variance_threshold": 99, "defam": 229, "default": [0, 58, 59, 65, 73, 107, 206, 212, 213, 214, 219, 220, 221, 223, 224, 228, 232, 235, 236, 237, 238, 239], "defin": [52, 53, 214, 220, 224, 229], "definit": 221, "degrad": 209, "degre": 209, "delet": 41, "deletem": [45, 137, 155, 156, 160, 161, 162], "deletemegend": [156, 157], "delimit": 231, "deliv": [191, 212], "democrat": 96, "demog_ag": [86, 87, 139], "demog_gend": 139, "demograph": 41, "demonstr": [205, 209], "denmark": [205, 209], "dens": 234, "densify_t": 0, "densiti": [89, 127, 215, 232], "depend": [15, 18, 40, 220, 222, 228, 229, 235, 238], "dependeci": 220, "depol": 107, "depolar": 107, "depress": [35, 79, 85, 209], "deriv": [1, 224, 228], "descend": 231, "descplot": 8, "describ": [65, 212, 219, 221, 224, 229, 234, 238], "describe_t": [0, 8, 237], "descript": [215, 221, 225, 236], "descstat": [2, 208], "desk": 27, "despit": 64, "destruct": 212, "det": [18, 238], "detach": 223, "detail": [121, 124, 139, 154, 169, 175, 176, 178, 186, 194, 213, 235, 239], "detect": 209, "determin": [16, 53, 96, 160, 204, 224, 227, 228, 235], "develop": [46, 168, 205, 209, 211, 236], "developerwork": 206, "development": 209, "deviat": [143, 145, 224, 227], "diab_perc": [114, 144, 149, 186, 187, 194], "diachron": 209, "dialog": 218, "dic": 107, "dicfil": 107, "dictat": 169, "dictionari": [46, 52, 53, 168, 209], "did": 212, "differ": [20, 21, 27, 46, 61, 108, 164, 168, 209, 212, 219, 221, 228, 229, 235, 236, 238], "differenti": [206, 209, 211, 218, 234, 235, 236], "difficult": 206, "digit": 209, "dimens": [213, 222, 239], "dimension": [89, 127, 205, 215], "dimensionreduc": 0, "dir": 223, "direct": [118, 206], "directli": [211, 214, 222], "directori": [0, 40, 116, 151, 171, 218, 221, 223, 228, 229, 231], "dirichlet": [10, 221], "disabl": [134, 135, 137, 228, 237], "disadvantag": 180, "disclosur": 209, "discrimin": [89, 127, 195, 215], "discuss": [213, 239], "diseas": [40, 44, 45, 209, 211], "diseasesond6s4": [41, 45], "disord": 209, "distinct": [35, 39, 79, 85, 128, 202, 213, 215, 218, 221, 234, 239], "distinguish": [46, 168, 227], "distress": 209, "distribut": [1, 29, 37, 41, 45, 107, 143, 145, 183, 206, 209, 215, 221, 228], "divid": [80, 143, 145, 221, 223, 224, 227], "divis": 180, "dla": [96, 99, 147, 206, 211, 218, 229, 234, 235, 236], "dla_tutori": [1, 11, 13, 16, 18, 21, 22, 23, 24, 25, 26, 31, 32, 33, 34, 39, 46, 47, 48, 49, 52, 53, 58, 59, 63, 64, 65, 67, 68, 69, 70, 71, 73, 86, 87, 93, 94, 99, 101, 107, 111, 112, 113, 128, 129, 139, 147, 148, 150, 151, 158, 159, 166, 167, 168, 172, 174, 177, 179, 183, 184, 191, 192, 198, 199, 200, 201, 202, 203, 206, 212, 213, 214, 215, 219, 220, 221, 223, 225, 226, 227, 228, 229, 231, 232, 234, 235, 236, 237, 238, 239], "dlaconst": [0, 99, 192, 206, 214, 232], "dlatk": [0, 1, 14, 24, 49, 72, 94, 99, 102, 103, 104, 105, 107, 116, 134, 135, 140, 141, 171, 205, 206, 207, 211, 212, 215, 220, 221, 224, 225, 226, 229, 231, 235, 238], "dlatk_dir": 223, "dlatk_dock": 223, "dlatk_lexica": [0, 49, 100, 107, 167, 206, 212, 215, 220, 221, 229], "dlatk_path": 49, "dlatk_tool": 0, "dlatkemnlp2017": [205, 209], "dlatkinterfac": [0, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 63, 64, 65, 67, 68, 69, 70, 71, 73, 79, 80, 84, 85, 86, 87, 89, 91, 93, 94, 96, 99, 101, 107, 111, 112, 113, 114, 118, 128, 129, 147, 148, 149, 150, 151, 158, 159, 166, 167, 168, 172, 174, 177, 179, 183, 184, 187, 191, 192, 198, 199, 200, 201, 202, 203, 205, 206, 208, 212, 213, 214, 215, 218, 219, 220, 221, 223, 224, 225, 226, 227, 228, 229, 231, 234, 235, 236, 237, 238, 239], "dlawork": 0, "dm_uncomp": [9, 35, 37, 79, 85], "do": [24, 26, 38, 40, 42, 43, 44, 46, 52, 53, 54, 81, 91, 93, 99, 103, 106, 118, 124, 129, 136, 137, 147, 154, 189, 190, 195, 196, 201, 206, 207, 212, 213, 214, 215, 218, 220, 221, 222, 224, 229, 234, 235, 236, 239], "dobj": [18, 238], "doc": [14, 15, 53, 54, 89, 91, 96, 110, 118, 127, 136, 137, 139, 142, 143, 144, 145, 153, 155, 156, 157, 158, 159, 160, 161, 162, 164, 165, 169, 170, 173, 180, 186, 187, 189, 190, 191, 194, 195, 196, 223, 229], "docker": [0, 206], "dockerhub": [205, 223], "document": [0, 38, 80, 94, 102, 106, 191, 223, 229, 235], "doe": [44, 52, 53, 96, 103, 129, 189, 190, 206, 207, 209, 213, 214, 220, 221, 223, 225, 236], "doesn": [20, 45, 213, 222], "doi": 209, "domain": 209, "don": [41, 99, 156, 158, 159, 161, 162, 203, 209, 213, 221, 223, 239], "done": [21, 28, 41, 52, 53, 57, 118, 139, 195, 196, 218], "doubl": [218, 221, 224], "down": [27, 221, 223, 229], "download": [18, 206, 213, 218, 223, 228, 229, 239], "downsid": 229, "downstream": 166, "dp_id": [12, 15, 29, 36, 89, 127, 182], "dp_mort_rat": [114, 144, 149, 186, 187, 194], "dri": 229, "drink": 209, "driven": [1, 46, 168, 209, 221, 236], "drop": [0, 218, 237, 238], "dt": [18, 238], "dual": [209, 236], "dumblob": 220, "dummi": [27, 234], "dummy_t": [177, 237], "dump": [220, 231], "duplic": [0, 47, 64, 138, 188, 229, 238], "dure": [0, 29, 36, 42, 43, 107, 111, 119, 120, 139, 166, 182, 206, 212, 221], "dz": 101, "dziurzynski": 209, "e": [0, 16, 17, 27, 37, 38, 46, 51, 52, 54, 63, 74, 93, 96, 101, 107, 137, 138, 143, 156, 157, 158, 159, 161, 162, 168, 188, 192, 200, 203, 209, 213, 214, 218, 221, 224, 228, 229, 239], "e0155885": 209, "e0194290": 209, "e16191": 209, "e241": 209, "e571dcc7fa1a6f1ebb1aba8d05d39b5c": 236, "e73791": 209, "e73b38988d4a277a1ac12c258fb33a14": 236, "e80dfb6a4adf": 223, "each": [1, 9, 16, 17, 18, 22, 23, 37, 44, 52, 53, 54, 74, 91, 94, 107, 124, 130, 143, 145, 148, 156, 159, 162, 165, 173, 183, 191, 197, 206, 212, 213, 218, 219, 221, 224, 227, 231, 234, 235, 236, 238, 239], "earlier": [118, 213, 239], "earliest": 213, "easi": 223, "easiest": 206, "easili": 228, "eating_di": [35, 79, 85], "echo": 223, "edinfo11_11_14": 181, "edit": [206, 229], "edu": [206, 228, 229], "educ": [39, 128], "education__multiclass": 128, "education_colleg": 39, "education_highschool": 39, "education_phd": 39, "effect": [0, 48, 118, 197, 221, 222, 231], "effici": [46, 135, 168, 180, 223], "eg": 229, "eichstaedt": [46, 168, 205, 209], "eighth": 209, "either": [16, 17, 35, 39, 45, 46, 52, 53, 63, 72, 107, 118, 128, 168, 189, 190, 202, 206, 232, 235], "el": 101, "elasticnet": [196, 222, 235], "elasticnetcv": 196, "elect": 209, "eleph": 229, "elif": 94, "els": [94, 127, 152, 212, 221, 229], "email": [209, 212], "emb": [213, 239], "emb_lay": [8, 13, 67, 69, 70], "emb_layer_aggreg": [8, 239], "emb_model": [8, 67, 68, 70], "emb_msg_aggreg": [8, 13, 67, 68, 69, 239], "embed": [34, 68, 70, 211, 213, 239], "emnlp": [46, 168, 209], "emoji": 21, "emoji_label_word": 21, "emot": 209, "emp_50nmf_fbcp": 215, "empathi": 209, "empir": [46, 168, 205, 209], "empti": 94, "en": [47, 101, 164, 165, 219], "enabl": [35, 98, 116, 202, 213, 218, 237, 239], "encod": [0, 7, 8, 16, 17, 46, 93, 139, 159, 168, 192, 218, 222, 224, 227, 234], "encoding_typ": 71, "encount": 229, "end": [22, 39, 52, 53, 54, 64, 73, 128, 193, 205, 213, 221, 223, 229, 235, 236, 239], "engag": 209, "engin": [63, 129, 218], "english": [101, 221, 229], "enough": 235, "ensembl": 0, "ensur": [183, 213, 235, 239], "enter": [179, 219, 223], "entir": [118, 228, 235], "entri": [215, 218, 229, 236], "entrypoint": 223, "env": [206, 223], "environ": [49, 223], "environment": 209, "eo": 101, "equal": [107, 135, 192, 235], "equat": [46, 168], "equival": [28, 93, 96, 135, 143], "er10k": 96, "erm": 229, "error": [0, 53, 118, 160, 209, 224, 229, 235, 236], "especi": 212, "essenti": [52, 53, 91, 213, 239], "estim": [72, 104, 116, 135, 140, 141, 171, 209, 222, 223], "estimate_lda_top": [8, 102, 103, 104, 105, 116, 134, 135, 140, 141, 171, 228], "et": [101, 209, 236], "eta": 215, "etc": [0, 29, 36, 40, 54, 64, 74, 92, 94, 99, 109, 111, 137, 142, 146, 150, 180, 182, 189, 190, 195, 196, 212, 222, 229, 235], "eu": 101, "evalu": [195, 196, 223], "even": 229, "everi": [39, 57, 128, 137, 143, 145, 157, 173, 195, 196, 221, 224, 227, 231, 234, 238], "everyth": [18, 27, 127, 206, 207, 215, 221], "everywher": 212, "evid": 209, "exact": [40, 231, 235], "exactli": [213, 239], "exam": 229, "exampl": [127, 137, 142, 143, 144, 145, 153, 155, 156, 157, 160, 161, 162, 165, 170, 173, 180, 212, 213, 220, 221, 223, 226, 229, 234, 236, 237, 239], "excel": 1, "except": [0, 14, 18, 94, 96, 148, 214, 222, 227, 229], "excess": 209, "excessdrink_perc": 153, "excit": [164, 209], "exec": 223, "exist": [12, 15, 19, 20, 107, 129, 145, 206, 218, 220, 223, 225, 237], "exit": [107, 215, 218, 221, 223, 235], "expand": [89, 107, 127, 215], "expand_lexicon": 107, "expect": [74, 213, 221, 222, 224, 229, 239], "expens": 180, "experi": 209, "explain": [40, 224, 235], "explan": [52, 97, 157], "explicit": [212, 235], "explicitli": [93, 174, 192], "explor": [209, 221], "export": 211, "express": [164, 209], "ext": 234, "extens": [0, 8, 24, 238], "extern": 0, "extra": [0, 65, 147, 212, 219, 221, 224, 227, 229, 235, 237, 238], "extra_stopwords_fil": 229, "extract": [0, 16, 17, 19, 20, 21, 29, 36, 38, 46, 51, 63, 74, 80, 84, 94, 100, 106, 111, 113, 129, 136, 139, 168, 182, 185, 198, 205, 206, 209, 213, 215, 235, 237, 239], "extratre": [195, 196], "extravers": 221, "extrem": 222, "extreme_red_10000": 96, "f": [7, 8, 9, 10, 12, 15, 27, 28, 30, 35, 37, 40, 41, 42, 43, 44, 45, 46, 48, 51, 52, 53, 56, 57, 60, 65, 72, 79, 80, 81, 82, 83, 84, 85, 86, 87, 89, 91, 93, 94, 96, 97, 99, 102, 103, 104, 105, 107, 109, 110, 112, 114, 116, 118, 124, 127, 134, 135, 137, 139, 140, 141, 143, 144, 145, 147, 148, 149, 150, 151, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 164, 166, 167, 168, 169, 171, 172, 173, 181, 183, 186, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 201, 202, 209, 212, 213, 214, 215, 218, 221, 226, 227, 228, 229, 231, 232, 234, 235, 236, 239], "f0": 224, "f1": [0, 236], "f5": 224, "f_classif": 236, "f_regress": [53, 87, 195, 196, 235], "fa": 101, "face": [33, 69, 213], "facebook": [114, 144, 149, 186, 187, 194, 209, 212, 221, 229, 234, 235, 236], "facilit": 49, "facor": 215, "fact": [19, 20, 27, 221], "factor": [0, 89, 127, 213, 215, 221, 239], "fairli": 235, "fals": [45, 53, 92, 107, 137, 142, 147, 148, 180, 195, 196, 213, 215, 231, 232, 235, 236, 239], "famili": 235, "fando": 232, "fando_df": 232, "faq": 206, "fast": [180, 222], "faster": 221, "faulti": 229, "fb": [228, 229], "fb20": [19, 20, 57, 91, 137, 155, 156, 157, 160, 161, 162], "fb2000_intr": 145, "fb22": [80, 84, 164], "fb22_messagesen": 198, "fb2eecbe942c268e0d47a377dde7831a": 236, "fbtopic": 231, "fbtopic_output": 221, "fbtopic_output_topic_tagcloud": 221, "fbtopic_output_topic_tagcloud_wordcloud": 221, "fbtopics_topic_tagcloud_wordcloud": 231, "fdr": 152, "fe": 214, "feat": [9, 10, 12, 15, 16, 17, 19, 20, 27, 28, 29, 35, 36, 37, 40, 41, 44, 45, 46, 48, 51, 52, 53, 57, 60, 73, 74, 79, 80, 83, 84, 85, 86, 87, 89, 91, 93, 94, 96, 99, 111, 112, 113, 114, 118, 127, 136, 137, 139, 143, 144, 145, 147, 149, 150, 151, 153, 155, 156, 157, 158, 159, 160, 161, 162, 164, 166, 167, 168, 169, 172, 173, 181, 182, 183, 186, 187, 191, 192, 193, 194, 197, 198, 200, 201, 202, 203, 204, 212, 213, 214, 215, 218, 221, 222, 224, 226, 227, 228, 229, 231, 232, 234, 235, 236, 237, 239], "feat1": [79, 85], "feat2": [79, 85], "feat_1": 110, "feat_as_control": [8, 118, 124], "feat_as_outcom": [8, 118, 124], "feat_as_path_start": [8, 118, 124, 154], "feat_blacklist": [7, 8, 35, 202], "feat_colloc_filt": [7, 8, 16, 17, 19, 20, 51, 176, 212, 222, 224], "feat_correl_filt": [7, 8], "feat_flexibin": [8, 90], "feat_n": 110, "feat_nam": [7, 8], "feat_occ_filt": [7, 8, 16, 17, 19, 20, 51, 94, 175, 198, 203, 212, 218, 221, 222, 224], "feat_select": 86, "feat_selection_str": [0, 87], "feat_sourc": 12, "feat_tabl": [7, 56, 74, 186, 194], "feat_whitelist": [7, 8, 35, 83, 145, 165, 202, 229], "featcolloclin": 164, "featlabelmaplex": [93, 192], "featlabelmapt": [93, 192], "featnam": [93, 192], "feattabl": [93, 192, 214, 226, 232], "featur": [0, 9, 11, 12, 13, 15, 16, 17, 27, 29, 31, 32, 33, 34, 35, 36, 38, 40, 41, 42, 44, 45, 46, 51, 52, 53, 54, 56, 57, 61, 67, 68, 69, 70, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 89, 91, 94, 96, 97, 99, 100, 107, 108, 110, 111, 113, 118, 124, 132, 133, 136, 137, 139, 143, 145, 147, 148, 150, 153, 154, 156, 157, 158, 159, 160, 161, 162, 164, 168, 172, 173, 175, 177, 182, 185, 191, 194, 195, 196, 197, 198, 200, 202, 205, 206, 209, 215, 222, 223, 227, 231, 235, 236], "feature_select": [7, 8, 222, 235], "feature_selection_str": [7, 8, 235], "feature_t": [89, 127], "feature_table_nam": [89, 118, 124, 154], "feature_type_nam": [8, 198], "featureextractor": [208, 214], "featuregett": [83, 192, 195, 196, 208, 214, 226, 235], "featurerefin": [208, 214], "featureselectionstr": [87, 195, 196, 222], "featurestar": [208, 226, 232], "featurework": [0, 138, 152, 188, 208, 214], "fed": [195, 196], "feel": 212, "femal": [39, 199, 218, 221, 236, 237], "femalepop165210d": [41, 54], "few": [222, 235, 237], "fg": [83, 214, 232], "fg_gn": 232, "fg_spars": 232, "fg_val": 232, "fg_vgn": 232, "fg_zgn": 232, "fg_zgns_piv": 232, "fi": 101, "field": [18, 27, 38, 39, 62, 65, 94, 107, 113, 125, 126, 128, 139, 143, 144, 149, 156, 162, 200, 212, 218, 219, 221, 224, 237, 238], "field1": 143, "field2": 143, "field3": 224, "field4": 224, "fifth": 209, "fiftycheck": 0, "figur": 118, "file": [0, 1, 14, 21, 40, 45, 54, 90, 93, 96, 107, 109, 114, 115, 121, 129, 138, 139, 151, 155, 158, 159, 165, 171, 172, 188, 192, 197, 207, 211, 214, 218, 220, 221, 223, 225, 228, 232, 234, 235, 236], "file_nam": [89, 127], "filenam": [0, 93, 107, 138, 151, 188, 192], "fillna": 232, "film": 229, "filter": [0, 47, 80, 84, 94, 101, 107, 135, 138, 140, 164, 188, 195, 196, 198, 201, 221, 222, 224], "final": [32, 68, 221, 234, 236], "find": [40, 44, 89, 96, 107, 127, 155, 207, 215, 218, 229, 235], "finest": [212, 221], "finish": 236, "fip": [94, 224], "first": [27, 40, 44, 52, 53, 64, 68, 94, 96, 118, 158, 159, 166, 199, 213, 215, 218, 219, 220, 221, 222, 223, 224, 231, 236, 239], "fit": [44, 89, 127, 195, 196, 212], "fit_intercept": [53, 213, 231, 235, 236, 239], "fit_reduc": [0, 7, 8, 127, 130, 166, 167, 180, 184, 215], "fit_transform": 0, "five": 199, "fix": [0, 21], "flag": [0, 40, 44, 47, 48, 49, 57, 64, 65, 86, 93, 94, 99, 107, 129, 137, 139, 191, 192, 199, 205, 206, 212, 213, 215, 218, 219, 220, 221, 224, 226, 227, 229, 231, 234, 235, 236, 237, 238, 239], "flat": 229, "flekova": 209, "flexiplot_fil": [8, 82], "flexiplotfil": 90, "fo": 101, "focu": 221, "fold": [0, 7, 8, 28, 52, 53, 54, 99, 150, 157, 183, 213, 235, 236, 239], "fold_column": 0, "folder": [206, 229], "folds_acc": 236, "folds_auc": 236, "folds_f1": 236, "folds_mfclass_acc": 236, "folds_precis": 236, "folds_recal": 236, "folds_rho": 236, "folds_se_acc": 236, "folds_se_auc": 236, "folds_se_f1": 236, "folds_se_mfclass_acc": 236, "folds_se_precis": 236, "folds_se_recal": 236, "folds_se_rho": 236, "follow": [14, 16, 17, 29, 36, 41, 53, 57, 64, 74, 80, 89, 94, 101, 111, 118, 127, 129, 130, 157, 160, 165, 182, 187, 195, 196, 205, 206, 207, 209, 211, 212, 213, 214, 215, 218, 219, 220, 221, 223, 224, 225, 227, 228, 229, 231, 234, 235, 236, 238, 239], "foo": [99, 227], "foo_binari": 227, "food_insec_perc": [114, 144, 149, 186, 187, 194], "forc": 207, "forecast": 209, "forget": 235, "forgnbornhc03_vc134acs3yr": [41, 54], "form": [15, 40, 221, 229, 234, 239], "format": [1, 40, 74, 107, 139, 164, 169, 180, 203, 211, 215, 218, 220, 221, 223, 234], "formula": [29, 36, 111, 182], "found": [64, 87, 95, 113, 124, 154, 177, 206, 207, 221, 235, 237, 239], "four": [32, 68, 221, 224, 227], "fr": [101, 214], "free_lunch_perc": [144, 149], "freq": [8, 221, 227, 229, 231, 232], "freq_t50ll": [215, 229], "frequeci": 235, "frequenc": [16, 17, 29, 36, 46, 74, 92, 94, 111, 168, 182, 193, 212, 221, 223, 224, 229, 235], "frequent": [140, 157, 228], "friend": [22, 23, 24, 25, 26, 164, 238], "frisbe": 26, "from": [0, 1, 9, 14, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 32, 33, 44, 46, 47, 52, 53, 54, 58, 59, 61, 69, 73, 89, 91, 93, 94, 96, 100, 106, 107, 108, 113, 114, 127, 137, 139, 143, 145, 150, 154, 155, 156, 161, 162, 164, 165, 168, 172, 179, 183, 185, 191, 192, 195, 196, 199, 200, 206, 209, 211, 213, 214, 215, 218, 219, 220, 221, 222, 224, 225, 227, 231, 232, 234, 236, 237, 238, 239], "from_fil": [7, 8, 192, 226], "fromfil": [192, 214, 226, 232], "fuck": 27, "full": [107, 213, 218, 220, 235], "fulli": [33, 206], "fun": [24, 27, 212], "function": [27, 34, 40, 46, 53, 62, 70, 91, 125, 126, 168, 195, 196, 206, 235, 236], "funtion": 222, "further": [41, 49], "futur": [172, 209], "fw": 214, "fwconstant": 208, "fwflag_01": 53, "fwflag_05": 153, "fwflag_add_char_ngram": 7, "fwflag_ascii": 139, "fwflag_bas": [89, 127], "fwflag_bert_no_context": 31, "fwflag_bert_word_aggreg": [31, 213], "fwflag_block": [127, 137, 142, 143, 144, 145, 153, 155, 156, 157, 160, 161, 162, 165, 169, 170, 173, 180, 186, 194], "fwflag_c": [96, 187], "fwflag_cca_penaltyx": 40, "fwflag_cca_penaltyz": 40, "fwflag_combo_rmatrix": 35, "fwflag_combo_s": 54, "fwflag_combo_test_reg": 180, "fwflag_control": [52, 53, 76, 118, 144, 186, 187, 194], "fwflag_control_adjust_reg": [7, 86, 180], "fwflag_convex": [89, 127], "fwflag_corpdb": [66, 110], "fwflag_correl": 96, "fwflag_csv": 96, "fwflag_d": [96, 187], "fwflag_ddlatagcloud": [7, 153, 187], "fwflag_emb_layer_aggreg": [13, 68, 69, 70, 239], "fwflag_ex_log": 7, "fwflag_f": [96, 187], "fwflag_feat_group_by_outcom": 7, "fwflag_feat_t": [110, 186, 194], "fwflag_feature_nam": [30, 173], "fwflag_fit": [189, 190], "fwflag_fold": 91, "fwflag_gram": [15, 136, 164], "fwflag_group_freq_thresh": 96, "fwflag_h": [7, 169], "fwflag_idf": 191, "fwflag_interaction_ddla": 96, "fwflag_interaction_ddla_p": 96, "fwflag_kenni": 118, "fwflag_learn": [195, 196], "fwflag_lex_boolean": 7, "fwflag_lex_sqrt": 7, "fwflag_load_model": 127, "fwflag_mad": [158, 159, 195], "fwflag_make_all_topic_wordcloud": 231, "fwflag_make_topic_wordcloud": [144, 194, 221], "fwflag_make_wordcloud": 187, "fwflag_mean": [89, 127], "fwflag_model": 110, "fwflag_multir": [35, 98], "fwflag_n": [19, 20, 221], "fwflag_nearest": 110, "fwflag_neg": [89, 127], "fwflag_no_bonf": [96, 144, 153, 193, 194], "fwflag_no_bonferroni": [110, 118, 152, 181], "fwflag_not_show_feat_freq": 110, "fwflag_occur": 164, "fwflag_outcom": [96, 187], "fwflag_outcome_control": 96, "fwflag_outcome_t": [96, 187], "fwflag_output_dir": 110, "fwflag_output_interaction_term": 145, "fwflag_output_nam": [96, 187], "fwflag_parametr": 110, "fwflag_path_start": 144, "fwflag_pred_csv": [52, 54], "fwflag_predict_c2r": [127, 180], "fwflag_predict_class": [127, 180], "fwflag_predict_classifiers_to_outcome_t": 234, "fwflag_predict_combo_to_feat": [86, 127, 180], "fwflag_predict_cv_to_feat": [86, 127, 180], "fwflag_predict_reg": 180, "fwflag_predict_regression_all_to_feat": [86, 127, 180], "fwflag_probability_csv": [151, 231], "fwflag_rmatrix": 96, "fwflag_save_model": 127, "fwflag_scor": 137, "fwflag_show_feat_freq": 110, "fwflag_sort": 96, "fwflag_standard": 170, "fwflag_svc": 195, "fwflag_t": [96, 187], "fwflag_tagcloud": 187, "fwflag_tagcloud_colorschem": 187, "fwflag_test_c2r": [127, 180], "fwflag_test_combined_regress": [127, 180], "fwflag_to_sql_t": 45, "fwflag_train_c2": 127, "fwflag_train_c2r": 180, "fwflag_train_class": 180, "fwflag_train_reg": 180, "fwflag_valu": 160, "fwflag_weighted_ev": 7, "fwflag_weighted_lex": 182, "fwinterfac": [7, 10, 27, 95, 127, 136, 137, 139, 143, 144, 145, 151, 153, 155, 156, 157, 160, 161, 162, 164, 165, 169, 181, 182, 186, 193, 194, 197, 213, 221, 224, 227, 231, 234, 239], "g": [0, 7, 8, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 31, 32, 33, 34, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 53, 54, 57, 64, 67, 68, 69, 70, 72, 73, 74, 86, 87, 89, 91, 94, 96, 97, 99, 100, 101, 102, 103, 104, 105, 107, 109, 111, 112, 113, 116, 118, 127, 128, 134, 135, 136, 137, 139, 140, 141, 143, 144, 145, 146, 147, 148, 150, 153, 155, 156, 157, 158, 159, 160, 161, 162, 164, 166, 167, 168, 169, 171, 172, 174, 179, 181, 182, 183, 184, 186, 189, 190, 191, 193, 194, 195, 196, 197, 200, 201, 209, 212, 213, 215, 218, 219, 221, 223, 224, 228, 229, 234, 237, 238, 239], "ga": 101, "gai": 229, "gain": 223, "gaussian": [29, 89, 127, 215], "gcv_mode": [53, 213, 231, 235, 236, 239], "gemini": 128, "gender": [39, 46, 48, 52, 53, 57, 65, 91, 93, 94, 99, 112, 128, 147, 148, 151, 156, 157, 158, 159, 168, 192, 199, 201, 202, 209, 211, 214, 215, 218, 221, 226, 227, 231, 232, 236, 237], "gender_1_neg": 231, "gender_1_po": 231, "gender__f": 218, "gender__f_neg": 218, "gender__f_po": 218, "gender__femal": 39, "gender__mal": 39, "gender__withlanguag": 236, "gender_cat": [39, 128, 199, 237], "gender_correlates_logist": 112, "gender_correlates_logistic_d": 48, "gender_wordcloud": 218, "gender_wordclouds_tagcloud": 218, "gender_wordclouds_tagcloud_wordcloud": 218, "genderdummi": [158, 159], "genderlex1gram": 46, "gener": [1, 15, 40, 45, 60, 84, 89, 107, 110, 127, 143, 145, 165, 178, 187, 193, 198, 205, 213, 215, 222, 223, 224, 226, 227, 239], "genr": 218, "geograph": 209, "georgi": 229, "georgia": 209, "gerlof": 80, "get": [21, 24, 25, 37, 39, 40, 42, 43, 44, 46, 52, 53, 107, 143, 168, 207, 213, 214, 221, 223, 235, 239], "getgroupandoutcomevaluesasdf": 232, "getgroupnormsasdf": 232, "getgroupnormswithzerosasdf": 232, "getgroupsandoutcom": 128, "getgroupsandoutcomesasdf": 232, "getvaluesandgroupnormsasdf": 232, "getvaluesasdf": 232, "gfile": 107, "gft": [197, 222], "gft0": [41, 45], "gft500": [234, 235], "gi_sx": [35, 79, 85], "giant": 229, "gibb": 104, "gift": [179, 219], "giorgi": [205, 209], "girl": 27, "git": [206, 220, 223], "github": [1, 205, 220, 223], "give": [28, 35, 58, 59, 202, 214, 221, 223, 224, 235, 236], "given": [12, 15, 16, 17, 18, 37, 45, 57, 64, 74, 75, 79, 80, 81, 83, 85, 93, 94, 107, 110, 113, 118, 136, 138, 148, 156, 157, 158, 159, 160, 161, 162, 173, 175, 177, 188, 192, 195, 196, 197, 212, 221, 227, 229, 231, 237], "gl": 101, "gloss": [213, 239], "gmm": [89, 127, 130, 215], "gnu": 205, "go": [22, 23, 24, 25, 26, 118, 212, 221, 223, 235, 238, 239], "goe": [27, 80, 218], "gonna": 24, "good": [42, 43, 89, 127, 158, 159, 195, 196, 215, 218, 222, 228, 229, 235], "googl": [49, 107], "got": [22, 23, 24, 25, 26, 164, 238], "goyal": 209, "gpl": 223, "gplv3": 205, "gpt2": 0, "gra": 15, "gradient": [89, 127, 215], "gram": [12, 15, 16, 74, 80, 85, 198, 203, 224, 234], "grammat": [18, 238], "graphic": 223, "great": [22, 23, 24, 25, 26, 238], "greater": [94, 150], "grep": 223, "group": [0, 12, 16, 17, 27, 29, 36, 38, 39, 40, 41, 44, 45, 46, 54, 57, 64, 84, 94, 96, 106, 107, 111, 113, 128, 142, 143, 145, 156, 157, 158, 159, 160, 161, 162, 164, 168, 175, 179, 182, 195, 196, 201, 203, 204, 212, 213, 215, 218, 219, 221, 224, 232, 234, 235, 237, 238, 239], "group_by_field": [12, 15, 29, 36, 38, 182], "group_column": 221, "group_freq_thresh": [7, 8, 9, 10, 12, 15, 28, 29, 35, 36, 37, 40, 41, 44, 45, 48, 52, 53, 54, 57, 79, 84, 85, 86, 87, 89, 93, 110, 112, 114, 118, 127, 139, 143, 145, 147, 148, 151, 153, 157, 160, 161, 170, 175, 181, 182, 189, 190, 192, 193, 194, 195, 196, 197, 202, 203, 212, 213, 215, 218, 221, 222, 226, 227, 234, 235, 236, 239], "group_frequ": 198, "group_id": [16, 17, 27, 34, 51, 70, 74, 94, 158, 159, 161, 164, 191, 197, 203, 212, 213, 215, 218, 221, 224, 228, 229, 232, 234, 236, 239], "group_id_rang": 82, "group_norm": [16, 17, 27, 57, 74, 137, 143, 145, 164, 191, 197, 212, 213, 215, 218, 221, 224, 227, 232, 234, 236, 239], "group_thresh": [89, 118, 127], "groupfreqthresh": [45, 93, 192, 226], "groupswher": 232, "groupthresh": 232, "gu": 101, "guntuku": 209, "gz": [14, 229], "h": [46, 107, 168, 205, 209, 223], "ha": [14, 16, 17, 27, 38, 39, 58, 59, 119, 120, 143, 145, 157, 185, 206, 209, 212, 221, 222, 223, 224, 239], "habit": 221, "had": 221, "hagan": 209, "hahah": 26, "hair": [25, 26], "half": 229, "halfwai": 221, "hand": 221, "happen": 57, "happi": [16, 17, 24, 80, 95, 238], "happier": [24, 212], "happierfuntoken": [2, 208], "hard": 222, "hardcod": [0, 138, 188], "hashtag": [64, 101], "hasn": [46, 168], "hate": 218, "have": [0, 16, 17, 21, 26, 33, 39, 40, 41, 44, 46, 51, 52, 53, 61, 80, 96, 99, 108, 109, 128, 146, 147, 156, 158, 159, 161, 162, 168, 195, 196, 198, 200, 203, 206, 209, 213, 214, 215, 218, 219, 220, 221, 222, 223, 227, 228, 229, 232, 234, 235, 236, 237, 239], "haven": 215, "he": [101, 212, 229], "head": [229, 232], "health": 209, "health_care_cost": [144, 149], "heap": 229, "heart": [27, 165, 209, 211], "heavili": 237, "heidi": 223, "hello": [16, 17], "help": [44, 107, 219, 221, 222, 223, 229, 237], "her": [22, 23, 24, 25, 26, 212, 238], "here": [64, 143, 156, 157, 158, 159, 161, 162, 203, 206, 212, 213, 215, 218, 220, 221, 223, 224, 226, 227, 229, 231, 234, 235, 236, 239], "hi": 101, "hi_incom": [144, 149], "hide": [121, 124, 139, 154, 169, 175, 176, 178, 186, 194], "high": [89, 127, 128, 215, 237], "higher": [37, 42, 43, 80, 229], "highli": [89, 127, 206, 215], "highschool": [39, 128], "hilbert": 209, "hispanicpop405210d": [41, 54], "histogram": 66, "hitler": 229, "hiv_rat": [114, 144, 149, 186, 187, 193, 194], "hlab": 205, "hoc": 227, "hochberg": 152, "hold": [27, 198], "holm": 152, "home": [93, 107, 192, 220, 226, 228, 229, 235], "hommel": 152, "honei": 229, "hood": 209, "hopkin": 209, "host": [0, 7, 129, 220, 223, 239], "hot": [39, 218], "hour": 221, "how": [14, 16, 17, 21, 52, 53, 54, 74, 80, 84, 91, 206, 213, 221, 222, 224, 234, 235, 239], "howev": [49, 213, 228, 239], "hr": 101, "hr_rate": [144, 149], "hsgradhc03_vc93acs3yr": [41, 54, 118, 144, 149], "ht": 101, "html": [40, 139, 221], "http": [21, 33, 64, 69, 205, 206, 209, 220, 223, 228, 229, 238, 239], "hu": 101, "hug": [33, 69, 213], "huge": 239, "huggingfac": [0, 13, 33, 69, 205, 211], "human": [205, 209, 221], "hurt": 222, "hy": 101, "hyper": [222, 229], "hyperparamet": [102, 103], "i": [0, 12, 14, 15, 16, 17, 18, 21, 22, 23, 24, 25, 26, 27, 28, 31, 32, 37, 38, 39, 41, 42, 43, 45, 46, 47, 48, 49, 51, 52, 53, 54, 57, 58, 59, 61, 64, 67, 72, 73, 74, 76, 77, 78, 79, 80, 83, 84, 85, 86, 87, 89, 90, 91, 93, 94, 95, 96, 99, 101, 102, 103, 105, 107, 108, 109, 110, 112, 116, 117, 118, 119, 121, 122, 124, 127, 128, 130, 132, 135, 137, 138, 139, 143, 144, 145, 147, 148, 149, 150, 151, 152, 154, 156, 157, 158, 159, 161, 162, 164, 165, 166, 167, 168, 170, 171, 172, 173, 174, 176, 178, 179, 180, 183, 184, 185, 187, 188, 189, 190, 191, 192, 195, 196, 197, 198, 199, 201, 203, 204, 205, 206, 207, 212, 213, 214, 215, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 231, 232, 234, 235, 236, 237, 238, 239], "i_am_veri": 164, "icwsm": 209, "id": [0, 14, 22, 74, 94, 101, 107, 164, 165, 191, 212, 213, 215, 218, 219, 221, 223, 224, 231, 234, 236, 239], "idea": [42, 43], "ident": [64, 118, 164, 224], "identifi": [38, 101, 206, 209, 224], "ideologi": 209, "idf": [46, 168, 191], "idnani": 209, "idp": [8, 57], "ignor": [93, 103, 130, 139, 192, 215, 218, 221], "ignore_lin": 225, "ignorelin": 225, "ill": 209, "illustr": [213, 239], "im_rat": [114, 144, 149, 186, 187, 194], "imag": [138, 188, 206, 209], "image_nam": 223, "imai": 122, "immort": 229, "implement": [37, 40, 57], "import": [46, 49, 54, 94, 168, 172, 206, 207, 211, 213, 214, 223, 226, 228, 235, 239], "importerror": 207, "importmethod": [218, 225], "improv": [0, 27, 101, 137, 219], "inaccur": 209, "inappropri": 27, "includ": [28, 52, 53, 94, 107, 143, 145, 152, 172, 201, 218, 223, 224, 227, 236, 238, 239], "include_sub_colloc": [8, 198], "incorrectli": [0, 21], "increment": 0, "inde": [215, 218, 235], "independ": 154, "index": [14, 16, 17, 32, 51, 68, 74, 146, 213, 218, 224, 229, 232, 234, 239], "indic": [0, 46, 155, 168, 213, 221, 224, 229, 239], "individu": [89, 127, 209, 215, 221], "indunk": [199, 237], "ineff": 209, "infer": 223, "info": [54, 93, 109, 112, 172, 175, 176, 192, 206, 221, 223, 228, 229, 231, 232], "inform": [10, 29, 36, 74, 80, 106, 111, 182, 206, 209, 213, 221, 223, 229, 235, 236, 239], "information_schema": [199, 223, 237], "infrastructur": [21, 41, 109, 155, 172, 195, 196, 203, 221, 229], "ini": [93, 192, 211], "init": [93, 192, 214, 215, 232], "initfil": 192, "initi": [27, 110, 213, 214, 215, 218, 221, 232, 235], "inner": [27, 236], "inproceed": [205, 209], "input": [90, 164, 165, 223, 226, 229], "inquiri": 221, "insert": [0, 16, 17, 27, 156, 161, 162, 218, 221, 228, 229, 237], "insid": [0, 76, 77, 78, 201, 212, 215, 219, 221, 237, 238], "insight": [46, 168, 209, 212], "inspect": [223, 229], "instal": [0, 1, 49, 116, 205, 213, 220, 228, 229, 239], "instanc": [89, 99, 107, 127, 156, 158, 159, 161, 162, 214, 215, 218, 223, 234], "instanti": 214, "instead": [0, 9, 10, 27, 112, 116, 164, 181, 214, 228], "instruct": [223, 228], "int": [65, 179, 212, 219, 221, 224, 235, 237, 238], "integ": [0, 91, 94, 117, 128, 218], "intens": 1, "inter": [96, 227], "interact": [0, 8, 57, 71, 96, 99, 118, 145], "interaction_ddla": [7, 8, 35, 48, 97, 112, 227], "interaction_ddla_pvalu": [8, 96], "interaction_output": 227, "intercept": [143, 236], "intercept_sc": 236, "interest": 227, "interfac": [0, 14, 72, 102, 103, 104, 105, 107, 116, 134, 135, 140, 141, 171, 211, 215, 218, 221, 223, 224, 235], "interg": 39, "interim": [134, 171, 228], "intermedi": [27, 223], "intern": 209, "internet": 209, "interpret": [31, 67, 213, 239], "intersect": 107, "interv": [0, 57, 227], "intervent": 209, "intro": [211, 213, 221, 228, 229, 234, 235, 239], "introduc": 228, "introduct": 211, "intuit": 80, "involv": [118, 221], "io": 209, "ip": 223, "ipaddress": 223, "is_educ": [39, 65, 147, 148, 199, 214, 221, 231, 232, 237], "is_education__withlanguag": 231, "is_education_neg": 231, "is_education_po": 231, "is_indunk": [65, 199, 237], "is_spam": [179, 219], "is_stud": [39, 65, 93, 147, 148, 192, 199, 221, 226, 231, 237], "is_student__withlanguag": 231, "is_student_neg": 231, "is_student_po": 231, "is_technologi": [39, 65, 147, 148, 199, 221, 231, 237], "is_technology__withlanguag": 231, "is_technology_po": 231, "isblack": [9, 10, 28, 35, 37, 79, 85, 181], "ishispan": [9, 10, 28, 35, 37, 79, 85, 181], "isn": [16, 17], "isol": 209, "issu": [0, 207, 229], "iswhit": [9, 10, 28, 35, 37, 79, 85, 181], "italian": 229, "italic": 16, "item": [16, 52, 53, 218], "iter": [37, 44, 104, 235], "iterated_pow": [53, 195, 196, 235, 236], "its": [23, 27, 107, 138, 165, 188, 212, 223], "itself": 20, "iuc": 209, "j": [1, 46, 168, 209], "ja": 101, "jaidka": 209, "japanes": 213, "jare": 229, "jason": [221, 232], "java": 229, "jha": 209, "jill": 229, "jmir": 209, "joe": 229, "johann": [205, 209], "join": [21, 27, 164, 236], "joint": 209, "jopi": 209, "jordan_msa": 145, "journal": [209, 221], "jr": 209, "json": [24, 218, 229], "jsonl": 218, "jsonrpclib": 206, "juli": [199, 209, 237], "jump": 235, "june": [198, 209, 229], "just": [20, 27, 52, 53, 57, 74, 80, 165, 172, 195, 213, 221, 239], "jv": 101, "k": [40, 52, 53, 54, 89, 110, 127, 209, 215, 236], "k10": [41, 45], "k15": 40, "ka": 101, "kapeln": 209, "kazadoom": 229, "keel": 122, "keep": [58, 59, 84, 89, 99, 127, 212, 213, 215, 219, 224, 226, 229, 235, 237, 239], "keep_dupl": 0, "keep_low_vari": 99, "keep_low_variance_outcom": [0, 8], "keep_underscor": 0, "kei": [65, 212, 218, 219, 221, 224, 228, 229, 237, 238], "kenni": [118, 122], "kept": 94, "kern": [46, 168, 209], "kernel": 195, "keyboard": 209, "keycach": 218, "kind": 224, "kit": 235, "kk": 101, "km": 101, "kmean": [89, 127, 130, 215], "kn": 101, "kno": 27, "knob": 235, "know": [213, 231, 239], "knowledg": 209, "known": 220, "ko": 101, "kokil": 209, "koppel": 1, "kosinski": [46, 168, 209], "kranzler": 209, "ku": 101, "kulkarni": 209, "ky": 101, "l": [0, 7, 8, 12, 15, 25, 29, 36, 73, 106, 107, 111, 113, 166, 182, 184, 200, 203, 209, 212, 213, 215, 221, 228, 229, 236, 237, 238, 239], "l1": [89, 127, 215, 222, 236], "l1_ratio": 215, "l1l2": 222, "l2": 222, "la": 101, "lab": 205, "labarth": 209, "label": [209, 221], "lakshmikanth": 209, "lang": [229, 231], "lang1": 101, "lang2": 101, "lang3": 101, "langid": [101, 206, 219], "languag": [0, 38, 46, 47, 52, 53, 86, 87, 96, 99, 101, 133, 143, 148, 156, 161, 162, 168, 206, 209, 211, 212, 218, 227, 234, 235, 236, 239], "language_filt": [0, 8, 47, 219], "lanugag": [47, 165], "laplacian": [89, 127, 215], "lar": 196, "larg": [33, 34, 69, 70, 203, 212, 213, 228, 229, 239], "larger": [80, 221, 235], "larson": 209, "lasso": [196, 222, 235, 236], "lassocv": 196, "lassolar": 196, "lassolarscv": 196, "last": [27, 31, 32, 67, 68, 213, 239], "latent": 221, "later": [110, 213, 239], "latest": 223, "lathf_perc": [114, 144, 149, 186, 187, 194], "latin1": [71, 139], "latin1_swedish_ci": 71, "latin2": 71, "latin2_general_ci": 71, "latter": 136, "law": 229, "layer": [31, 32, 67, 68, 213, 239], "lazaru": 209, "lb": 101, "lbp": 234, "lbp_age": 234, "lbp_gender": 158, "lbp_prob_gend": 159, "lda": [0, 14, 72, 89, 102, 103, 104, 105, 107, 116, 127, 130, 134, 135, 140, 141, 164, 171, 195, 205, 206, 212, 213, 215, 221, 224, 235, 239], "lda_alpha": [8, 72, 103, 104, 105, 116, 134, 135, 140, 141, 171, 228], "lda_beta": [8, 72, 102, 104, 105, 116, 134, 135, 140, 141, 171, 228], "lda_fil": 228, "lda_iter": [8, 72, 102, 103, 105, 116, 134, 135, 140, 141, 171, 228], "lda_lexicon_nam": [8, 72, 102, 103, 104, 116, 135, 140, 141, 171, 228], "lda_tabl": 14, "lda_top": [107, 229], "lda_tutori": [107, 229], "ldaextractor": [2, 208], "le": 209, "learn": [195, 196, 206, 234, 235], "least": [16, 17, 29, 36, 40, 41, 44, 61, 74, 108, 111, 143, 145, 182, 212, 220, 221, 229], "leav": 132, "left": [40, 57], "len": [195, 196, 235], "length": [136, 212, 213, 239], "leo": [128, 199, 237], "less": [42, 43, 94, 99, 153, 209, 218, 221, 222, 224], "let": [22, 23, 24, 25, 26, 212, 213, 238, 239], "letter": [101, 158, 159], "level": [0, 38, 46, 64, 113, 114, 129, 144, 149, 153, 168, 184, 186, 187, 194, 209, 212, 213, 215, 218, 220, 221, 224, 226, 235, 237, 238, 239], "levi": 229, "lex": [0, 7, 12, 15, 206, 221], "lex_anscomb": [7, 8], "lex_interfac": [0, 8, 229], "lex_tabl": [7, 15, 29, 36, 100, 106, 182], "lexic": [57, 74, 209], "lexica": [0, 46, 168, 193, 200, 209, 211, 213, 221, 224, 234, 235, 239], "lexicainterfac": [0, 2, 208], "lexicon": [0, 12, 15, 46, 74, 100, 105, 106, 107, 134, 137, 166, 167, 168, 184, 193, 200, 203, 206, 212, 236], "lexicon_categori": 107, "lexicon_count_t": 232, "lexicon_weight": 0, "lexicondb": [7, 8, 61, 93, 100, 107, 192, 229], "lexinterfac": [0, 2, 107, 208], "lextabl": [93, 192], "lh": 209, "lib": [2, 206, 208, 223], "liblinear": 236, "libra": [128, 199, 237], "librari": [206, 220, 223, 239], "licens": [1, 205], "lie": 50, "lik": [201, 229], "like": [16, 17, 24, 27, 38, 52, 53, 57, 80, 113, 143, 145, 156, 158, 159, 161, 162, 177, 209, 213, 221, 223, 228, 229, 234, 235, 237, 239], "likelihood": 193, "likihood": 215, "limbachiya": 209, "lime": 212, "limit": [18, 22, 23, 24, 25, 26, 83, 191, 199, 206, 212, 213, 215, 218, 221, 229, 234, 235, 236, 237, 238, 239], "lin": 209, "line": [0, 21, 40, 41, 53, 85, 93, 147, 157, 165, 195, 196, 214, 218, 221, 223, 229, 231, 232], "linear": [9, 10, 46, 52, 89, 91, 112, 118, 127, 143, 145, 168, 195, 196, 215, 222, 235], "linguist": [205, 209, 221], "link": 1, "linquist": 221, "linux": 207, "list": [7, 18, 21, 23, 24, 25, 26, 35, 39, 51, 54, 93, 96, 107, 110, 124, 128, 143, 144, 147, 148, 149, 154, 173, 192, 198, 202, 214, 222, 232, 234, 235, 238], "liu": 209, "live": [209, 212, 215, 219, 221, 229, 237, 238], "liwc": [57, 96, 107, 201, 221, 236], "liwc2015": 212, "lk": 209, "ll": [52, 53], "ln": 111, "lnpmi0_15": 198, "lo": 101, "load": [24, 107, 109, 155, 156, 157, 158, 159, 160, 161, 162, 195, 196, 223, 231, 234], "load_model": [8, 45, 46, 89, 155, 156, 157, 158, 159, 160, 161, 162, 168, 172, 231, 234], "local": [110, 206, 223], "localdata": [54, 114, 144, 149, 186, 187, 194, 197], "localhost": [0, 129, 220], "locat": [0, 76, 77, 78, 118, 124, 129, 154, 171, 205, 209, 220], "locu": 209, "loess": 110, "loessplot": [8, 35], "log": [0, 7, 8, 15, 16, 17, 19, 20, 193, 212, 215, 224], "log_mean_incom": [96, 143], "logic": 27, "logincomehc01_vc85acs3yr": [41, 54], "logist": [9, 46, 48, 112, 195, 218, 222, 236], "logistic_reg": [7, 8, 48, 99], "logistic_regress": 218, "logisticregress": 236, "loglik": 229, "loneli": 209, "long": [21, 209, 235, 238], "longer": 228, "longtext": 0, "look": [24, 38, 46, 52, 53, 156, 158, 159, 161, 162, 165, 168, 213, 218, 221, 227, 229, 234, 235, 236, 239], "lookin": [199, 237], "lorrain": 229, "loss_func": 53, "lot": [195, 196, 212, 213, 222, 235, 238, 239], "louisiana": 209, "love": 229, "lover": 229, "low": 99, "low_variance_thresh": 99, "lower": [89, 94, 127, 215], "lowercas": [16, 17, 19, 101, 219], "lowess": 110, "lr": [28, 46, 158, 159, 195, 222, 236], "lsmean_wavg": 145, "lt": 101, "luca": 209, "lv": 101, "lyle": [205, 209], "m": [1, 27, 46, 101, 168, 199, 209, 213, 215, 218, 229, 237, 239], "m0": 218, "ma": 209, "maarten": [205, 209], "machin": [195, 196, 206, 229], "macro": 0, "mad": [22, 23, 24, 25, 26, 238], "made": 106, "mae": [53, 213, 231, 235, 236, 239], "mae_fold": [53, 213, 231, 235, 236, 239], "mage": 209, "magic": [222, 235], "magic_sauc": [234, 235], "mai": [32, 33, 68, 110, 134, 164, 213, 221, 223, 228, 229, 239], "main": [157, 229], "main_interest_vars_control": 153, "maintain": [206, 223], "make": [46, 56, 61, 94, 107, 108, 114, 115, 156, 157, 158, 159, 160, 161, 162, 168, 186, 194, 200, 207, 212, 213, 215, 221, 231, 235, 236, 239], "make_all_topic_wordcloud": [0, 231], "make_topic_wordcloud": [0, 7, 8, 40, 48, 56, 112, 115, 149, 151, 153, 181, 193, 194, 215, 221, 227, 231], "make_wordcloud": [0, 7, 8, 10, 48, 57, 94, 112, 114, 151, 186, 218, 221, 231], "makeblackwhitelist": 0, "male": [39, 99, 199, 201, 218, 221, 236, 237], "mallet": [0, 49, 72, 103, 116, 164, 205, 223, 228], "mallet_path": [8, 72, 102, 103, 104, 105, 134, 135, 140, 141, 171, 228], "manag": [209, 221, 229], "mani": [16, 17, 76, 77, 78, 119, 120, 121, 122, 123, 132, 151, 195, 196, 222, 235, 239], "mann": 209, "manual": [18, 189, 190, 207, 228], "map": [27, 107, 128], "march": 209, "mariadb": 223, "marion": 229, "mark": [138, 179, 188, 219], "marko": 209, "marriedavehc03_ac3yr": [41, 54], "martin": 209, "masoud": 209, "masterstats_andy_r10k": [57, 91, 137, 155, 157, 160, 161], "masterstats_r500": [86, 87, 139], "match": [57, 74, 107, 203], "matern": 209, "matero": 209, "mathemat": 143, "matplotlib": 206, "matric": [41, 180], "matrix": [1, 40, 41, 42, 43, 44, 45, 89, 127, 143, 157, 180, 215, 221, 236], "matter": 106, "max": [159, 195, 196, 213, 235, 239], "max_compon": [53, 195, 196, 235], "max_it": [215, 236], "max_tagcloud_word": [7, 8], "max_to_disable_kei": 218, "maximum": 117, "maxp": [93, 192], "me": [22, 23, 24, 25, 26, 213, 238, 239], "mean": [21, 34, 42, 43, 52, 53, 70, 143, 145, 147, 150, 160, 213, 215, 221, 223, 227, 236, 239], "mean_income_wavg_log": 145, "meant": 175, "measur": [1, 80, 89, 106, 127, 209, 215, 222], "med": 209, "media": [46, 168, 205, 209, 221, 236], "median": [34, 70], "median_ag": [96, 143], "median_age_wavg": 145, "mediat": [7, 8, 76, 77, 78, 119, 120, 121, 122, 123, 132, 144, 149, 153, 154, 205, 208], "mediation_boot": [8, 118, 120], "mediation_boot_num": [8, 118, 119], "mediation_csv": [8, 118], "mediation_method": [8, 118], "mediation_no_summari": [8, 118], "mediator_1": [118, 132], "mediator_j": [118, 132], "medic": 209, "medicin": 223, "meet": 212, "melbourn": 229, "meller": 209, "mellon": [25, 26, 238], "memori": [164, 195, 196, 212, 229], "men": 209, "mental": 209, "mention": [47, 64, 101], "merchant": 209, "mess": [94, 221], "messag": [0, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 34, 38, 47, 51, 57, 61, 62, 64, 65, 70, 94, 101, 107, 108, 113, 125, 126, 136, 164, 165, 174, 179, 185, 199, 206, 212, 218, 219, 221, 222, 224, 226, 228, 237, 238, 239], "message_field": [7, 8, 62, 93, 126, 192], "message_id": [14, 18, 21, 22, 23, 24, 25, 26, 27, 38, 65, 107, 113, 126, 164, 174, 199, 206, 212, 218, 219, 224, 228, 229, 234, 237, 238], "message_t": [12, 16, 17, 158, 159, 161, 203, 221, 228, 229, 234], "messageannot": 0, "messageid_field": [7, 8, 62, 93, 125, 192], "messages_en": [40, 41, 44, 45, 52, 57, 91, 96, 118, 137, 143, 144, 149, 155, 156, 157, 160, 161, 162, 213, 224, 239], "messages_tok": 17, "messagesen": [80, 164], "messagetransform": 0, "met": 221, "met_a30_2000": [200, 203, 224], "met_a30_2000_cp": [1, 12, 15, 29, 36, 73, 111, 166, 182, 184, 212, 215, 221], "met_a30_2000_freq_t50l": [1, 40, 48, 112, 114, 144, 149, 151, 153, 194, 215, 221, 227, 231], "meta": [110, 136, 212], "meta_1gram": [113, 136, 212, 218, 237], "meta_2gram": 113, "meta_3gram": 113, "method": [0, 31, 34, 46, 57, 67, 70, 110, 118, 119, 120, 122, 128, 152, 168, 192, 205, 209, 212, 213, 215, 219, 226, 232, 236, 238, 239], "metric": [0, 52, 53, 235], "mfclass": [157, 236], "mfclass_acc": [157, 236], "mg": 101, "michael": 223, "microtext": 209, "midatlant": [114, 144, 149, 186, 187, 194], "midwest": [114, 144, 149, 186, 187, 194], "might": [206, 213, 221, 229, 235, 239], "mil": 229, "miller": 209, "min": 235, "min_word_freq": 107, "mind": 224, "minim": 228, "minimum": [94, 107], "minneapoli": 209, "minnesota": 209, "minor": 206, "minu": 80, "minut": 223, "mirror": 229, "miss": [84, 199, 212, 224, 229, 237], "mix": [209, 229], "mixtur": [89, 127, 215], "mk": 101, "mkdir": 229, "ml": 101, "mle": 130, "mn": 101, "mode": 0, "model": [0, 8, 9, 21, 28, 33, 45, 46, 52, 53, 54, 68, 69, 86, 87, 89, 91, 109, 110, 118, 130, 137, 143, 145, 150, 155, 156, 157, 158, 159, 160, 161, 162, 166, 167, 168, 172, 174, 183, 184, 189, 190, 195, 196, 205, 209, 211, 213, 215, 222, 223, 227, 229, 231, 236, 238, 239], "model_control": 231, "model_desc": [53, 213, 231, 235, 236, 239], "model_nam": [33, 69, 89, 127], "modelfs_desc": [53, 213, 231, 235, 236, 239], "modeltyp": [158, 159], "modern": 239, "modifi": [50, 88, 95, 178, 198], "modul": [0, 152, 207, 208], "mohammadzaman": 209, "mom": [22, 23, 24, 25, 26, 238], "monitor": 223, "month": 27, "moral": 209, "morals2demog_ctrinc": 143, "more": [1, 18, 22, 23, 24, 25, 26, 32, 63, 68, 74, 80, 84, 85, 89, 93, 94, 97, 106, 107, 109, 112, 127, 129, 135, 138, 157, 158, 159, 172, 175, 176, 188, 192, 206, 209, 211, 213, 215, 219, 221, 222, 223, 226, 228, 229, 231, 235, 236, 238, 239], "morn": 229, "mortal": 209, "mosh": 1, "most": [62, 89, 93, 125, 126, 127, 140, 157, 192, 195, 196, 206, 207, 213, 215, 223, 228, 231, 235, 237, 239], "motion": 164, "move": [0, 206], "movi": 218, "movie_id": 218, "movie_idx": 218, "movie_nam": 218, "mr": 101, "msa_id": 145, "mse": [53, 213, 231, 235, 236, 239], "mse_fold": [53, 213, 231, 235, 236, 239], "msg": [1, 11, 13, 16, 18, 21, 22, 23, 24, 25, 26, 31, 32, 33, 34, 39, 46, 47, 48, 52, 53, 58, 59, 60, 63, 64, 65, 67, 68, 69, 70, 73, 93, 94, 99, 101, 107, 111, 112, 113, 128, 129, 147, 148, 150, 151, 158, 159, 166, 167, 168, 169, 172, 174, 177, 179, 183, 184, 191, 192, 198, 199, 200, 201, 202, 203, 212, 213, 214, 215, 219, 221, 224, 225, 226, 227, 228, 229, 231, 232, 234, 235, 237, 238, 239], "msgs_10nmf_fbcp": [166, 184, 215], "msgs_10nmf_fbll": 215, "msgs_2011to13": [54, 153], "msgs_an": [47, 219], "msgs_ch": 238, "msgs_ch_seg": 238, "msgs_const": [18, 238], "msgs_dedup": [47, 64, 219], "msgs_dep": [18, 238], "msgs_en": [47, 101, 145, 219], "msgs_en_dedup": 219, "msgs_lda": [228, 229], "msgs_lda_cp": [107, 229], "msgs_lda_freq_t50l": 229, "msgs_lda_stat": 229, "msgs_lda_tok": 229, "msgs_lda_tok_lda": [107, 229], "msgs_nospam": [179, 219], "msgs_po": [18, 238], "msgs_r10k": [19, 20], "msgs_r10k_po": [19, 20], "msgs_rand": [58, 59, 177, 237], "msgs_reduced10_nmf": [166, 167, 184, 215], "msgs_seg": [21, 238], "msgs_sent": [22, 238], "msgs_stok": [23, 238], "msgs_stoke": [23, 238], "msgs_tok": [24, 212, 238], "msgs_tweetpo": [25, 238], "msgs_tweettok": [26, 238], "msgs_xxx": [71, 86, 87, 139, 213, 221, 236, 239], "msgs_xxx_stok": 213, "msgsen_r5k": [84, 198], "msgspa": 193, "msgspa_2012": [27, 114, 144, 149, 186, 187, 194], "msgspa_2012_01": 27, "msgspa_2012_02": 27, "msgspa_2012_03": 27, "msgspa_2012_04": 27, "msgspa_2012_05": 27, "msgspa_2012_06": 27, "msgspa_2012_07": 27, "msgspa_2012_08": 27, "msgspa_2012_09": 27, "msgspa_2012_10": 27, "msgspa_2012_11": 27, "msgspa_2012_12": 27, "msgspa_800_freq_t50l": 193, "msz2vhj4h0": 64, "mt": 101, "mtt": 229, "much": [80, 221, 228], "mul": [65, 212, 219, 221, 224, 237, 238], "multi": [80, 164, 187, 209], "multi_class": 236, "multiclass": [0, 8], "multiclass_outcom": 128, "multigram": [80, 198], "multipl": [0, 46, 51, 52, 53, 110, 143, 152, 168, 180, 189, 190, 195, 196, 212, 213, 239], "multivari": 98, "multiword": 0, "music": 229, "must": [12, 15, 39, 40, 56, 57, 58, 59, 74, 87, 93, 107, 109, 116, 124, 128, 145, 154, 165, 172, 194, 201, 204, 206, 207, 213, 214, 218, 220, 221, 229, 232, 234, 236, 239], "mutual": 80, "mv_mort_rat": [114, 144, 149, 186, 187, 194], "my": [0, 22, 23, 24, 25, 26, 27, 129, 212, 220, 221, 223, 238], "my_lda_lexicon": 228, "my_lda_lexicon_cp": 228, "my_output": [93, 192, 202, 226], "myisamchk": 218, "mylexicon": 107, "mysql": [0, 1, 18, 22, 23, 24, 25, 26, 27, 38, 39, 45, 49, 54, 61, 62, 63, 64, 65, 71, 74, 94, 100, 107, 108, 125, 126, 128, 129, 139, 146, 156, 158, 159, 161, 162, 166, 167, 184, 185, 189, 190, 191, 199, 203, 207, 212, 213, 215, 219, 221, 224, 227, 234, 236, 237, 238, 239], "mysql2sqlit": 220, "mysql_config": [129, 207], "mysql_config_fil": [8, 220], "mysql_host": [93, 192], "mysql_iter_func": [2, 208], "mysql_root_password": 223, "mysql_to_csv": 225, "mysql_v5": 223, "mysqlclient": [206, 207, 220], "mysqlmethod": [0, 2, 208], "mysqltocsv": 225, "mystic": 209, "n": [0, 7, 12, 15, 16, 17, 19, 20, 25, 28, 32, 51, 52, 53, 68, 71, 74, 84, 89, 91, 107, 111, 120, 127, 142, 198, 207, 209, 213, 215, 218, 221, 222, 225, 227, 228, 229, 231, 235, 236, 238, 239], "n1": [32, 68], "n2": [7, 16, 17, 32, 68], "n_cluster": 130, "n_compon": [0, 8, 53, 89, 127, 166, 167, 195, 196, 215, 235, 236], "n_gram": 0, "n_iter": 0, "n_job": 236, "naacl": 209, "name": [0, 12, 15, 16, 17, 18, 27, 31, 33, 38, 39, 46, 47, 51, 54, 58, 59, 61, 62, 64, 67, 69, 73, 74, 86, 87, 94, 96, 100, 105, 107, 108, 110, 121, 124, 125, 126, 128, 144, 145, 146, 149, 151, 154, 155, 156, 158, 159, 161, 162, 165, 166, 167, 168, 170, 172, 184, 185, 187, 192, 193, 195, 196, 203, 206, 207, 211, 218, 219, 221, 223, 226, 234, 235, 238], "name_of_engin": 63, "namespac": 231, "nan": [0, 232, 235], "narciss": 221, "nathresh": [41, 45], "nation": 209, "natur": [46, 168, 205, 209, 213, 239], "nb": 101, "nb_topic": 130, "nddtc_perc": [144, 149], "ne": 101, "necessari": [62, 125, 126, 206, 220, 224], "need": [29, 36, 46, 48, 96, 111, 114, 115, 121, 124, 137, 139, 154, 158, 159, 161, 182, 195, 196, 203, 206, 212, 213, 215, 218, 219, 220, 223, 224, 228, 231, 234, 235, 236, 237, 238], "neg": [187, 215, 218, 221, 236], "neighbor": [110, 221, 232], "nejm_intersect_small50k": [118, 144, 149], "nest": [89, 127, 215], "network": [209, 213, 239], "neu": 234, "never": 165, "new": [0, 12, 15, 17, 21, 24, 25, 26, 27, 39, 47, 51, 58, 59, 64, 80, 107, 128, 156, 162, 164, 179, 191, 209, 212, 215, 218, 219, 221, 223, 227, 228, 229, 234, 235, 237, 238], "new_england": [114, 144, 149, 186, 187, 194], "new_feat_nam": 51, "newberg": 209, "newer": 206, "newlin": [16, 221, 229, 232], "newtabl": 215, "next": [96, 218, 220, 221, 223, 235, 236], "nfold_test_classifi": [7, 8, 28, 86, 87, 91, 99, 127, 133, 137, 150, 180, 183, 189, 235, 236], "nfold_test_regress": [7, 8, 28, 54, 86, 87, 91, 99, 127, 133, 137, 150, 180, 183, 190, 213, 235, 236, 239], "ng": 209, "ngram": [0, 16, 17, 19, 20, 21, 46, 74, 84, 136, 168, 191, 203, 212, 218, 221, 224], "nguyen": 209, "nice": [219, 235], "niyati": 209, "nk": [32, 68], "nl": 101, "nlp": [0, 223, 239], "nls_max_it": 215, "nltk": [22, 23, 213, 239], "nmf": [89, 127, 130, 166, 167, 215], "nn": [18, 101, 212, 238], "nndsvd": 215, "nnp": [18, 238], "no_bonferroni": 152, "no_control": 0, "no_correct": [8, 9, 37, 57], "no_featur": [8, 118, 124], "no_lang": [8, 52, 53], "no_lda_lexicon": [8, 72, 102, 103, 104, 105, 116, 135, 140, 141, 171, 228], "no_lda_stop": [8, 72, 102, 103, 104, 105, 116, 134, 140, 141, 171, 228], "no_low": [0, 101], "no_metafeat": [8, 16], "no_outcom": 0, "no_standard": [8, 46, 52, 53, 54, 89, 127, 168, 189, 190, 195, 196], "no_tagcloud_filt": [8, 56, 186, 194], "no_unicod": [7, 8], "nod": 212, "nois": [89, 127, 215], "non": [0, 9, 33, 37, 40, 44, 56, 73, 89, 94, 101, 110, 114, 127, 139, 158, 159, 161, 164, 177, 194, 206, 215, 229, 234, 237], "none": [10, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 35, 41, 42, 43, 45, 47, 48, 49, 52, 53, 54, 57, 62, 64, 66, 81, 82, 86, 98, 106, 107, 109, 112, 114, 115, 125, 126, 130, 133, 136, 138, 142, 147, 148, 152, 157, 160, 164, 169, 170, 172, 173, 181, 182, 183, 186, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 200, 202, 204, 213, 214, 215, 223, 231, 232, 235, 236, 239], "norm": [29, 36, 46, 84, 106, 111, 143, 145, 168, 182, 212, 215, 218, 221, 232, 234], "normal": [0, 16, 17, 29, 36, 53, 80, 89, 111, 118, 127, 143, 145, 182, 213, 215, 221, 222, 224, 231, 235, 236, 239], "north": 209, "notat": 0, "note": [0, 1, 16, 17, 18, 19, 20, 21, 27, 40, 41, 45, 46, 48, 52, 53, 57, 61, 76, 77, 78, 93, 103, 108, 112, 118, 119, 120, 121, 122, 123, 124, 128, 129, 130, 132, 154, 161, 168, 192, 195, 196, 198, 206, 212, 213, 214, 215, 218, 220, 221, 223, 228, 229, 232, 235, 236, 238, 239], "noth": 232, "notic": [213, 235], "notifi": [2, 208], "nov": 209, "novel": 209, "now": [0, 12, 15, 18, 27, 41, 161, 206, 215, 218, 221, 227, 228, 229, 235, 236], "np": [18, 34, 70, 235, 238], "nsubj": 18, "null": [37, 40, 44, 65, 75, 158, 159, 161, 163, 176, 178, 212, 218, 219, 221, 223, 224, 234, 237, 238], "num": [104, 107, 140, 141, 229], "num_bin": 82, "num_class": 236, "num_factor": 0, "num_featur": [53, 213, 231, 235, 236, 239], "num_rand_messag": 107, "num_stopword": [8, 72, 102, 103, 104, 105, 116, 134, 135, 141, 171, 228], "num_top": [8, 72, 102, 103, 104, 105, 116, 134, 135, 140, 171, 228], "number": [21, 22, 28, 40, 42, 43, 44, 53, 57, 74, 80, 84, 89, 91, 94, 102, 103, 104, 107, 117, 119, 120, 130, 140, 141, 142, 153, 157, 179, 213, 215, 219, 221, 224, 229, 235, 236, 239], "numer": [0, 206, 213, 221, 239], "numpi": [31, 67, 206, 207, 213, 239], "nvalu": 8, "o": [21, 25, 143, 238], "o_pr": 145, "oa": 214, "object": [83, 128, 195, 196, 209, 214, 232], "obligatori": [18, 238], "observ": [197, 209, 218, 222, 235], "oc": 101, "occu": [65, 199, 237], "occup": 39, "occur": [80, 221], "occurr": [20, 74, 94, 221, 224], "occurrenceselect": 208, "occurrencethreshold": [53, 195, 196, 235], "ocean": 234, "octob": [46, 168], "oddessi": 164, "off": [0, 92, 96, 99, 101, 123, 131, 136, 138, 139, 142, 152, 164, 215, 227], "offens": 229, "offer": 220, "offic": 223, "offici": [206, 223], "often": [107, 180, 212, 235], "og": [214, 232], "og_out": 232, "og_val": 232, "ok": 222, "old": [0, 212, 228], "older": 221, "omit": 192, "onc": [16, 96, 118, 178, 195, 196, 206, 236], "one": [0, 17, 21, 26, 29, 31, 36, 39, 46, 48, 51, 52, 53, 57, 67, 74, 84, 89, 94, 96, 109, 111, 127, 130, 132, 138, 146, 156, 162, 172, 179, 182, 185, 187, 188, 195, 196, 198, 209, 212, 213, 214, 215, 218, 219, 221, 222, 223, 224, 227, 228, 229, 235, 236, 239], "onelin": 206, "ones": [40, 157, 160, 213, 239], "onli": [0, 9, 19, 20, 21, 28, 31, 37, 39, 40, 46, 54, 57, 62, 67, 80, 83, 84, 85, 89, 94, 96, 99, 127, 139, 146, 161, 168, 189, 190, 197, 201, 202, 203, 212, 214, 215, 221, 227, 228, 229, 235, 236, 238], "onlin": 209, "oov": [84, 212], "op": 234, "opaqu": [213, 239], "opcp_rat": [144, 149], "open": [206, 209, 211, 221, 223, 239], "oper": [9, 170, 180, 201, 223], "oppos": [12, 15, 236], "optim": [89, 127, 215, 229], "option": [0, 9, 10, 11, 12, 13, 15, 16, 17, 19, 20, 21, 27, 28, 31, 32, 33, 34, 35, 37, 40, 41, 44, 45, 47, 48, 51, 52, 53, 54, 56, 57, 58, 59, 60, 62, 64, 65, 67, 68, 69, 70, 72, 76, 77, 78, 80, 86, 87, 89, 90, 91, 92, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 109, 110, 112, 114, 115, 116, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 132, 133, 134, 135, 136, 138, 140, 141, 142, 143, 145, 147, 148, 150, 151, 152, 153, 154, 157, 160, 161, 164, 165, 166, 167, 169, 170, 171, 172, 173, 177, 178, 180, 181, 182, 186, 188, 189, 190, 193, 194, 195, 196, 197, 198, 199, 200, 212, 213, 214, 221, 223, 224, 225, 228, 231, 235, 236, 239], "oracl": [164, 223], "order": [80, 109, 128, 156, 157, 158, 159, 160, 161, 162, 164, 172, 191, 195, 196, 211, 212, 213, 220, 222, 234, 235, 239], "org": [205, 209, 229, 235], "orient": [1, 209], "orig": 215, "origin": [12, 15, 18, 21, 22, 25, 26, 27, 39, 64, 91, 128, 160, 185, 223, 238], "origtop": 215, "orlean": 209, "oserror": 207, "osf": 209, "osx": 0, "other": [139, 144, 213, 215, 221, 223, 224, 229, 234, 235, 239], "otherwis": [46, 80, 94, 148, 168, 179, 219], "our": [1, 195, 196, 206, 212, 215, 219, 221, 235, 236, 237, 238], "out": [22, 23, 24, 25, 26, 27, 52, 53, 57, 94, 140, 189, 190, 195, 196, 206, 212, 221, 229, 236, 238], "outandcont": 232, "outcom": [0, 8, 9, 10, 28, 30, 35, 37, 39, 40, 41, 42, 43, 44, 45, 46, 48, 52, 53, 54, 56, 57, 60, 66, 77, 79, 81, 85, 86, 87, 91, 93, 94, 96, 97, 99, 109, 110, 112, 114, 118, 121, 124, 128, 132, 137, 138, 139, 143, 144, 145, 146, 147, 148, 150, 151, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 168, 169, 172, 173, 181, 183, 186, 187, 188, 189, 190, 192, 193, 194, 195, 196, 201, 202, 204, 209, 213, 214, 215, 226, 227, 231, 235, 236, 239], "outcome": 43, "outcome_": 147, "outcome_1": [77, 118, 124, 132, 154], "outcome_ag": [221, 231], "outcome_control": [7, 8, 10, 28, 35, 37, 39, 40, 41, 44, 45, 54, 57, 79, 85, 128, 145, 146, 181], "outcome_data_with_control": [114, 144, 149, 186, 187, 193, 194], "outcome_field": [8, 149], "outcome_gend": [221, 231], "outcome_interact": [8, 57, 96, 143], "outcome_is_educ": [221, 231], "outcome_is_stud": [221, 231], "outcome_is_technologi": [221, 231], "outcome_k": [77, 118, 124, 132, 154], "outcome_t": [7, 8, 9, 10, 28, 30, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 52, 53, 54, 56, 57, 60, 65, 66, 79, 81, 85, 86, 87, 91, 93, 94, 96, 97, 99, 109, 110, 112, 114, 118, 124, 128, 137, 139, 143, 144, 145, 147, 148, 149, 150, 151, 153, 154, 155, 157, 158, 159, 160, 161, 168, 169, 172, 173, 181, 183, 186, 189, 190, 192, 193, 194, 195, 196, 199, 201, 202, 213, 215, 218, 221, 226, 227, 231, 234, 235, 236, 239], "outcome_table_nam": [118, 124, 154], "outcome_with_outcom": [7, 8, 148], "outcome_with_outcome_onli": [7, 8, 39, 128, 221, 231], "outcomeanalyz": [99, 208, 214], "outcomecontrol": [93, 192, 214, 226, 232], "outcomefield": [93, 192, 214, 226, 232], "outcomegett": [99, 128, 192, 208, 214, 226], "outcomeinteract": [93, 192], "outcomesfin": [9, 35, 37, 79, 85], "outcomesfinal_femonli": 28, "outcomet": [93, 192, 214, 226, 232], "outdat": 0, "outlier": 150, "outlier_threshold": 150, "outliers_to_mean": [0, 8], "outofmemoryerror": 229, "outperform": [213, 239], "output": [0, 9, 27, 28, 35, 37, 39, 40, 45, 52, 57, 60, 79, 85, 90, 96, 107, 110, 114, 115, 118, 128, 134, 139, 145, 147, 151, 153, 157, 158, 159, 160, 161, 165, 169, 170, 178, 181, 192, 193, 197, 198, 204, 205, 213, 215, 218, 221, 223, 229, 235, 236, 239], "output_fil": 151, "output_file_nam": [118, 121], "output_interaction_term": 227, "output_nam": [7, 8, 9, 10, 28, 35, 37, 40, 41, 45, 48, 54, 60, 79, 85, 93, 94, 110, 112, 114, 118, 121, 139, 143, 144, 145, 149, 153, 169, 170, 181, 186, 192, 193, 194, 197, 201, 202, 213, 215, 221, 226, 227, 229, 231, 236, 239], "outputfile_nam": 165, "outputnam": [45, 93, 192, 226], "outsid": [93, 192, 235], "over": [16, 17, 31, 32, 34, 45, 46, 67, 68, 70, 99, 168, 189, 190, 195, 196, 201, 209, 213, 215, 218, 219, 227, 234, 235, 236, 239], "overal": [183, 236], "overall_l": [96, 143], "overfit": [195, 196, 235], "overrid": [84, 86, 107, 135, 139, 151, 212], "overridden": [80, 93], "overview": [212, 219, 228, 229, 238], "ovr": 236, "own": [23, 107, 224, 238], "owner": 223, "p": [0, 25, 37, 57, 97, 101, 107, 112, 123, 131, 152, 153, 160, 197, 206, 209, 215, 221, 222, 223, 226, 227, 231, 236, 238], "p75ku": 209, "p_adjust": 152, "p_correct": [0, 8, 37, 57, 93, 110, 114, 118, 144, 149, 153, 181, 192, 193, 194, 226], "p_correction_method": [93, 192, 226], "p_modeltyp": [156, 162, 234], "p_modeltype_argu": [158, 159, 161, 234], "p_rfc_argument": [158, 159], "p_ridg": [162, 234], "p_ridg_argu": 161, "p_ridg_deletem": 161, "p_ridg_lbp_ag": 234, "p_ridg_lbp_ocean": 202, "p_ridg_lbp_oceangft500": [35, 79, 85], "p_svc": 156, "p_valu": [7, 8, 93, 118, 192, 226], "pa": [101, 114, 144, 149, 186, 187, 194], "paam_age_adj_mort": [114, 144, 149, 186, 187, 194], "pac": 195, "pacif": 209, "packag": [44, 101, 195, 196, 205, 206, 207, 208, 212, 218, 219, 220, 223, 238], "packg": 225, "page": [1, 57, 74, 205, 206, 209, 223, 224, 229], "pahealth": [27, 114, 144, 149, 186, 187, 193, 194], "pair": [21, 80, 143, 145, 173, 197, 224], "panda": [205, 206, 211], "pang": 209, "paper": [205, 221], "par": 196, "param": 0, "paramat": 229, "paramet": [40, 52, 53, 103, 107, 128, 130, 192, 195, 196, 214, 221, 222, 226, 228, 229, 235], "parametr": [37, 119], "parenthes": 160, "pari": 229, "park": [46, 168, 209], "pars": [18, 218], "parser": [205, 223], "part": [18, 25, 83, 118, 198, 205, 211, 220], "particip": 209, "particular": 218, "partit": 91, "pass": [81, 124, 154, 197, 214, 218, 220, 221, 232], "passga": 212, "passiv": 195, "password": [129, 220, 223], "past": [209, 226], "path": [78, 116, 118, 129, 132, 154, 171, 206, 207, 214, 218, 220, 223, 225, 228, 232], "path_start": [8, 78, 118, 132, 149], "path_start_1": [78, 118, 132], "path_start_i": [78, 118, 132], "pathogen": 209, "patrick": [143, 197, 205, 209], "pattern": 221, "paus": 223, "pca": [89, 127, 130, 215, 222, 235], "pca_mod": 208, "pdf": [170, 209], "pds_bmi_subj": 10, "pearson": [57, 143, 160, 181, 213, 235, 236, 239], "pearsonr": 57, "pelix": 206, "pelullo": 209, "penal": [42, 43, 211, 222, 235], "penalti": [40, 41, 42, 43, 44, 89, 127, 215, 236], "peng": 209, "penn": [18, 21, 174, 223, 238], "pennebak": 1, "pennsylvania": 205, "peopl": [229, 235], "per": [1, 44, 45, 52, 53, 94, 96, 102, 103, 145, 146, 203, 212, 222, 223, 229], "percent": [157, 229], "percent_bachelor": [96, 143], "percent_bachelors_wavg": 145, "percent_whit": [96, 143], "percent_white_wavg": 145, "percentag": [37, 58, 59, 106, 175, 179, 212, 221], "percentil": 37, "perfectli": 9, "perform": [40, 41, 44, 52, 53, 54, 57, 96, 104, 137, 218, 231, 235], "performance_schema": 223, "perhap": [61, 108], "permalexicon": [0, 1, 184, 223], "permiss": 1, "permut": 44, "person": [209, 221, 222, 234], "perth": 229, "pesc": 209, "phd": [39, 128], "php": [228, 229], "phrase": [16, 17, 107], "pick": 122, "pickl": [0, 41, 45, 137, 155, 156, 157, 158, 159, 160, 161, 162, 172, 211], "picklefil": [8, 41, 45, 89, 109, 127, 137, 156, 157, 158, 159, 160, 161, 162, 172, 195, 196, 231, 234, 235], "pictur": 209, "piec": [94, 221], "pietro": 209, "pig": 229, "pinocchio": 229, "pip": [0, 1, 207, 220, 228], "pip3": 207, "pipelin": [53, 86, 87, 195, 196, 235, 236], "pisc": 128, "pivot": 232, "pku": [174, 238], "pl": 101, "place": [12, 15, 107, 151, 158, 159, 185, 206, 221, 222, 229, 235], "plan": [89, 127, 215, 228, 229], "planetpok": 229, "platform": 209, "pleas": [1, 52, 53, 63, 129, 205, 206, 213, 236, 239], "plo": 209, "plot": [82, 90, 110, 173], "plu": 40, "pma": 44, "pmi": [80, 198, 222, 224], "pmi3_0": 224, "pmi6_0": 113, "pmi_valu": 176, "png": [218, 221, 231], "po": [0, 19, 20, 25, 212, 229], "pocc_thresh": 175, "point": 229, "pointwis": 80, "poisson": 29, "pokerstar": 229, "polit": 209, "pone": 209, "popul": 209, "population_dens": 143, "port": 223, "portion": 223, "posit": [65, 187, 199, 218, 221, 236], "possibl": [52, 53, 71, 97, 152, 213, 239], "post": [1, 49, 209, 227], "postdoc": [195, 196], "pow": 229, "power": 180, "pp": [46, 168, 209], "pprint": 107, "ppron": 212, "practic": [89, 99, 127, 215, 228], "pragma": 218, "prai": 229, "pre": [158, 159, 195], "precari": 229, "preced": 93, "precis": [157, 236], "pred_csv": [0, 54], "predefin": 198, "predict": [1, 9, 45, 46, 52, 53, 54, 86, 87, 91, 99, 127, 137, 143, 145, 150, 155, 156, 157, 158, 159, 160, 161, 162, 163, 168, 172, 183, 189, 190, 195, 196, 201, 205, 209, 213, 221, 226, 235, 239], "predict_classifi": [7, 8, 52, 99, 109, 127, 150, 158, 159, 180], "predict_classification_to_outcome_t": [7, 8], "predict_classifiers_to_feat": [7, 8, 127, 180, 234], "predict_combo_to_feat": [87, 91], "predict_cv_to_feat": [87, 91], "predict_probabilities_to_feat": [0, 159], "predict_regress": [7, 8, 99, 109, 127, 150, 155, 161, 180], "predict_regression_all_to_feat": [87, 91], "predict_regression_to_feat": [0, 7, 8, 127, 180, 234], "predict_regression_to_outcome_t": [0, 7, 8, 156, 234], "predictcompstosql": 45, "predicted_data": [54, 231, 236], "prediction_csv": [7, 8, 151, 231, 236], "prediction_prob": 231, "predictor": [0, 9, 28, 37], "prefer": [189, 190, 198], "prefix": 147, "pregdla": 197, "pregnanc": [28, 35, 79, 85], "preo": 209, "preotiuc": [64, 209], "prepar": 229, "prepmatric": 41, "prepmatricestogeth": 41, "present": [12, 15, 16, 17, 22, 23, 24, 25, 26, 65, 76, 77, 78, 130, 197, 199, 209, 221, 238], "press": 209, "presum": 222, "pretrain": [213, 239], "preval": 221, "prevent": 228, "previou": [0, 224], "previous": [46, 109, 138, 166, 168, 188], "pri": [65, 212, 219, 221, 224, 237, 238], "primal": [12, 15, 29, 36, 89, 127, 182, 209], "primals_new": [12, 15, 29, 36, 89, 127, 182], "primari": [218, 229], "primarili": 221, "princip": [89, 127, 215], "print": [0, 21, 44, 52, 53, 57, 65, 85, 107, 121, 123, 139, 153, 160, 164, 165, 187, 199, 206, 207, 215, 218, 221, 223, 229, 236], "print_csv": 0, "print_joined_feature_lin": [7, 8, 229], "print_tokenized_lin": [7, 8, 85, 164, 229], "print_weight": 107, "prior": [10, 102, 103, 229], "privileg": [61, 108, 206], "prize": [179, 219], "pro": 223, "prob": [25, 238], "probabilit": 159, "probability_csv": 231, "probabl": [1, 27, 80, 99, 107, 159, 221, 223, 224, 229], "probe": 227, "proce": [218, 235], "proceed": [46, 168, 205, 209, 229], "process": [0, 46, 72, 101, 107, 168, 171, 205, 206, 209, 215, 221], "produc": [12, 15, 30, 31, 34, 54, 56, 66, 67, 70, 111, 159, 164, 186, 194, 212, 213, 215, 221, 227, 229, 231, 234, 236, 239], "product": [145, 179, 180, 219, 227, 229], "project": [1, 18, 89, 127, 205, 209, 211, 215, 226, 229, 238], "promot": 212, "prompt": 223, "properli": 207, "properti": 229, "proport": 221, "prospect": 1, "proud": 209, "provid": [12, 15, 18, 238], "prp": 212, "prune": 223, "pseudo": 57, "psyarxiv": 209, "psychodemograph": 209, "psycholog": 209, "psychologi": [205, 209], "psychos": [35, 79, 85], "pt": 101, "pub": [212, 229], "public": [1, 205, 206], "publish": [205, 209], "pull": 223, "punctuat": 64, "punkt": [22, 23, 213, 239], "purpl": 80, "purpos": 239, "push": 222, "put": [155, 156, 158, 159, 161, 162, 189, 190, 195, 196], "pvalu": 0, "pw": 223, "py": [0, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 63, 64, 65, 67, 68, 69, 70, 71, 73, 79, 80, 84, 85, 86, 87, 89, 91, 93, 94, 96, 99, 101, 107, 111, 112, 113, 114, 118, 127, 128, 129, 136, 137, 139, 143, 144, 145, 147, 148, 149, 150, 151, 153, 155, 156, 157, 158, 159, 160, 161, 162, 164, 165, 166, 167, 168, 169, 172, 174, 177, 179, 181, 182, 183, 184, 186, 187, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 206, 207, 212, 213, 215, 218, 219, 220, 221, 222, 223, 225, 226, 227, 228, 229, 231, 232, 234, 235, 236, 237, 238, 239], "pymallet": [0, 72, 103, 116, 228], "python": [0, 21, 49, 101, 107, 127, 137, 142, 143, 144, 145, 153, 155, 156, 157, 160, 161, 162, 165, 169, 170, 173, 180, 186, 194, 205, 207, 213, 219, 220, 221, 223, 239], "python3": [218, 223], "qt62kodzew": 64, "qu": 101, "qualiti": 209, "quantifi": 209, "quantit": 221, "queri": [65, 94, 107, 113, 199, 201, 212, 215, 218, 237], "question": [27, 213, 221, 239], "quiz": 221, "quot": [93, 214, 232], "r": [25, 40, 44, 53, 57, 107, 143, 152, 160, 181, 206, 209, 213, 221, 231, 235, 236, 238, 239], "r2": [53, 213, 231, 235, 236, 239], "r2_fold": [53, 213, 231, 235, 236, 239], "r_fold": [53, 213, 231, 235, 236, 239], "r_p": [53, 213, 231, 235, 236, 239], "r_p_fold": [53, 213, 231, 235, 236, 239], "ram": 229, "ramon": 209, "ramsai": 209, "ran": 215, "rand": [228, 229, 237], "random": [0, 1, 29, 58, 59, 80, 107, 187, 222, 223, 235], "random_se": [58, 59], "random_st": [53, 195, 196, 215, 235, 236], "randomforrest": 195, "randomizedpca": [53, 195, 196, 235, 236], "randomli": [52, 53, 91, 236], "rang": [0, 9, 218, 222, 235], "rank": [160, 193, 221, 231], "rare": [212, 218, 221, 235], "raritan": 229, "rate": [209, 218, 222, 235], "rather": 0, "ratio": 84, "ratio_of_group": 84, "raw": [16, 17, 229], "rb": 18, "rd": 209, "re": [38, 158, 159, 189, 190, 209, 213, 222, 228, 229, 239], "reaction": 209, "read": [0, 52, 53, 79, 85, 90, 93, 139, 213, 218, 220, 226, 236, 238, 239], "readabl": 229, "readi": [0, 228, 229], "real": [37, 209], "realiti": 209, "realiz": 228, "realli": [22, 23, 24, 25, 26, 222, 238], "recal": [157, 236], "recap": 229, "receiv": [9, 170], "recogn": 209, "recombin": 27, "recommand": 220, "recommend": [209, 213, 229, 239], "reconstruct": [89, 127, 215], "record": 209, "recoveri": 209, "red": 187, "redblu": 187, "reduc": [89, 166, 184, 209], "reduced_lexicon": [0, 8, 184, 215], "reducer_to_lexicon": [8, 166, 184, 215], "reduct": [89, 127, 167, 205, 215], "refer": [9, 10, 166, 191, 209, 213, 215], "reflect": 172, "refrain": 228, "regex": 229, "region": [114, 144, 149, 186, 187, 194], "regist": 223, "regress": [0, 9, 10, 28, 48, 98, 99, 110, 112, 118, 137, 143, 145, 150, 155, 160, 161, 162, 168, 172, 190, 195, 196, 211, 213, 218, 222, 227, 231, 235, 236, 239], "regression_to_lex": 0, "regression_to_lexicon": [0, 7, 8, 54, 127, 137, 160, 196, 236], "regressionpredictor": [0, 86, 87, 196, 208, 214, 222, 235], "rel": [16, 17, 37, 46, 74, 168, 224, 235], "relat": [18, 110, 211, 238], "relationship": [209, 221, 222], "releas": [206, 221], "release_year": 218, "reli": 237, "religi": 209, "religion": 209, "remain": [52, 53, 91, 236], "remark": [52, 53, 209], "rememb": [213, 223, 239], "remov": [0, 40, 44, 47, 64, 81, 99, 101, 107, 139, 179, 206, 212, 218, 221, 223, 228, 229, 235], "renam": 218, "repeat": [91, 213, 227, 239], "repetit": [119, 120], "replac": [0, 16, 47, 64, 164, 207, 213, 219, 221, 228, 229], "replic": 209, "reply_to": 218, "repo": [205, 223], "report": [37, 92, 123, 142, 153], "repositori": 223, "repres": [91, 213, 229, 239], "represent": [18, 31, 39, 67, 68, 128, 180, 213, 238, 239], "republican": 96, "requir": [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 56, 57, 58, 59, 62, 64, 65, 66, 67, 68, 69, 70, 72, 73, 76, 77, 78, 79, 81, 82, 83, 84, 85, 86, 87, 89, 90, 91, 94, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 128, 130, 132, 133, 134, 135, 136, 137, 138, 140, 141, 142, 143, 144, 145, 147, 148, 149, 150, 152, 154, 155, 156, 157, 158, 159, 160, 161, 162, 164, 165, 166, 167, 168, 171, 172, 173, 174, 177, 179, 181, 182, 183, 184, 186, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 206, 207], "rerun": [207, 235], "research": [209, 239], "reserv": 223, "residu": 0, "respect": [15, 68, 118, 183, 223, 239], "respons": 209, "rest": 164, "restrict": [1, 229], "result": [19, 20, 27, 47, 52, 53, 94, 107, 118, 123, 153, 163, 164, 191, 213, 219, 221, 224, 229, 231, 234, 235, 236, 239], "retriev": 214, "return": [181, 214, 232], "reveal": [213, 239], "review": [1, 228], "revisit": 231, "rfc": [158, 159, 195], "rfeat0": 215, "rfeat1": 215, "rfeat2": 215, "rfeat3": 215, "rfeat4": 215, "rfeat5": 215, "rfeat6": 215, "rfeat7": 215, "rfeat8": 215, "rfeat9": 215, "rho": [53, 160, 213, 231, 235, 236, 239], "rho_p": [53, 213, 231, 235, 236, 239], "rid": [40, 44], "ridg": [161, 162, 168, 196, 213, 222, 234, 235, 236, 239], "ridge100": 168, "ridge1000": [234, 235], "ridgecv": [53, 127, 150, 183, 196, 213, 222, 231, 235, 236, 239], "ridgefirstpass": 235, "ridgefirstpasscv": [0, 86, 87, 196, 235], "ridgehighcv": [0, 196, 235], "ridgelowcv": [0, 196], "rieman": 209, "right": [40, 46, 57, 156, 158, 159, 161, 162, 168, 209, 223, 235], "risk": [209, 224], "rlike": 107, "rm": 223, "rmatrix": [0, 7, 8, 9, 10, 35, 37, 40, 41, 48, 57, 60, 79, 85, 92, 96, 112, 139, 142, 143, 145, 147, 151, 178, 181, 202, 221, 231], "rmatrix_output": 221, "ro": 101, "roadwai": 229, "roberta": 0, "roc": [8, 127, 157, 180], "rock": 229, "root": [18, 160, 182, 223, 238], "roughli": [211, 213, 235, 239], "rouhizadeh": 209, "round": 229, "row": [22, 23, 24, 58, 59, 145, 146, 180, 199, 218, 219, 221, 223, 234, 237, 238], "row_id": 231, "rp": [212, 214], "rpcridgecv": 196, "rpercent_2008": [143, 145], "rpy2": 206, "rrb": 165, "ru": 101, "ruch": 209, "rule": [89, 94, 127, 211, 215], "run": [0, 21, 27, 28, 40, 49, 52, 53, 54, 64, 72, 76, 77, 78, 91, 96, 99, 101, 106, 109, 118, 119, 120, 122, 123, 128, 132, 133, 143, 150, 153, 155, 158, 159, 161, 164, 172, 183, 201, 206, 207, 211, 213, 215, 218, 219, 221, 224, 228, 234, 235, 239], "runtim": [215, 218, 235], "rvcypcj": [21, 238], "rw": 101, "sai": [52, 53, 209, 212, 213, 221, 239], "said": [24, 195, 196, 229], "saifuddin": 209, "salari": [60, 169], "salvator": [205, 209], "same": [14, 18, 24, 64, 157, 160, 172, 189, 190, 219, 221, 224, 232, 234, 235, 236], "sampl": [57, 89, 91, 104, 107, 127, 165, 189, 190, 214, 215, 223, 232], "sap": [46, 168, 205, 209, 236], "satisfi": 40, "sauc": [222, 235], "save": [16, 17, 20, 41, 45, 54, 109, 134, 137, 155, 171, 172, 215, 223, 231, 235, 238], "save_lda_fil": [8, 72, 102, 103, 104, 105, 116, 134, 135, 140, 141, 228], "save_model": [8, 41, 89, 109, 137, 155, 195, 196, 231, 235], "scale": [1, 224], "scaler": [0, 236], "scatter": 173, "scatterplot": [8, 83, 110], "schema": 218, "scheme": 187, "schler": 1, "schneider": 209, "school": 128, "schwartz": [46, 168, 205, 209], "sci": 235, "scienc": 209, "scientif": 205, "scikit": [195, 196, 206], "scipi": [180, 206], "scope": [235, 236], "score": [0, 53, 118, 137, 191, 212, 213, 221, 231, 235, 236, 239], "score_func": [53, 235, 236], "scorpio": [128, 199, 237], "screen": 221, "script": [24, 49, 223, 228, 229], "scroll": 235, "se": [41, 101], "se_": [213, 239], "se_mae_fold": [53, 213, 231, 235, 236, 239], "se_mse_fold": [53, 213, 231, 235, 236, 239], "se_r2_fold": [53, 213, 231, 235, 236, 239], "se_r_fold": [53, 213, 231, 235, 236, 239], "se_r_p_fold": [53, 213, 231, 235, 236, 239], "se_train_mean_mae_fold": [53, 213, 231, 235, 236, 239], "sean": 229, "search": [165, 235], "sec": 223, "second": [96, 118, 200, 209, 215, 218, 231], "secondaryipaddress": 223, "secret": 223, "section": [52, 53, 206, 235], "sedoc": 209, "see": [10, 35, 42, 43, 52, 54, 56, 57, 62, 63, 72, 74, 80, 93, 96, 97, 100, 102, 103, 104, 105, 106, 107, 109, 112, 113, 114, 115, 116, 125, 126, 129, 134, 135, 138, 140, 141, 157, 158, 159, 164, 166, 167, 171, 172, 175, 176, 177, 184, 186, 188, 192, 194, 195, 196, 202, 206, 209, 213, 218, 221, 222, 223, 224, 226, 228, 229, 231, 234, 235, 236, 237, 239], "seed": [0, 58, 59, 237], "seem": [213, 235, 239], "seen": [118, 191], "segment": [0, 21, 174, 211, 213, 239], "segmentation_model": [8, 21, 238], "segmentor": 21, "selec": 235, "select": [18, 22, 23, 24, 25, 26, 27, 34, 46, 52, 53, 54, 61, 70, 86, 87, 107, 108, 168, 191, 195, 196, 199, 212, 213, 215, 218, 221, 222, 228, 229, 234, 235, 236, 237, 238, 239], "selectfw": [53, 87, 195, 196, 235, 236], "selector": [195, 196], "self": [41, 45, 195, 196, 209, 235], "seligman": 209, "sem": 209, "semant": [209, 213, 239], "semanticsextractor": 208, "semicolon": 221, "send": [107, 223], "sens": [46, 107, 168, 215], "sense_annotated_lex": 107, "sentenc": [18, 22, 23, 94], "sentiment": 209, "sentirno": 229, "separ": [40, 41, 93, 96, 110, 124, 144, 149, 154, 163, 212, 213, 214, 222, 232, 234, 235, 236, 239], "sequel": 223, "sequenc": 229, "ser1_filt": [85, 229], "seri": 209, "serv": [213, 239], "server": [0, 94, 223], "session": 229, "set": [1, 16, 17, 27, 40, 42, 43, 52, 53, 63, 80, 84, 89, 93, 94, 97, 99, 102, 103, 107, 127, 129, 130, 135, 139, 140, 141, 150, 156, 158, 159, 161, 162, 174, 189, 190, 192, 198, 212, 214, 215, 218, 220, 221, 222, 223, 224, 227, 228, 229, 231, 232, 234, 235, 236], "set_p_occ": [8, 84, 94, 198, 212, 218, 221], "set_pmi_threshold": [8, 80, 212, 224], "setup": [0, 16, 208, 215, 226], "seventh": 209, "sever": [213, 218, 228, 239], "severalnin": 223, "sex_int": [9, 10, 35, 37, 79, 85, 181], "sgdregressor": 196, "sh": [49, 206], "shah": 209, "shape": [195, 196, 235, 236], "sharath": 209, "share": [1, 138, 179, 188, 209, 219], "she": [24, 229], "sherritt": 209, "shiiiennntaaaahhh": 212, "short": 94, "shorten": 226, "shot": [18, 238], "should": [32, 38, 68, 80, 118, 143, 146, 161, 171, 172, 183, 191, 195, 196, 198, 213, 219, 221, 223, 228, 229, 234, 235, 238, 239], "show": [80, 107, 113, 143, 177, 199, 218, 221, 223, 224], "show_feat_t": [0, 113], "show_feature_t": [7, 8, 237], "show_tabl": [0, 8, 237], "shown": [218, 228], "shrunk": 16, "shtml": 206, "shuffl": [37, 215], "shufflesplit": 0, "shulman": 209, "si": 101, "sign": [65, 128, 199, 206, 236, 237], "sign__multiclass": 128, "signal": 209, "signific": [37, 48, 81, 89, 96, 97, 118, 119, 120, 123, 127, 153, 215, 227, 235], "sime": [114, 144, 149, 152, 153, 181, 193, 194], "similar": [19, 20, 83, 89, 118, 127, 148, 164, 183, 215, 225, 227, 228, 229], "similarli": [28, 52, 53, 187, 221, 232], "simpl": [213, 214, 221, 223, 239], "simplejson": 206, "simpler": 229, "simplest": [143, 213, 223, 239], "simpli": [17, 19, 20, 24, 51, 106, 214, 218, 221], "sinc": [62, 125, 126, 213, 221, 223, 235, 236, 237, 239], "singl": [16, 17, 22, 23, 31, 34, 67, 70, 91, 212, 213, 215, 221, 223, 239], "singular": [89, 127, 215], "site": [1, 223], "sixth": 209, "size": [0, 48, 54, 57, 197, 221, 222, 223, 231, 235, 238], "sk": 101, "sketch": 229, "skill": 229, "skip": 206, "sklearn": 0, "skoric": 209, "sl": 101, "slaff": 209, "slice": 180, "slight": 235, "slightli": 137, "slow": 180, "slower": 228, "small": [212, 221], "smaller": [80, 118, 235], "smartphon": 209, "smilei": 64, "smith": 209, "smooth": 110, "sng": 229, "so": [21, 22, 23, 24, 25, 26, 28, 41, 44, 46, 48, 52, 53, 84, 94, 137, 161, 168, 172, 195, 209, 212, 213, 214, 218, 220, 221, 235, 237, 238, 239], "sobel": [118, 123, 153], "social": [46, 168, 205, 209, 221, 236], "softimput": [40, 41, 44], "softimputextoo": 41, "softwar": 206, "solanki": 209, "solut": 229, "solv": 207, "solver": [215, 236], "some": [1, 99, 143, 150, 157, 206, 212, 213, 215, 221, 223, 225, 227, 234, 235, 239], "somedb": [214, 232], "somefeaturedf": 232, "somefeaturegett": 232, "somefield": [214, 232], "somefil": [93, 192, 226], "someoutcomedf": 232, "someoutcomegett": 232, "sometb": [214, 232], "someth": [16, 17, 21, 38, 52, 53, 164, 212, 213, 223, 235, 239], "sometim": [40, 137, 212, 221, 222, 227], "someus": 25, "son": 209, "soon": [27, 161], "sooo": 209, "soorri": 229, "soprano": 229, "sort": [7, 8, 10, 40, 41, 57, 60, 139, 143, 145, 169, 181, 221, 229, 231], "soundtrack": 164, "sourc": [224, 229, 239], "south": [114, 144, 149, 186, 187, 194], "southwest": [114, 144, 149, 186, 187, 194], "space": [16, 89, 96, 110, 124, 127, 144, 149, 154, 164, 215, 229], "spam": 179, "spam_filt": [0, 8, 219], "spars": [1, 7, 8, 40, 52, 53, 54, 89, 107, 127, 170, 189, 190, 195, 196, 215, 224, 232], "sparsefil": 107, "sparsepca": [89, 127, 130, 215], "sparsiti": [42, 43, 44, 180, 222], "spatial": [89, 127, 215], "speak": [213, 239], "speaker": 218, "spearman": [8, 57, 110, 160, 236], "specif": [57, 74, 94, 118, 152, 205, 212, 235], "specifi": [0, 14, 21, 24, 25, 26, 28, 31, 32, 33, 34, 38, 40, 50, 52, 53, 57, 58, 59, 61, 62, 65, 66, 67, 68, 69, 70, 71, 72, 74, 89, 90, 94, 100, 105, 108, 116, 117, 118, 119, 120, 121, 125, 126, 127, 130, 134, 139, 146, 152, 153, 165, 167, 170, 171, 172, 173, 183, 185, 187, 193, 198, 199, 203, 212, 213, 214, 215, 218, 223, 224, 228, 231, 232, 234, 235, 236, 237, 239], "spectral": [89, 127, 130, 215], "speech": [18, 25, 205, 211], "spiritu": 209, "spit": [52, 53], "split": [16, 19, 20, 21, 41, 52, 53, 91, 189, 190, 213, 223, 236], "spread": [89, 127, 215], "spring": [209, 229], "sprinkl": 229, "spybot": 229, "sq": 101, "sql": [27, 65, 107, 113, 156, 158, 159, 161, 162, 177, 199, 201, 206, 211, 215, 218, 220, 221, 223], "sql_csv": 54, "sqlalchemi": [206, 220], "sqlite": [0, 63, 218], "sqlite3": [218, 220], "sqrt": [7, 8, 15, 16, 17, 19, 20, 212, 224, 236], "squar": [53, 143, 145, 160, 182, 236], "sr": 101, "stabil": 29, "stack": 239, "stai": 161, "stand": [110, 221, 224, 234], "standalon": 24, "standard": [29, 46, 53, 57, 63, 73, 118, 129, 137, 143, 145, 150, 168, 195, 196, 206, 212, 218, 220, 223, 224, 227, 228, 236, 237], "standardscal": [215, 235, 236], "stanford": [0, 205, 209, 223], "stanfordpars": [2, 206, 208], "starbuck": 164, "start": [72, 78, 118, 128, 132, 154, 164, 203, 212, 219, 221, 222, 223, 228, 229, 235, 238], "startswith": 94, "stat": 152, "state": [209, 223, 224], "statement": 223, "static": [68, 228, 239], "statist": 235, "statsmodel": 206, "statu": 223, "statuses_6moab": 197, "statuses_6mobb": 197, "statuses_er1": [9, 10, 28, 35, 37, 79, 85, 181, 197, 224], "statuses_er1_655": [9, 37, 85], "statuses_er1_freq_t50l": 181, "stdout": [52, 57, 107, 160], "step": [27, 53, 74, 96, 171, 195, 196, 227, 235], "stereotyp": 209, "steven": 209, "sti": [35, 79, 85], "stick": 229, "still": [22, 23, 24, 25, 26, 212, 229, 238], "stillwel": [46, 168, 209], "stoni": 205, "stop": [135, 140, 223, 228], "stoplist": 228, "stopword": 229, "store": [0, 74, 105, 107, 109, 128, 195, 196, 213, 221, 226, 228, 229, 239], "store_cv_valu": [53, 213, 231, 235, 236, 239], "stori": [191, 209, 212], "straight": [74, 212], "stratifi": [0, 183], "stratify_fold": [0, 8], "straw": 229, "streamlin": 228, "strength": [209, 222], "stretch": 223, "string": [73, 87, 93, 101, 128, 139, 151, 195, 196, 198, 214, 218, 232], "strong": 239, "strongli": [110, 221], "structur": [14, 18, 89, 127, 180, 215, 238], "student": [199, 237], "studi": [209, 229], "study_cod": [9, 10, 28, 35, 37, 79, 85, 181, 197], "stumbl": 212, "style": [18, 113, 177, 235], "su": [199, 229, 237], "subject": 209, "submodul": 208, "subpackag": 208, "subsampl": 91, "subsect": [213, 239], "subsequ": 218, "subset": [1, 52, 53, 58, 59, 85, 94, 214, 221, 227, 229, 237], "substanc": 209, "subtract": [143, 145, 180, 227], "success": [215, 218, 235], "successfulli": 223, "sudo": [206, 207], "suggest": 221, "suicid": 209, "suit": 205, "suitabl": [89, 127, 215], "sum": [16, 17, 20, 27, 31, 67, 94, 215, 221, 224], "summari": [123, 153, 221, 229, 231], "super": [0, 107, 166, 167, 184, 211], "super_top": [8, 107, 166, 167, 215], "supertop": [107, 215], "supertopic_output": 215, "suppli": [107, 165, 203], "support": [0, 49, 180, 195, 212, 235, 236], "sure": [61, 90, 94, 108, 156, 157, 158, 159, 160, 161, 162, 207, 228, 235], "surpress": 229, "surveil": 209, "sv": 101, "svc": [52, 91, 156, 195, 222], "svm": 222, "svmlight": 223, "svr": 196, "sw": 101, "sweep": [179, 219], "switch": [212, 220, 235, 236], "sy": [206, 207, 223], "symposium": 209, "syntact": [209, 239], "syntax": [89, 127, 221], "system": [21, 129, 205, 206, 209, 220, 221, 223, 229], "t": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 53, 54, 57, 58, 59, 60, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 79, 80, 84, 85, 86, 87, 89, 91, 93, 94, 96, 97, 99, 100, 101, 102, 103, 104, 105, 107, 109, 111, 112, 113, 114, 116, 118, 127, 128, 129, 134, 135, 136, 137, 139, 140, 141, 143, 144, 145, 147, 148, 149, 150, 151, 153, 155, 156, 157, 158, 159, 160, 161, 162, 164, 165, 166, 167, 168, 169, 171, 172, 174, 179, 181, 182, 183, 184, 186, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 209, 212, 213, 215, 218, 219, 221, 222, 223, 224, 225, 226, 227, 228, 229, 231, 234, 235, 236, 237, 238, 239], "ta": 101, "tabl": [0, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 31, 33, 34, 35, 36, 38, 45, 46, 47, 50, 51, 56, 57, 58, 59, 61, 62, 64, 65, 67, 69, 70, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85, 89, 94, 100, 101, 105, 107, 108, 111, 113, 118, 124, 125, 126, 127, 132, 136, 140, 143, 145, 146, 148, 154, 156, 157, 158, 159, 160, 161, 162, 164, 165, 166, 167, 168, 172, 173, 177, 179, 182, 184, 185, 191, 194, 195, 196, 197, 198, 199, 200, 202, 203, 206, 211, 215, 218, 219, 221, 225, 226, 227, 231, 235, 236, 238], "table_const": 18, "table_dep": 18, "table_info": 218, "table_nam": [166, 167, 184, 199, 237], "table_po": 18, "table_schema": [199, 237], "table_seg": 21, "table_tok": 24, "table_tweetpo": 25, "table_tweettok": 26, "tablenam": [45, 165, 198], "tablename_tok": 165, "tag": [18, 19, 20, 25, 186, 205, 211, 221, 223, 231], "tagcloud": [0, 7, 8, 10, 48, 56, 57, 94, 112, 114, 115, 117, 138, 147, 151, 153, 187, 188, 194, 218, 221, 231], "tagcloud_colorschem": [7, 8, 48, 112, 114, 115, 144, 149, 151, 181, 194, 215, 221, 227], "tagcloud_filt": [8, 56, 186, 194], "tagcloudcolorschem": [93, 192], "tagger": [25, 238], "tailor": 223, "take": [39, 51, 64, 65, 128, 192, 199, 213, 215, 221, 229, 235, 238, 239], "taken": [47, 197, 219], "talk": [195, 196], "tanya": 209, "task": [209, 219, 222, 234, 235, 239], "tauru": [128, 199, 237], "tcp": 223, "te": 101, "teacher": 229, "teal": 0, "technic": 224, "techniqu": [46, 168, 189, 190], "tedijanto": 209, "tell": [27, 28, 52, 53, 91, 107, 109, 155, 172, 221, 234, 235], "temp": 21, "tempfil": 21, "tempor": [1, 209], "tend": [62, 125, 126], "tent": 229, "term": [14, 107, 138, 145, 188, 212, 215, 221, 228, 229], "term_id": [14, 229], "termin": [0, 153, 218, 221, 223], "terni": 209, "test": [33, 37, 52, 53, 60, 81, 118, 119, 120, 169, 180, 189, 190, 197, 206, 213, 223, 235, 236, 239], "test_classifi": [7, 8, 52, 99, 127, 150, 180], "test_correl": [60, 169], "test_regress": [7, 8, 53, 99, 127, 150, 180], "test_siz": [53, 213, 231, 235, 236, 239], "testagelex": 137, "tester": 229, "tester7": [9, 10, 28, 35, 37, 79, 85, 181, 197], "testinitfil": 232, "tetlock": 209, "text": [0, 39, 65, 93, 94, 95, 101, 128, 138, 139, 188, 192, 205, 206, 209, 212, 214, 215, 218, 219, 221, 231, 236, 237, 238, 239], "textstat": 206, "tf": [46, 168, 191], "tf_idf": [7, 8, 212], "tf_idf_1gram": [191, 212], "tfidf": 0, "tfwe": 235, "tgz": 206, "th": 101, "tha": 229, "than": [0, 1, 37, 79, 80, 94, 99, 100, 118, 135, 137, 138, 150, 152, 153, 188, 209, 212, 218, 219, 221, 224, 228, 229], "thats": [22, 23, 24, 25, 26, 238], "the_mysql_server_host": 220, "theatreproblem": 27, "thei": [33, 80, 84, 156, 157, 158, 159, 160, 161, 162, 180, 193, 213, 218, 221, 235, 239], "them": [16, 17, 21, 46, 51, 89, 127, 151, 157, 160, 168, 206, 213, 215, 220, 221, 224, 228, 229, 239], "themselv": 147, "therefor": [29, 36, 111, 182, 212, 219, 223], "thi": [0, 1, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 31, 38, 40, 41, 44, 45, 46, 48, 49, 52, 53, 54, 57, 61, 62, 64, 67, 80, 86, 90, 91, 93, 94, 96, 99, 101, 103, 106, 107, 108, 109, 112, 114, 115, 118, 119, 120, 123, 124, 125, 126, 127, 128, 129, 130, 132, 134, 136, 137, 139, 143, 145, 146, 147, 151, 153, 155, 156, 157, 158, 159, 160, 161, 162, 164, 168, 172, 176, 183, 185, 189, 190, 195, 196, 198, 203, 206, 207, 212, 213, 214, 215, 218, 219, 220, 221, 223, 224, 227, 228, 229, 231, 234, 235, 236, 237, 238, 239], "thing": [21, 52, 157, 189, 190, 203, 218, 221, 224], "think": [24, 25, 209], "third": [16, 96], "those": [65, 84, 94, 156, 158, 159, 161, 162, 195, 196, 199, 212, 213, 215, 227, 229, 239], "though": [112, 137, 161, 164, 206, 213, 224], "thread": 229, "three": [18, 39, 109, 118, 145, 172, 209, 218, 227, 238], "thresh": 232, "threshed50": 229, "threshold": [53, 80, 94, 96, 97, 99, 107, 138, 150, 153, 175, 179, 188, 193, 195, 196, 212, 218, 219, 221, 224, 229, 235], "through": [1, 68, 101, 206, 209, 213, 219, 220, 221, 223, 229, 235, 239], "throughout": 0, "throw": [94, 224], "thrown": 94, "thu": [143, 145], "thumb": 211, "thx": 212, "time": [16, 17, 80, 91, 94, 96, 157, 164, 172, 189, 190, 199, 212, 221, 224, 235, 237, 238], "timestamp": 218, "timid": 229, "titl": [205, 209], "tl": 101, "tly": 229, "tmp": [171, 228], "to_catch_up": 164, "to_fil": [0, 7, 8, 93, 226], "to_sql_tabl": 45, "todai": 164, "togeth": [21, 80, 94, 198, 221], "tohoku": 213, "toi": 99, "tok_tabl": 14, "tok_table_lda": 14, "token": [14, 16, 17, 22, 23, 24, 25, 26, 64, 85, 164, 165, 211, 219], "tokenizen": 221, "tol": [215, 236], "told": 215, "too": [203, 235], "tool": [0, 206, 218, 221, 225], "toolkit": 209, "top": [1, 41, 140, 214, 228, 232, 239], "top15": 54, "top15aar": 54, "topc": 114, "topdeaths_comp_0910": [40, 41, 44, 45], "topdeaths_comp_11to13": 54, "topic": [0, 12, 14, 15, 40, 44, 46, 56, 72, 102, 103, 104, 105, 107, 114, 115, 116, 134, 135, 140, 141, 143, 144, 149, 151, 153, 164, 166, 167, 168, 184, 186, 187, 193, 194, 205, 206, 212, 213, 223, 234, 235, 236, 239], "topic_csv": [107, 229], "topic_id": [14, 229], "topic_lexicon": [8, 40, 48, 56, 110, 112, 114, 144, 149, 151, 153, 181, 194, 215, 221, 227, 228, 229, 231], "topic_tagcloud": [7, 8, 40, 48, 57, 112, 114, 115, 138, 144, 149, 151, 153, 181, 186, 187, 188, 193, 215, 221, 227, 228, 229, 231], "topic_tbl_from_dlatk_lexica": 221, "topic_threshold": 107, "topicextractor": 0, "topicfil": [107, 229], "topicgivenword": [107, 229], "topics_grams16and1": 234, "topicthreshold": 107, "total": [46, 57, 80, 168, 179, 212, 218, 219, 221, 236], "toward": [209, 221], "tr": 101, "track": [226, 237], "trademark": 223, "trail": 224, "train": [28, 46, 52, 53, 54, 86, 87, 91, 101, 109, 137, 155, 168, 172, 174, 180, 189, 190, 195, 196, 223, 229, 236, 239], "train_classifi": [7, 8, 46, 52, 109, 127, 137, 172, 180, 235], "train_mean": 236, "train_mean_ma": [53, 213, 231, 235, 236, 239], "train_mean_mae_fold": [53, 213, 231, 235, 236, 239], "train_regress": [7, 8, 53, 54, 86, 87, 109, 127, 137, 155, 168, 172, 180, 231, 235], "train_siz": [53, 213, 231, 235, 236, 239], "trait": 209, "transform": [0, 12, 13, 15, 29, 36, 67, 68, 69, 106, 111, 182, 195, 196, 205, 238], "translat": 209, "trash": 229, "treat": [118, 139], "treatment": [118, 154, 209], "tree": [18, 222, 235, 238], "treebank": [18, 21, 174, 238], "tri": [220, 235], "triad": 209, "trigger": 57, "truck": 24, "true": [0, 41, 53, 92, 107, 110, 142, 213, 215, 222, 231, 232, 235, 236, 239], "trust": 209, "try": [0, 206, 207, 235, 236], "ttest_feat_t": [7, 8], "ttest_r": 197, "tune": [161, 221, 235], "tupl": 57, "turn": [0, 21, 46, 48, 92, 99, 101, 123, 131, 136, 138, 139, 142, 152, 164, 168, 188, 218], "tut_init_fil": [93, 192], "tutori": [72, 93, 102, 103, 104, 105, 107, 116, 134, 135, 140, 141, 164, 166, 167, 171, 184, 192, 205, 206, 218, 228, 229, 231, 234, 235, 236, 239], "tweak": [195, 196], "tweet": [0, 1, 27, 47, 64, 209, 219, 223, 224], "tweetnlp": [2, 25, 26, 205, 206, 208, 212], "twice": [96, 235], "twitter": [1, 38, 114, 144, 149, 186, 187, 194, 209, 211, 221, 224], "twittergh": [14, 96, 118, 143, 144, 145, 149, 165], "twittertagg": 206, "two": [0, 14, 17, 27, 31, 32, 39, 41, 46, 51, 64, 67, 68, 96, 99, 101, 105, 107, 110, 118, 164, 195, 196, 197, 206, 213, 215, 218, 220, 221, 224, 225, 234, 235, 236, 239], "twt_20mil": [14, 165], "twt_20mil_stat": 14, "twt_20mil_tok": [14, 165], "twt_20mil_tok_lda": 14, "twt_topic": 14, "txt": [14, 40, 85, 129, 164, 165, 192, 218, 220, 221, 229, 232], "type": [8, 35, 46, 57, 65, 71, 74, 94, 96, 106, 122, 168, 202, 205, 212, 219, 220, 221, 223, 224, 226, 229, 231, 234, 235, 237, 238], "typeindex": 229, "typic": [29, 73, 103, 212, 213, 219, 224, 228, 239], "u": [27, 107, 199, 206, 209, 221, 224, 234, 235, 236, 237], "u0": 218, "u2": 218, "u3": 218, "u4f11": [21, 238], "u52a8": [21, 238], "u58eb": [21, 238], "u590f": [21, 238], "u5957": [21, 238], "u5973": [21, 238], "u5b63": [21, 238], "u5c1a": [21, 238], "u65b0": [21, 238], "u65f6": [21, 238], "u6b27": [21, 238], "u6b3": [21, 238], "u6d32": [21, 238], "u77": [21, 238], "u795": [21, 238], "u7ad9": [21, 238], "u7eba": [21, 238], "u8896": [21, 238], "u88c5": [21, 238], "u88e4": [21, 238], "u8fd0": [21, 238], "u957f": [21, 238], "u95f2": [21, 238], "u96ea": [21, 238], "u9a6c": [21, 238], "ua_perc": [144, 149], "ubuntu": 206, "uc_perc": [144, 149], "ucd_i25_1_atherohd": 118, "ufeat": 198, "ug": 101, "uh": [191, 212], "uhm": 229, "uidx": 234, "uk": 101, "umass": [228, 229], "un": [195, 196, 213, 239], "unabl": 206, "uncas": [13, 33, 34, 67, 68, 69, 70, 213, 239], "uncom": 86, "under": [9, 128, 146, 157, 205, 214, 223], "underscor": [0, 164], "understand": [74, 211, 234, 235], "understood": 110, "undi": 229, "unemployave_blslau": [41, 54], "ungar": [205, 209], "ungroup": 107, "unicod": [0, 139], "uniform": [62, 125, 126], "unigram": [63, 129, 140, 213, 218, 228, 239], "union": 107, "uniqu": [206, 221], "unit": [38, 209], "univari": [46, 168, 222, 235], "univers": [25, 26, 174, 205, 238], "unknown": 235, "unless": [12, 15, 41, 52, 53, 57, 72, 94, 105, 195, 196], "unnecessari": [212, 238], "unrecogn": 223, "unrol": [46, 168, 184, 215], "unscal": 224, "unsign": [65, 212, 219, 221, 224, 237, 238], "unsort": 178, "until": 228, "unweight": [212, 221], "unzip": 218, "up": [0, 20, 21, 74, 80, 106, 143, 164, 206, 221, 223, 229, 235], "updat": [0, 27, 207, 218], "upgrad": 207, "upload": [0, 107, 218, 223, 225], "upon": 68, "upt": 201, "upward": 229, "ur": 101, "url": [21, 47, 64, 101, 205, 209], "urllink": [18, 229, 238], "us": [0, 1, 9, 10, 12, 14, 15, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 33, 36, 38, 39, 40, 41, 44, 45, 46, 47, 48, 49, 52, 53, 54, 56, 60, 62, 63, 69, 71, 72, 73, 74, 76, 77, 78, 82, 83, 84, 85, 86, 87, 89, 90, 91, 93, 94, 96, 99, 100, 101, 105, 106, 107, 109, 111, 112, 114, 116, 118, 119, 120, 121, 123, 124, 125, 126, 127, 129, 130, 132, 134, 139, 140, 143, 144, 145, 147, 149, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 164, 168, 171, 172, 174, 175, 176, 180, 182, 183, 186, 187, 189, 190, 192, 194, 195, 196, 198, 200, 203, 205, 206, 209, 211, 212, 218, 219, 220, 221, 222, 223, 224, 228, 229, 231, 232, 234, 235, 236, 238], "usa": 209, "usag": [1, 20, 107, 203, 209, 221], "use_colloc": [7, 8, 50, 88, 95], "useag": 212, "user": [0, 1, 38, 46, 47, 52, 53, 57, 60, 64, 91, 94, 107, 113, 128, 129, 137, 143, 145, 148, 150, 155, 156, 157, 160, 161, 162, 168, 169, 172, 183, 189, 190, 206, 209, 212, 213, 215, 219, 220, 221, 222, 223, 224, 227, 229, 231, 235, 237, 239], "user_id": [11, 13, 16, 17, 19, 20, 27, 31, 32, 33, 34, 38, 39, 46, 47, 48, 51, 52, 53, 57, 60, 63, 64, 65, 67, 68, 69, 70, 71, 73, 80, 84, 86, 87, 91, 93, 94, 99, 101, 111, 112, 113, 128, 129, 136, 137, 139, 147, 148, 150, 151, 155, 156, 157, 158, 159, 160, 161, 162, 166, 167, 168, 169, 172, 179, 183, 184, 191, 192, 198, 199, 200, 201, 202, 203, 212, 213, 214, 215, 219, 221, 224, 225, 226, 227, 229, 231, 232, 234, 235, 236, 237, 238, 239], "usernam": [64, 93, 129, 192, 206, 220, 223, 226], "usexmatrix": 45, "usr": [94, 206, 223], "usual": [16, 17, 40, 42, 43, 45, 54, 74, 75, 137, 178, 189, 190, 195, 196, 203, 222, 224, 229, 234], "utf8": [0, 71], "utf8_general_ci": 71, "utf8mb4": [16, 17, 71], "utf8mb4_bin": 71, "util": 205, "utter": 218, "v": [25, 41, 106, 209, 212, 221, 238], "v1": [0, 206, 220], "v3": 205, "v5": 223, "val": 80, "valenc": 209, "valid": [0, 46, 52, 53, 91, 99, 150, 168, 183, 197, 213, 223, 229, 235, 236, 239], "vallei": 229, "valu": [0, 209, 212, 213, 214, 215, 218, 221, 224, 229, 231, 232, 234, 235, 236, 239], "varchar": [39, 65, 128, 139, 212, 218, 219, 221, 224, 237, 238], "variabl": [29, 37, 46, 57, 76, 77, 78, 93, 99, 118, 124, 132, 143, 145, 147, 154, 173, 192, 214, 223, 232, 236], "varianc": [29, 40, 54, 99], "variance_data": [54, 231], "variat": 209, "variou": [218, 235], "varir": 118, "vb": [18, 238], "vbg": 18, "vbn": 212, "vbp": 212, "vbz": 18, "ve": [213, 223, 226, 229, 239], "vector": [31, 57, 67, 89, 127, 180, 195, 213, 215, 218, 239], "verbos": [215, 236], "veri": [89, 94, 127, 164, 215, 223, 235], "verifi": [221, 223], "version": [0, 14, 18, 21, 22, 23, 24, 25, 26, 165, 215, 220, 223, 224, 238], "versu": [209, 221], "vi": 101, "via": [1, 21, 99, 206, 212, 223, 224, 236, 238], "video": 221, "view": [45, 171, 218, 221, 228], "view_tabl": [8, 73, 237], "visit": 223, "visual": [205, 206, 209, 218], "vo": 101, "vocabulari": [209, 211, 223], "vol": 209, "volum": 209, "vote": [96, 218, 221], "vp": [18, 238], "vu": 209, "w": [106, 107, 209, 229, 231], "w6m3upju4p": 64, "wa": [0, 14, 19, 22, 23, 24, 25, 26, 45, 46, 52, 53, 80, 84, 96, 101, 106, 109, 157, 160, 168, 172, 198, 203, 220, 221, 223, 224, 227, 234, 238], "wai": [143, 206, 213, 214, 224, 236, 239], "walk": [206, 221], "want": [40, 41, 44, 45, 46, 99, 100, 101, 134, 154, 158, 159, 161, 171, 207, 213, 214, 223, 229, 234, 235, 239], "warm_start": 236, "warmer": 209, "warn": 207, "wassa": 209, "wast": 27, "wat": 27, "we": [27, 52, 54, 80, 94, 99, 101, 103, 118, 128, 143, 145, 148, 156, 157, 161, 162, 166, 195, 196, 206, 212, 213, 215, 218, 219, 220, 221, 222, 223, 227, 229, 234, 235, 236, 237, 238, 239], "web": 209, "weblog": 209, "websit": [228, 229], "weeg": 209, "week": 223, "weibo": 21, "weight": [0, 40, 107, 110, 200, 212, 215, 221, 224, 229, 236], "weighted_fil": 107, "weighted_lex": [12, 15, 29, 36, 111], "weighted_lexicon": [8, 12, 15, 73, 203, 212, 215, 221, 228, 229, 236], "weighted_sampl": 0, "weightedsparsefil": 107, "weingarten": 209, "weird": 21, "welcom": 223, "well": [1, 52, 53, 54, 65, 91, 164, 199, 205, 209, 211, 215, 221, 222, 235], "went": 235, "were": [1, 52, 53, 80, 85, 156, 157, 158, 159, 160, 161, 162, 211, 213, 221, 224, 239], "west": [114, 144, 149, 186, 187, 194], "wget": 206, "what": [26, 38, 42, 43, 46, 106, 168, 199, 203, 212, 213, 215, 221, 222, 224, 235, 237, 239], "whatev": [16, 17, 41, 86], "when": [0, 46, 47, 49, 57, 60, 71, 73, 76, 77, 78, 89, 93, 94, 95, 107, 118, 119, 120, 122, 123, 127, 130, 132, 139, 143, 147, 153, 156, 157, 158, 159, 160, 161, 162, 166, 168, 172, 180, 192, 193, 212, 213, 215, 219, 221, 222, 224, 228, 229, 234, 235, 236, 239], "where": [0, 7, 8, 12, 15, 16, 21, 24, 25, 26, 27, 28, 39, 50, 52, 53, 61, 74, 93, 96, 99, 107, 108, 118, 128, 143, 155, 158, 159, 165, 173, 191, 199, 212, 214, 215, 218, 219, 221, 223, 227, 228, 229, 231, 232, 234, 235, 236, 237, 238], "wherea": [38, 132, 206], "wherev": 218, "whether": 228, "which": [14, 16, 18, 21, 24, 28, 38, 40, 45, 52, 53, 58, 59, 61, 68, 80, 84, 89, 91, 94, 96, 101, 102, 103, 107, 108, 118, 127, 143, 152, 158, 159, 161, 171, 174, 185, 189, 190, 204, 206, 212, 213, 215, 218, 219, 221, 223, 227, 228, 229, 231, 232, 234, 235, 236, 238, 239], "while": [47, 64, 94, 101, 143, 213, 215, 228, 229, 239], "whitelist": [7, 8, 35, 57, 83, 85, 96, 97, 110, 145, 227], "whiten": [53, 195, 196, 235, 236], "whitespac": [19, 20], "who": [26, 212], "whose": [46, 47, 168, 215, 219], "why": [158, 159, 161, 221], "wide": [209, 239], "wildcard": [113, 177], "wildest": 229, "willing": 27, "win": [179, 219], "wind": 221, "window": 221, "winter": 209, "wise": [137, 235], "wish": [212, 228], "with_mean": [215, 235, 236], "with_std": [215, 235, 236], "within": [0, 64, 94, 118, 219, 221], "without": [40, 44, 46, 49, 52, 53, 84, 118, 133, 136, 137, 164, 168, 206, 235], "wolf": 229, "women": 209, "won": [46, 137, 168], "wonder": 212, "wong": 209, "wop": 229, "word": [0, 1, 12, 15, 16, 17, 18, 19, 21, 46, 56, 68, 73, 74, 80, 94, 103, 106, 107, 114, 115, 117, 135, 136, 140, 143, 151, 164, 168, 179, 184, 194, 198, 201, 203, 206, 209, 211, 213, 215, 218, 219, 221, 222, 224, 228, 235, 238, 239], "word1": 80, "word2": 80, "word_tabl": [7, 8, 73, 84, 94, 100, 153, 193, 198, 200, 212, 224], "wordcloud": [0, 2, 40, 139, 205, 208, 215, 218, 226, 227], "wordcloud_algorithm": 206, "wordcount": 175, "wordgiventop": 229, "wordi": [189, 190], "wordl": [56, 186, 194, 231], "wordnet": 206, "wordtabl": [93, 192], "work": [0, 9, 19, 20, 21, 28, 33, 46, 54, 61, 74, 94, 108, 113, 146, 177, 201, 205, 211, 212, 213, 220, 221, 222, 226, 227, 232], "workbench": 223, "workshop": 209, "world": [1, 205, 209, 211], "wors": [137, 222], "worth": 165, "would": [64, 68, 106, 136, 145, 203, 213, 220, 221, 239], "wouln": [22, 23, 24, 25, 26, 238], "wrb": 212, "write": [21, 23, 54, 64, 139, 159, 163, 167, 179, 197, 215, 238], "written": [22, 23, 64, 167, 184, 192, 205, 218, 221, 223, 234], "wrong": 165, "wrote": 218, "wwbp": [169, 206, 235], "www": 206, "x": [40, 41, 42, 45, 57, 80, 111, 180, 195, 196, 212, 215, 235, 236], "x0_4": [41, 45], "x0_5": 40, "xarg": [206, 207], "xdf": 41, "xfreq": 41, "xh": 101, "xlnet": 0, "xxx": [213, 221], "xxx_age_output": [213, 236, 239], "xxx_gender_output": 236, "xxx_output": [94, 139, 153, 201, 221], "xxxx": [145, 229], "xxxxx": 145, "y": [57, 195, 196, 207, 209, 212, 229], "yaden": 209, "yai": 229, "ye": [65, 207, 212, 219, 221, 224, 237, 238], "yea": 229, "year": [22, 23, 24, 25, 26, 205, 209, 238], "yeild": 219, "yellow": 221, "yet": [195, 196, 213, 239], "yield": [189, 190, 218, 221], "yoga": 229, "you": [22, 23, 24, 25, 26, 27, 33, 38, 39, 40, 41, 44, 45, 46, 48, 52, 53, 56, 58, 59, 61, 86, 91, 94, 99, 100, 106, 108, 109, 112, 118, 124, 128, 129, 132, 134, 139, 145, 154, 155, 156, 158, 159, 161, 162, 165, 168, 171, 172, 185, 189, 190, 194, 195, 196, 199, 203, 205, 206, 207, 212, 213, 214, 215, 218, 220, 221, 222, 223, 225, 226, 228, 229, 231, 232, 234, 235, 236, 237, 238, 239], "young": 209, "younger": 221, "your": [12, 15, 16, 24, 38, 39, 52, 53, 61, 91, 94, 101, 108, 118, 128, 129, 145, 165, 172, 189, 190, 195, 196, 201, 203, 205, 206, 213, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 231, 235, 238], "your_mysql_password": 220, "your_mysql_usernam": 220, "your_usernam": 220, "yourself": 221, "youth": 209, "youtub": [16, 17, 221], "yyyi": 145, "yyyyi": 145, "z": [40, 41, 43, 45, 137, 229], "z0_4": [41, 45], "z0_5": 40, "z0_5_topic_tagcloud": 40, "za": 229, "zakeri": 209, "zamani": 209, "zdf": 41, "zeng": 209, "zero": [44, 94, 143, 145, 215, 218, 221, 224, 232], "zfreq": 41, "zh": 101, "zilca": 209, "zip": [1, 206], "zombi": 164, "zscore": 204, "zscoregroup": [7, 8], "zu": 101, "\u30c4": [215, 218, 235], "\u6b27\u6d32\u7ad9\u590f\u5b63\u5973\u88c5\u96ea\u7eba\u77ed\u8896\u957f\u88e4\u5973\u58eb\u8fd0\u52a8\u65f6\u5c1a\u4f11\u95f2\u5957\u88c5\u5973\u590f\u88c52014\u65b0\u6b3e": [21, 238], "\u795e\u9a6c": [21, 238]}, "titles": ["Changelog", "Packaged Datasets", "dlatk package", "dlatk.LexicaInterface package", "dlatk.lib package", "dlatk.mysqlMethods package", "dlatkInterface module", "dlatkInterface Flags by type", "Alphabetical list of dlatkInterface Flags", "--AUC", "--IDP", "--bert_model", "--add_corp_lex_table", "--emb_model", "--add_lda_messages", "--add_lex_table", "--add_ngrams", "--add_ngrams_from_tokenized", "--add_parses", "--add_pos_ngram_table", "--add_pos_table", "--add_segmented", "--add_sent_per_row", "--add_sent_tokenized", "--add_tokenized", "--add_tweetpos", "--add_tweettok", "--aggregate_feats_by_new_group", "--all_controls_only", "--anscombe", "--barplot", "--bert_layer_aggregation", "--bert_layers", "--bert_model", "--bert_msg_aggregation", "--blacklist", "--boolean", "--bootstrapp", "-g", "--categorical", "--cca", "--cca_outcomes_vs_controls", "--cca_penalty_feats", "--cca_penalty_outcomes", "--cca_permute", "--cca_predict_components", "--classification_to_lexicon", "--clean_messages", "--cohens_d", "--colabify", "--colloc_table", "--combine_feat_tables", "--nfold_test_classifiers", "--nfold_test_regression", "--control_adjust_outcomes_regression", "--control_combo_sizes", "--corp_topic_tagcloud", "--correlate", "--create_random_sample", "--create_random_sample", "--csv", "-d", "--date_field", "--db_engine", "--deduplicate", "--describe_tables", "--descplot", "--emb_layer_aggregation", "--emb_layers", "--emb_model", "--emb_msg_aggregation", "--encoding", "--estimate_lda_topics", "--extension", "-f", "-f.", "--feat_as_control", "--feat_as_outcome", "--feat_as_path_start", "--feat_blacklist", "--feat_colloc_filter", "--feat_correl_filter", "--feat_flexibin", "--feat_names", "--feat_occ_filter", "--feat_whitelist", "--feature_selection", "--feature_selection_string", "--feature_type_name", "--fit_reducer", "--flexiplot_file", "--folds", "--freq", "--from_file", "--group_freq_thresh", "--include_sub_collocs", "--interaction_ddla", "--interaction_ddla_pvalue", "--interactions", "--keep_low_variance_outcomes", "-l", "--language_filter", "--lda_alpha", "--lda_beta", "--lda_iterations", "--lda_lexicon_name", "--lex_anscombe", "--lex_interface", "--lexicondb", "--load_model", "--loessplot", "--log", "--logistic_reg", "--show_feature_tables", "--make_topic_wordclouds", "--make_wordclouds", "--mallet_path", "--max_tagcloud_words", "--mediation", "--mediation_boot", "--mediation_boot_num", "--mediation_csv", "--mediation_method", "--mediation_no_summary", "--mediators", "--message_field", "--messageid_field", "--model", "--multiclass", "--mysql_config_file", "--n_components", "--no_correction", "--no_features", "--no_lang", "--no_lda_lexicon", "--no_lda_stopping", "--no_metafeats", "--no_standardize", "--no_tagcloud_filter", "--no_unicode", "--num_stopwords", "--num_topics", "--nvalue", "--outcome_controls", "--outcome_fields", "--outcome_interaction", "--outcome_table", "--outcome_with_outcome", "--outcome_with_outcome_only", "--outcomes", "--outliers_to_mean", "--output_name", "--p_correction", "--p_value", "--path_starts", "--picklefile", "--predict_classification_to_outcome_table", "--predict_classifiers", "--predict_classifiers_to_feats", "--predict_classifiers_to_feats", "--predict_regression", "--predict_regression_to_feats", "--predict_regression_to_outcome_table", "--prediction_csv", "--print_joined_feature_lines", "--print_tokenized_lines", "--reduced_lexicon", "--reducer_to_lexicon", "--regression_to_lexicon", "--rmatrix", "--roc", "--save_lda_files", "--save_model", "--scatterplot", "--segmentation_model", "--set_p_occ", "--set_pmi_threshold", "--show_tables", "--sort", "--spam_filter", "--sparse", "--spearman", "--sqrt", "--stratify_folds", "--super_topics", "-t", "--tagcloud", "--tagcloud_colorscheme", "--tagcloud_filter", "--test_classifiers", "--test_regression", "--tf_idf", "--to_file", "--topic_lexicon", "--topic_tagcloud", "--train_classifiers", "--train_regression", "--ttest_feat_tables", "--use_collocs", "--view_tables", "--weighted_lexicon", "--where", "--whitelist", "--word_table", "--zScoreGroup", "Differential Language Analysis ToolKit", "Installation", "Install FAQs", "dlatk", "Papers Utilizing DLATK", "setup module", "Tutorials", "Advanced Feature Extraction", "BERT in DLATK", "Working with DLATK's Classes", "Clustering and Super Topics", "&lt;no title&gt;", "&lt;no title&gt;", "DLATK with ConvoKit", "Data Cleaning", "Data Engines", "Differential Language Analysis (DLA) Tutorial", "DLA Rules of Thumb", "Installing DLATK with Docker", "Understanding Feature Table Names", "Importing and Exporting Data", "Using INI Files", "DLA with Interactions", "DLATK LDA Interface", "Mallet LDA Interface", "&lt;no title&gt;", "Output Formats", "DLATK's Pandas Interface", "&lt;no title&gt;", "Applying A Pickle Model", "Building A Pickle Model", "Intro Prediction / Classification / Predictive Lexica", "Using DLATK to view your SQL data", "Tokenization, Part of Speech Tagging and Segmentation", "Transformers in DLATK (Huggingface Interface)"], "titleterms": {"": [214, 229, 232], "0": [0, 206, 221, 228, 229], "01": 0, "02": 0, "03": 0, "04": 0, "05": 0, "06": 0, "07": 0, "08": 0, "09": 0, "1": [0, 213, 215, 218, 221, 223, 224, 228, 229, 231, 239], "10": 0, "11": 0, "15": 0, "17": 0, "1a": 215, "1b": 215, "1to3": 221, "2": [0, 213, 215, 218, 221, 223, 224, 228, 229], "2000": 1, "2013": 209, "2014": 209, "2015": [0, 209], "2016": [0, 209], "2017": [0, 209], "2018": [0, 209], "2019": [0, 209], "2020": 209, "2021": 0, "21": 0, "29": 0, "3": [0, 206, 213, 215, 221, 223, 228, 229, 231, 236, 239], "30": 0, "31": 0, "4": [0, 213, 228, 229, 239], "5": [0, 229], "6": [0, 229], "7": 229, "8": 229, "9": 229, "A": [229, 231, 234, 235], "For": 231, "If": [228, 229], "The": 235, "To": [229, 234], "access": 229, "acknowledg": 223, "ad": [213, 239], "add": 229, "add_corp_lex_t": 12, "add_lda_messag": 14, "add_lex_t": 15, "add_ngram": 16, "add_ngrams_from_token": 17, "add_pars": 18, "add_pos_ngram_t": 19, "add_pos_t": 20, "add_seg": 21, "add_sent_per_row": 22, "add_sent_token": 23, "add_token": 24, "add_tweetpo": 25, "add_tweettok": 26, "addmessageid": 3, "advanc": 212, "ag": 1, "aggreg": [213, 239], "aggregate_feats_by_new_group": 27, "all_controls_onli": 28, "alphabet": 8, "an": [226, 227], "anaconda": 206, "analysi": [205, 221, 222], "anscomb": 29, "appli": 234, "appropri": 229, "argument": [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 74, 75, 79, 80, 81, 82, 83, 84, 85, 86, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 108, 109, 110, 112, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 200, 201, 202, 203, 204], "ark": 206, "auc": 9, "authorship": 1, "b": 229, "barplot": 30, "bert": 213, "bert_lay": [32, 213], "bert_layer_aggreg": 31, "bert_model": [11, 33, 213], "bert_msg_aggreg": 34, "bigram": 224, "blacklist": 35, "blog": 1, "boolean": 36, "bootstrapp": 37, "brew": 206, "build": [223, 235], "categor": 39, "cca": 40, "cca_outcomes_vs_control": 41, "cca_penalty_feat": 42, "cca_penalty_outcom": 43, "cca_permut": 44, "cca_predict_compon": 45, "changelog": 0, "charact": 212, "citat": 205, "class": [214, 226], "classif": [7, 231, 236], "classification_to_lexicon": 46, "classifypredictor": 2, "clean": [211, 219], "clean_messag": 47, "cloud": 231, "cluster": [2, 7, 211, 215], "cohens_d": 48, "colabifi": 49, "colloc": 212, "colloc_filt": 222, "colloc_t": 50, "combin": 212, "combine_feat_t": 51, "command": [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 79, 80, 81, 82, 83, 84, 85, 86, 87, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99, 101, 102, 103, 104, 105, 106, 107, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 125, 126, 128, 129, 130, 132, 133, 134, 135, 136, 138, 139, 140, 141, 147, 148, 149, 150, 151, 152, 158, 159, 163, 164, 166, 167, 168, 169, 171, 172, 174, 175, 176, 177, 178, 179, 181, 182, 183, 184, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 206, 226, 234, 235], "configur": 206, "content": [2, 3, 4, 5], "continu": [221, 227], "control_adjust_outcomes_regress": 54, "control_combo_s": 55, "convert": 229, "convokit": 218, "corp_topic_tagcloud": 56, "corpu": [1, 206], "correl": [57, 218, 221, 231], "creat": [226, 228, 229, 237], "create_random_sampl": [58, 59], "csv": [60, 225, 231], "d": 61, "data": [1, 211, 218, 219, 220, 225, 237], "databas": 229, "datafram": 232, "dataset": [1, 206], "date_field": 62, "db_engin": 63, "ddla": [2, 227], "dedupl": [64, 219], "default": [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 74, 75, 79, 80, 81, 82, 83, 84, 85, 86, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 108, 109, 110, 112, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 200, 201, 202, 203, 204], "depend": 206, "descplot": 66, "describ": 237, "describe_t": 65, "descript": [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204], "descstat": 4, "detail": [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 74, 75, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 116, 118, 119, 120, 122, 123, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 151, 152, 153, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 170, 171, 172, 173, 174, 179, 180, 181, 182, 183, 184, 185, 188, 189, 190, 191, 192, 193, 195, 196, 197, 198, 200, 202, 203, 204], "differenti": [205, 221], "distribut": 229, "dla": [221, 222, 227], "dlatk": [2, 3, 4, 5, 208, 209, 213, 214, 218, 223, 228, 232, 237, 239], "dlatkinterfac": [6, 7, 8], "docker": 223, "dockerfil": 223, "emb_lay": [68, 239], "emb_layer_aggreg": 67, "emb_model": [13, 69, 239], "emb_msg_aggreg": 70, "encod": 71, "engin": [211, 220], "estim": 228, "estimate_lda_top": 72, "etc": 224, "exampl": [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 79, 80, 81, 82, 83, 84, 85, 86, 87, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99, 101, 102, 103, 104, 105, 106, 107, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 125, 126, 128, 129, 130, 132, 133, 134, 135, 136, 138, 139, 140, 141, 147, 148, 149, 150, 151, 152, 158, 159, 163, 164, 166, 167, 168, 169, 171, 172, 174, 175, 176, 177, 178, 179, 181, 182, 183, 184, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 219, 224, 232], "export": [225, 229], "extens": 73, "extract": [7, 211, 212, 218, 221, 224, 228, 229], "f": [74, 75], "facebook": 1, "faq": 207, "feat_as_control": 76, "feat_as_outcom": 77, "feat_as_path_start": 78, "feat_blacklist": 79, "feat_colloc_filt": 80, "feat_correl_filt": 81, "feat_flexibin": 82, "feat_nam": 83, "feat_occ_filt": 84, "feat_whitelist": 85, "featur": [7, 211, 212, 213, 218, 221, 224, 228, 229, 232, 234, 237, 239], "feature_select": 86, "feature_selection_str": 87, "feature_type_nam": 88, "featureextractor": 2, "featuregett": [2, 232], "featurerefin": 2, "featurestar": [2, 214], "featurework": 2, "file": [206, 226, 229, 231], "filter": [212, 219], "final": 235, "first": 235, "fit": 215, "fit_reduc": 89, "flag": [7, 8], "flexiplot_fil": 90, "fold": 91, "format": [229, 231], "freq": 92, "frequenc": 222, "from": [212, 223, 226, 228, 229], "from_fil": 93, "full": 206, "fun": 238, "fwconstant": 2, "g": 38, "gender": 1, "gener": [221, 228, 229], "get": [205, 206, 211, 229, 232], "github": 206, "gram": [212, 221, 231], "group": 222, "group_freq_thresh": 94, "happier": 238, "happierfuntoken": 4, "hood": 215, "html": 231, "hub": 223, "huggingfac": 239, "ibm": 206, "id": 229, "idf": 212, "idp": 10, "imag": 223, "import": [218, 225, 229, 232], "include_sub_colloc": 95, "inform": [205, 212], "ini": [226, 231], "init": 226, "insight": [7, 221], "instal": [206, 207, 223], "interact": [98, 227], "interaction_ddla": 96, "interaction_ddla_pvalu": 97, "interfac": [206, 228, 229, 232, 239], "intro": 236, "issu": 206, "jar": 206, "keep_low_variance_outcom": 99, "l": 100, "languag": [1, 7, 205, 219, 221], "language_filt": 101, "lda": [1, 211, 228, 229], "lda_alpha": 102, "lda_beta": 103, "lda_iter": 104, "lda_lexicon_nam": 105, "ldaextractor": 3, "level": 222, "lex_anscomb": 106, "lex_interfac": 107, "lexica": [1, 212, 236], "lexicainterfac": 3, "lexicon": [1, 215, 221, 224, 228, 229, 231], "lexicondb": 108, "lexinterfac": 3, "lib": 4, "line": [206, 226], "link": 223, "linux": 206, "list": [8, 206], "load": 206, "load_model": 109, "loessplot": 110, "log": 111, "logistic_reg": 112, "make_topic_wordcloud": 114, "make_wordcloud": 115, "mallet": [206, 211, 229], "mallet_path": 116, "matrix": 231, "max_tagcloud_word": 117, "mediat": [2, 118, 124], "mediation_boot": 119, "mediation_boot_num": 120, "mediation_csv": 121, "mediation_method": 122, "mediation_no_summari": 123, "mention": 219, "messag": [213, 229], "message_field": 125, "messageid_field": 126, "metric": 231, "model": [127, 234, 235], "modul": [2, 3, 4, 5, 6, 206, 210], "more": [205, 212], "multiclass": 128, "mutual": 212, "mysql": [206, 220, 223, 225, 229], "mysql_config_fil": 129, "mysql_iter_func": 5, "mysqlmethod": 5, "n": 212, "n_compon": 130, "name": [213, 224, 239], "necessari": [228, 229], "next": 206, "nfold_test_classifi": 52, "nfold_test_regress": 53, "nlp": 206, "nltk": 206, "no_correct": 131, "no_featur": 132, "no_lang": 133, "no_lda_lexicon": 134, "no_lda_stop": 135, "no_metafeat": 136, "no_standard": 137, "no_tagcloud_filt": 138, "no_unicod": 139, "notifi": 4, "num_stopword": 140, "num_top": 141, "nvalu": 142, "occurr": 212, "occurrenceselect": 2, "one": 232, "option": [206, 229], "osx": 206, "other": [1, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 56, 57, 58, 59, 60, 62, 64, 65, 66, 67, 68, 69, 70, 72, 73, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 89, 90, 91, 92, 94, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 130, 132, 133, 134, 135, 136, 137, 138, 140, 141, 142, 143, 145, 147, 148, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 177, 179, 180, 181, 182, 183, 184, 186, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 204, 206, 211, 212], "outcom": [149, 218, 221, 232, 234], "outcome_control": 143, "outcome_field": 144, "outcome_interact": 145, "outcome_t": 146, "outcome_with_outcom": 147, "outcome_with_outcome_onli": 148, "outcomeanalyz": 2, "outcomegett": [2, 232], "outliers_to_mean": 150, "output": [53, 211, 231, 234], "output_nam": 151, "p_correct": 152, "p_valu": 153, "packag": [1, 2, 3, 4, 5], "panda": 232, "paper": 209, "parser": [206, 238], "part": [212, 238], "pass": 235, "path_start": 154, "pca_mod": 2, "peer": 209, "perma": 1, "pickl": [231, 234, 235], "picklefil": 155, "pip": 206, "pointwis": 212, "predict": [7, 211, 222, 231, 234, 236], "predict_classifi": 157, "predict_classification_to_outcome_t": 156, "predict_classifiers_to_feat": [158, 159], "predict_regress": 160, "predict_regression_to_feat": 161, "predict_regression_to_outcome_t": 162, "prediction_csv": 163, "prepar": [213, 221], "preprocess": 7, "prerequisit": [213, 239], "print": 231, "print_joined_feature_lin": 164, "print_tokenized_lin": 165, "probabl": 231, "public": 209, "python": [206, 225], "random": 237, "real": 219, "recommend": 206, "reduc": 215, "reduced_lexicon": 166, "reducer_to_lexicon": 167, "refer": [46, 168], "refin": 7, "regress": [7, 234], "regression_to_lexicon": 168, "regressionpredictor": 2, "remov": 219, "requir": 234, "review": 209, "rmatrix": 169, "roc": 170, "rule": 222, "run": [223, 227, 229], "sampl": [206, 228, 229, 234, 237], "save_lda_fil": 171, "save_model": 172, "scatterplot": 173, "script": 225, "second": 235, "segment": 238, "segmentation_model": 174, "semanticsextractor": 2, "sentenc": 238, "set_p_occ": 175, "set_pmi_threshold": 176, "setup": [7, 206, 210, 228], "show": 237, "show_feature_t": 113, "show_tabl": 177, "sort": 178, "spam": 219, "spam_filt": 179, "spanish": 1, "spars": 180, "spearman": 181, "speech": [212, 238], "sql": 237, "sqlite": 220, "sqrt": 182, "standalon": 225, "stanford": [206, 238], "stanfordpars": 4, "start": [205, 206, 211], "state": 229, "step": [206, 215, 218, 221, 223, 228, 229, 236], "stratify_fold": 183, "structur": 224, "submodul": [2, 3, 4, 5], "subpackag": 2, "super": 215, "super_top": 184, "support": 206, "switch": [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 234], "t": 185, "tabl": [212, 213, 224, 228, 229, 232, 234, 237, 239], "tag": 238, "tagcloud": 186, "tagcloud_colorschem": 187, "tagcloud_filt": 188, "term": 227, "test_classifi": 189, "test_regress": 190, "text": [211, 229], "tf": 212, "tf_idf": 191, "third": 235, "threshold": 222, "thumb": 222, "to_fil": 192, "token": [212, 229, 238], "toolkit": 205, "topic": [1, 211, 215, 221, 224, 228, 229, 231], "topic_lexicon": 193, "topic_tagcloud": 194, "train": 235, "train_classifi": 195, "train_regress": 196, "transform": [211, 212, 239], "ttest_feat_t": 197, "tutori": [211, 221], "tweet": [206, 228, 229], "tweetnlp": [4, 238], "two": 227, "type": 7, "under": 215, "understand": [213, 224, 239], "unigram": [212, 224], "url": 219, "us": [213, 214, 215, 225, 226, 227, 237, 239], "usag": 212, "use_colloc": 198, "util": 209, "v0": 206, "valu": [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 74, 75, 79, 80, 81, 82, 83, 84, 85, 86, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 108, 109, 110, 112, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 200, 201, 202, 203, 204], "variabl": 227, "version": 206, "via": 226, "video": 211, "view": [211, 237], "view_tabl": 199, "visual": 7, "weighted_lexicon": 200, "where": 201, "whitelist": 202, "word": [212, 229, 231], "word_tabl": 203, "wordcloud": [4, 206], "work": 214, "world": 219, "your": [211, 215, 237], "zscoregroup": 204}})